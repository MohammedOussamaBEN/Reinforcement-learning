{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a9046086ab104ad19085b9fe91797e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_ab0f8641ef2e47b6ada23a3197b29bdc"
          }
        },
        "700cf055d755454e8e3a514486c945e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6047961d9cbf4e90a8b342dae97ccbb7",
            "placeholder": "​",
            "style": "IPY_MODEL_ca1f49a4b5dd41399d3f1133c367eab1",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "298989225cd04e4c9273d3d57c3f8577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_0f3330b587364ddb8185244b3cc8e302",
            "placeholder": "​",
            "style": "IPY_MODEL_e2a14cac37924445890727e1bb99f5da",
            "value": ""
          }
        },
        "8ea627d85bcb4948bc27b5d83296f967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_a880a16471de4055bf3fca0f0a927131",
            "style": "IPY_MODEL_b5db27274d8c4f50bfcd343813e292e6",
            "value": true
          }
        },
        "40e3f08692c34f9e9f6ff74e7d246d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_52f7c233d0284066a29dd45ac2e9ca55",
            "style": "IPY_MODEL_1dd9cf2b47d64b928b346406c83bea40",
            "tooltip": ""
          }
        },
        "522db5f67c6040538f2ba2ac24ab1546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_781969fcfc19418d9a3a8ba92c4b9f20",
            "placeholder": "​",
            "style": "IPY_MODEL_207341f7cd094f5ab882a733ff055742",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "ab0f8641ef2e47b6ada23a3197b29bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "6047961d9cbf4e90a8b342dae97ccbb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca1f49a4b5dd41399d3f1133c367eab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f3330b587364ddb8185244b3cc8e302": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2a14cac37924445890727e1bb99f5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a880a16471de4055bf3fca0f0a927131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5db27274d8c4f50bfcd343813e292e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52f7c233d0284066a29dd45ac2e9ca55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dd9cf2b47d64b928b346406c83bea40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "781969fcfc19418d9a3a8ba92c4b9f20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "207341f7cd094f5ab882a733ff055742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84265be849b24979bb5977dc4c89aad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40a53988f49247359d0a72f079f78da2",
            "placeholder": "​",
            "style": "IPY_MODEL_13bf4b6de6ff4a78943d3b713a88461b",
            "value": "Connecting..."
          }
        },
        "40a53988f49247359d0a72f079f78da2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13bf4b6de6ff4a78943d3b713a88461b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c78c5ec0063b416289dce2fe89e9b0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fd552a5e11744049800633bae0113eb",
              "IPY_MODEL_ee4ec4e591294599a359719edbd8e683",
              "IPY_MODEL_619f5cf36b8045728c25441e5dbcd87e"
            ],
            "layout": "IPY_MODEL_39cd3e39b77544e784129cf10345b7d1"
          }
        },
        "7fd552a5e11744049800633bae0113eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c6da74c843748b9b72512619a2b8ff2",
            "placeholder": "​",
            "style": "IPY_MODEL_c3560a282d7947b0a0fc8c8859be2b4c",
            "value": "policy.optimizer.pth: 100%"
          }
        },
        "ee4ec4e591294599a359719edbd8e683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eef69609139c477f88dcf0c72f485493",
            "max": 49224,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b56561bb7e4406dbfc1765ebf073c8d",
            "value": 49224
          }
        },
        "619f5cf36b8045728c25441e5dbcd87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_283a3a4a6ad34970b1f9354cfc061fe8",
            "placeholder": "​",
            "style": "IPY_MODEL_418ee5dd7b8b4a5c80f723c26994020c",
            "value": " 49.2k/49.2k [00:00&lt;00:00, 77.3kB/s]"
          }
        },
        "39cd3e39b77544e784129cf10345b7d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c6da74c843748b9b72512619a2b8ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3560a282d7947b0a0fc8c8859be2b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eef69609139c477f88dcf0c72f485493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b56561bb7e4406dbfc1765ebf073c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "283a3a4a6ad34970b1f9354cfc061fe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "418ee5dd7b8b4a5c80f723c26994020c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adbdabe296864d4bb49cd7bf8a6eaa81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ca21c3b56de4cdfbabf69e62f2c5b5d",
              "IPY_MODEL_4122230c2ca94b98b392556b403ea576",
              "IPY_MODEL_75aac76a1e3443d38b045f75e8229d04"
            ],
            "layout": "IPY_MODEL_45e2d80723ac44a88112c71c1b44d324"
          }
        },
        "2ca21c3b56de4cdfbabf69e62f2c5b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10dd75ccb3ce49c7a9d430d427adebd8",
            "placeholder": "​",
            "style": "IPY_MODEL_88092a58a99b430ca62a488e5f5378b5",
            "value": "Upload 3 LFS files: 100%"
          }
        },
        "4122230c2ca94b98b392556b403ea576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f181cc724a4771b977da55d73fad3a",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4e56a18ccdc42c8bd2f3837f69dec0c",
            "value": 3
          }
        },
        "75aac76a1e3443d38b045f75e8229d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b740bf50fa643898ef910e59c3975cd",
            "placeholder": "​",
            "style": "IPY_MODEL_543cae745d054c6ea92d37575a92b556",
            "value": " 3/3 [00:00&lt;00:00,  2.49it/s]"
          }
        },
        "45e2d80723ac44a88112c71c1b44d324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10dd75ccb3ce49c7a9d430d427adebd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88092a58a99b430ca62a488e5f5378b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38f181cc724a4771b977da55d73fad3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4e56a18ccdc42c8bd2f3837f69dec0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b740bf50fa643898ef910e59c3975cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "543cae745d054c6ea92d37575a92b556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af001b75d30f48c7a5a02293afa17ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a7ed8d444d14ff2bda905fba1e6f2c0",
              "IPY_MODEL_b07139fd2f8b470a940d9f07afdaa0f9",
              "IPY_MODEL_5c6278e79f274f2e96a1e2e323b61b17"
            ],
            "layout": "IPY_MODEL_3c75e898bfdb45329da491debd7804a6"
          }
        },
        "8a7ed8d444d14ff2bda905fba1e6f2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d36d8e3f912e46cbae23854960e6e43e",
            "placeholder": "​",
            "style": "IPY_MODEL_71b3536b80c64ae59f9b32ad865d6e55",
            "value": "policy.pth: 100%"
          }
        },
        "b07139fd2f8b470a940d9f07afdaa0f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2be2284cce3b462192b40b5ce90b98a8",
            "max": 47343,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f5334bfb2404cb89c5ce0479592a454",
            "value": 47343
          }
        },
        "5c6278e79f274f2e96a1e2e323b61b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12d43c87ba1d484d900c33a50c398391",
            "placeholder": "​",
            "style": "IPY_MODEL_f6b77041e8054281acf81d3cd6809d84",
            "value": " 47.3k/47.3k [00:00&lt;00:00, 65.7kB/s]"
          }
        },
        "3c75e898bfdb45329da491debd7804a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36d8e3f912e46cbae23854960e6e43e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b3536b80c64ae59f9b32ad865d6e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2be2284cce3b462192b40b5ce90b98a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f5334bfb2404cb89c5ce0479592a454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12d43c87ba1d484d900c33a50c398391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6b77041e8054281acf81d3cd6809d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc348c31afbf470a84acde08f7f4142c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4112157198ea406bb57cddbcef95e55d",
              "IPY_MODEL_8296fa13df80418ab2d12b4856f564c8",
              "IPY_MODEL_a8937b021ecb421986877e2d852516c0"
            ],
            "layout": "IPY_MODEL_08c8924685c648f9aa0b78b86e1af506"
          }
        },
        "4112157198ea406bb57cddbcef95e55d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_452d21dd58bd4b1396ec5f7e78ebed31",
            "placeholder": "​",
            "style": "IPY_MODEL_2e7a1e4df0e243329d7abe148a54ad27",
            "value": "a2c-panda-reach.zip: 100%"
          }
        },
        "8296fa13df80418ab2d12b4856f564c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f7e7d0bb83c4ae08bb1dc907a6c66dd",
            "max": 113710,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30208c255d674ae3b908e538406f82ee",
            "value": 113710
          }
        },
        "a8937b021ecb421986877e2d852516c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04b3bb74aa08413cb5b4225a2f21bca7",
            "placeholder": "​",
            "style": "IPY_MODEL_96818b1f5fd546868d830b0bc1610a9c",
            "value": " 114k/114k [00:00&lt;00:00, 89.4kB/s]"
          }
        },
        "08c8924685c648f9aa0b78b86e1af506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "452d21dd58bd4b1396ec5f7e78ebed31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e7a1e4df0e243329d7abe148a54ad27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f7e7d0bb83c4ae08bb1dc907a6c66dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30208c255d674ae3b908e538406f82ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04b3bb74aa08413cb5b4225a2f21bca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96818b1f5fd546868d830b0bc1610a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nCK-hBUz1ho",
        "outputId": "b3226991-5b8b-49da-bc3b-14c29756d0d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting panda-gym==3.0.7\n",
            "  Downloading panda_gym-3.0.7-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\n",
            "Collecting huggingface_sb3\n",
            "  Downloading huggingface_sb3-3.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: gymnasium>=0.26 in /usr/local/lib/python3.11/dist-packages (from panda-gym==3.0.7) (1.0.0)\n",
            "Collecting pybullet (from panda-gym==3.0.7)\n",
            "  Downloading pybullet-3.2.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from panda-gym==3.0.7) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from panda-gym==3.0.7) (1.13.1)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: huggingface-hub~=0.8 in /usr/local/lib/python3.11/dist-packages (from huggingface_sb3) (0.28.1)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.11/dist-packages (from huggingface_sb3) (1.1.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->panda-gym==3.0.7) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (24.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
            "Downloading panda_gym-3.0.7-py3-none-any.whl (23 kB)\n",
            "Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_sb3-3.0-py3-none-any.whl (9.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybullet-3.2.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybullet, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, panda-gym, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, huggingface_sb3, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed huggingface_sb3-3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 panda-gym-3.0.7 pybullet-3.2.7 stable-baselines3-2.5.0\n",
            "Requirement already satisfied: panda-gym==3.0.7 in /usr/local/lib/python3.11/dist-packages (3.0.7)\n",
            "Requirement already satisfied: gymnasium>=0.26 in /usr/local/lib/python3.11/dist-packages (from panda-gym==3.0.7) (1.0.0)\n",
            "Requirement already satisfied: pybullet in /usr/local/lib/python3.11/dist-packages (from panda-gym==3.0.7) (3.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from panda-gym==3.0.7) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from panda-gym==3.0.7) (1.13.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->panda-gym==3.0.7) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->panda-gym==3.0.7) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->panda-gym==3.0.7) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install panda-gym==3.0.7 stable-baselines3 wandb huggingface_sb3\n",
        "! pip install --upgrade panda-gym==3.0.7\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU\n",
        "#0b197edd6d50d8cc0ed00564436ada87f46084fa\n",
        "! wandb login --relogin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiIjvtLfasLj",
        "outputId": "2313253d-a77f-4ac2-e314-e537d46725d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2HWR0VVay1J",
        "outputId": "84954610-515f-4d22-ddeb-1297a30dae77"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbenyahiamohammedoussama\u001b[0m (\u001b[33mbenyahiamohammedoussama-ecole-central-lyon\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a new run\n",
        "wandb.init(project=\"panda-gym\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "aYyAj3xmay39",
        "outputId": "96c2f77a-68f0-4d88-ed06-1786bcd720d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250226_101509-h4i7sifx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym/runs/h4i7sifx' target=\"_blank\">light-snowflake-25</a></strong> to <a href='https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym' target=\"_blank\">https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym/runs/h4i7sifx' target=\"_blank\">https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym/runs/h4i7sifx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym/runs/h4i7sifx?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7a55d7011e50>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n",
        "#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"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "a9046086ab104ad19085b9fe91797e36",
            "700cf055d755454e8e3a514486c945e9",
            "298989225cd04e4c9273d3d57c3f8577",
            "8ea627d85bcb4948bc27b5d83296f967",
            "40e3f08692c34f9e9f6ff74e7d246d93",
            "522db5f67c6040538f2ba2ac24ab1546",
            "ab0f8641ef2e47b6ada23a3197b29bdc",
            "6047961d9cbf4e90a8b342dae97ccbb7",
            "ca1f49a4b5dd41399d3f1133c367eab1",
            "0f3330b587364ddb8185244b3cc8e302",
            "e2a14cac37924445890727e1bb99f5da",
            "a880a16471de4055bf3fca0f0a927131",
            "b5db27274d8c4f50bfcd343813e292e6",
            "52f7c233d0284066a29dd45ac2e9ca55",
            "1dd9cf2b47d64b928b346406c83bea40",
            "781969fcfc19418d9a3a8ba92c4b9f20",
            "207341f7cd094f5ab882a733ff055742",
            "84265be849b24979bb5977dc4c89aad7",
            "40a53988f49247359d0a72f079f78da2",
            "13bf4b6de6ff4a78943d3b713a88461b"
          ]
        },
        "id": "ja19EsqZaWF8",
        "outputId": "a8efb7e5-4c75-4d0e-d52e-2a8a55be19a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9046086ab104ad19085b9fe91797e36"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "import wandb\n",
        "import panda_gym\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from huggingface_hub import notebook_login\n",
        "from huggingface_sb3 import package_to_hub\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configuration dictionary for the RL agent\n",
        "config = {\n",
        "    \"policy_type\": \"MultiInputPolicy\",\n",
        "    \"total_timesteps\": 500000,\n",
        "    \"env_name\": \"PandaReachJointsDense-v3\",\n",
        "    \"num_episodes\": 600,\n",
        "}\n",
        "\n",
        "# Initialize a new wandb run\n",
        "run = wandb.init(\n",
        "    project=\"panda-gym\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # Auto-upload\n",
        "    monitor_gym=True,  # Auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # Save the code (optional)\n",
        ")\n",
        "\n",
        "def make_env():\n",
        "\n",
        "    env = gym.make(config[\"env_name\"])\n",
        "    env = Monitor(env)  # Record stats such as returns\n",
        "    return env\n",
        "\n",
        "# Create the environment and model\n",
        "env = DummyVecEnv([make_env])\n",
        "model = A2C(config[\"policy_type\"], env, verbose=1, tensorboard_log=f\"runs/{run.id}\")\n",
        "\n",
        "# Train the model for a fixed number of episodes\n",
        "episode_rewards = []\n",
        "timesteps_per_episode = config[\"total_timesteps\"] // config[\"num_episodes\"]\n",
        "\n",
        "for episode in range(config[\"num_episodes\"]):\n",
        "    obs = env.reset()\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action, _states = model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, info = env.step(action)\n",
        "        total_reward += reward[0]\n",
        "\n",
        "    episode_rewards.append(total_reward)\n",
        "    print(f\"Episode {episode+1}/{config['num_episodes']}: Total Reward = {total_reward:.2f}\")\n",
        "\n",
        "    # Train the model incrementally\n",
        "    model.learn(total_timesteps=timesteps_per_episode, reset_num_timesteps=False)\n",
        "\n",
        "# Save the model\n",
        "model.save(\"a2c_panda_reach\")\n",
        "wandb.log({\"model_saved\": True})\n",
        "\n",
        "# Evaluate the model\n",
        "eval_env = DummyVecEnv([lambda: gym.make(\"PandaReachJointsDense-v3\")])\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "wandb.log({\"mean_reward\": mean_reward, \"std_reward\": std_reward})\n",
        "print(f\"Evaluation: mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "\n",
        "# Plot Total Reward per Episode\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(episode_rewards, label=\"Episode Reward\")\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Total Reward\")\n",
        "plt.title(\"Total Reward per Episode\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Upload the model to the Hugging Face Hub\n",
        "package_to_hub(\n",
        "    model=model,\n",
        "    model_name=\"a2c-panda-reach\",\n",
        "    model_architecture=\"A2C\",\n",
        "    env_id=\"PandaReachJointsDense-v3\",\n",
        "    eval_env=eval_env,\n",
        "    repo_id=\"oussamab2n/a2c-panda-reach\",\n",
        "    commit_message=\"Optimized model upload with evaluation\"\n",
        ")\n",
        "\n",
        "# Finish the wandb run\n",
        "wandb.finish()\n",
        "\n",
        "print(\"Modèle entraîné sur 500 épisodes, évalué, sauvegardé et visualisé avec succès !\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c78c5ec0063b416289dce2fe89e9b0ad",
            "7fd552a5e11744049800633bae0113eb",
            "ee4ec4e591294599a359719edbd8e683",
            "619f5cf36b8045728c25441e5dbcd87e",
            "39cd3e39b77544e784129cf10345b7d1",
            "4c6da74c843748b9b72512619a2b8ff2",
            "c3560a282d7947b0a0fc8c8859be2b4c",
            "eef69609139c477f88dcf0c72f485493",
            "5b56561bb7e4406dbfc1765ebf073c8d",
            "283a3a4a6ad34970b1f9354cfc061fe8",
            "418ee5dd7b8b4a5c80f723c26994020c",
            "adbdabe296864d4bb49cd7bf8a6eaa81",
            "2ca21c3b56de4cdfbabf69e62f2c5b5d",
            "4122230c2ca94b98b392556b403ea576",
            "75aac76a1e3443d38b045f75e8229d04",
            "45e2d80723ac44a88112c71c1b44d324",
            "10dd75ccb3ce49c7a9d430d427adebd8",
            "88092a58a99b430ca62a488e5f5378b5",
            "38f181cc724a4771b977da55d73fad3a",
            "c4e56a18ccdc42c8bd2f3837f69dec0c",
            "0b740bf50fa643898ef910e59c3975cd",
            "543cae745d054c6ea92d37575a92b556",
            "af001b75d30f48c7a5a02293afa17ba5",
            "8a7ed8d444d14ff2bda905fba1e6f2c0",
            "b07139fd2f8b470a940d9f07afdaa0f9",
            "5c6278e79f274f2e96a1e2e323b61b17",
            "3c75e898bfdb45329da491debd7804a6",
            "d36d8e3f912e46cbae23854960e6e43e",
            "71b3536b80c64ae59f9b32ad865d6e55",
            "2be2284cce3b462192b40b5ce90b98a8",
            "6f5334bfb2404cb89c5ce0479592a454",
            "12d43c87ba1d484d900c33a50c398391",
            "f6b77041e8054281acf81d3cd6809d84",
            "fc348c31afbf470a84acde08f7f4142c",
            "4112157198ea406bb57cddbcef95e55d",
            "8296fa13df80418ab2d12b4856f564c8",
            "a8937b021ecb421986877e2d852516c0",
            "08c8924685c648f9aa0b78b86e1af506",
            "452d21dd58bd4b1396ec5f7e78ebed31",
            "2e7a1e4df0e243329d7abe148a54ad27",
            "9f7e7d0bb83c4ae08bb1dc907a6c66dd",
            "30208c255d674ae3b908e538406f82ee",
            "04b3bb74aa08413cb5b4225a2f21bca7",
            "96818b1f5fd546868d830b0bc1610a9c"
          ]
        },
        "id": "CB_jCjFuLzKZ",
        "outputId": "204eada6-0a9f-4ade-9b9a-2a99a412913e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250226_140257-aqrdlwti</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym/runs/aqrdlwti' target=\"_blank\">sweet-pyramid-32</a></strong> to <a href='https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym' target=\"_blank\">https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym/runs/aqrdlwti' target=\"_blank\">https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym/runs/aqrdlwti</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1/600: Total Reward = -8.30\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 38.8     |\n",
            "|    ep_rew_mean        | -10.3    |\n",
            "|    success_rate       | 0.25     |\n",
            "| time/                 |          |\n",
            "|    fps                | 223      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.9     |\n",
            "|    explained_variance | 0.473    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | -5.6     |\n",
            "|    std                | 0.996    |\n",
            "|    value_loss         | 0.388    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 2/600: Total Reward = -4.45\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 43.8     |\n",
            "|    ep_rew_mean        | -11.3    |\n",
            "|    success_rate       | 0.138    |\n",
            "| time/                 |          |\n",
            "|    fps                | 217      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 1335     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.93    |\n",
            "|    explained_variance | -0.162   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 266      |\n",
            "|    policy_loss        | 2.27     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.0702   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 3/600: Total Reward = -12.06\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 44.5     |\n",
            "|    ep_rew_mean        | -10.5    |\n",
            "|    success_rate       | 0.128    |\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 2170     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.96    |\n",
            "|    explained_variance | -3.14    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 433      |\n",
            "|    policy_loss        | 3.12     |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.083    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 4/600: Total Reward = -9.18\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 44.4     |\n",
            "|    ep_rew_mean        | -10.6    |\n",
            "|    success_rate       | 0.136    |\n",
            "| time/                 |          |\n",
            "|    fps                | 181      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 3005     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.96    |\n",
            "|    explained_variance | -0.125   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 600      |\n",
            "|    policy_loss        | 3.9      |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.177    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 5/600: Total Reward = -5.14\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 44.4     |\n",
            "|    ep_rew_mean        | -10.4    |\n",
            "|    success_rate       | 0.145    |\n",
            "| time/                 |          |\n",
            "|    fps                | 163      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 3840     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.96    |\n",
            "|    explained_variance | -0.149   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 767      |\n",
            "|    policy_loss        | -3.72    |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.173    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 6/600: Total Reward = -9.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 45       |\n",
            "|    ep_rew_mean        | -10.4    |\n",
            "|    success_rate       | 0.13     |\n",
            "| time/                 |          |\n",
            "|    fps                | 197      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 4675     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.97    |\n",
            "|    explained_variance | -16.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 934      |\n",
            "|    policy_loss        | 1.7      |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.0856   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 7/600: Total Reward = -6.01\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 46.2     |\n",
            "|    ep_rew_mean        | -10.2    |\n",
            "|    success_rate       | 0.11     |\n",
            "| time/                 |          |\n",
            "|    fps                | 221      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 5510     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.98    |\n",
            "|    explained_variance | -0.0124  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1101     |\n",
            "|    policy_loss        | -2.58    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.0868   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 8/600: Total Reward = -11.52\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 46.4     |\n",
            "|    ep_rew_mean        | -9.76    |\n",
            "|    success_rate       | 0.11     |\n",
            "| time/                 |          |\n",
            "|    fps                | 231      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 6345     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -10      |\n",
            "|    explained_variance | -1.49    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1268     |\n",
            "|    policy_loss        | -1.21    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.0253   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 9/600: Total Reward = -5.45\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 46.5     |\n",
            "|    ep_rew_mean        | -9.71    |\n",
            "|    success_rate       | 0.12     |\n",
            "| time/                 |          |\n",
            "|    fps                | 245      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 7180     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -10      |\n",
            "|    explained_variance | -12      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1435     |\n",
            "|    policy_loss        | -0.157   |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.025    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 10/600: Total Reward = -22.55\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 44       |\n",
            "|    ep_rew_mean        | -8.76    |\n",
            "|    success_rate       | 0.17     |\n",
            "| time/                 |          |\n",
            "|    fps                | 180      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 8015     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -10      |\n",
            "|    explained_variance | -0.479   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1602     |\n",
            "|    policy_loss        | -2.11    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.0749   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 11/600: Total Reward = -12.20\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 43.5     |\n",
            "|    ep_rew_mean        | -8.45    |\n",
            "|    success_rate       | 0.19     |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 8850     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -10      |\n",
            "|    explained_variance | 0.465    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1769     |\n",
            "|    policy_loss        | 3.85     |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.136    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 12/600: Total Reward = -12.57\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 43.1     |\n",
            "|    ep_rew_mean        | -8.56    |\n",
            "|    success_rate       | 0.19     |\n",
            "| time/                 |          |\n",
            "|    fps                | 235      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 9685     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.99    |\n",
            "|    explained_variance | -10.4    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1936     |\n",
            "|    policy_loss        | -0.244   |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.00153  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 13/600: Total Reward = -13.70\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 41.6     |\n",
            "|    ep_rew_mean        | -8.35    |\n",
            "|    success_rate       | 0.23     |\n",
            "| time/                 |          |\n",
            "|    fps                | 170      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 10520    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.97    |\n",
            "|    explained_variance | 0.699    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2103     |\n",
            "|    policy_loss        | -0.271   |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.00199  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 14/600: Total Reward = -4.09\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 42       |\n",
            "|    ep_rew_mean        | -8.37    |\n",
            "|    success_rate       | 0.21     |\n",
            "| time/                 |          |\n",
            "|    fps                | 236      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 11355    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.99    |\n",
            "|    explained_variance | 0.573    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2270     |\n",
            "|    policy_loss        | -1.8     |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.0347   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 15/600: Total Reward = -11.69\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 42.3     |\n",
            "|    ep_rew_mean        | -8.42    |\n",
            "|    success_rate       | 0.2      |\n",
            "| time/                 |          |\n",
            "|    fps                | 159      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 12190    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -10      |\n",
            "|    explained_variance | -0.75    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2437     |\n",
            "|    policy_loss        | -1.89    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.0585   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 16/600: Total Reward = -8.44\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 42       |\n",
            "|    ep_rew_mean        | -8.2     |\n",
            "|    success_rate       | 0.22     |\n",
            "| time/                 |          |\n",
            "|    fps                | 175      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 13025    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -10      |\n",
            "|    explained_variance | -0.949   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2604     |\n",
            "|    policy_loss        | -0.545   |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.0118   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 17/600: Total Reward = -7.67\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 42.2     |\n",
            "|    ep_rew_mean        | -8.15    |\n",
            "|    success_rate       | 0.23     |\n",
            "| time/                 |          |\n",
            "|    fps                | 235      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 13860    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.98    |\n",
            "|    explained_variance | 0.997    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2771     |\n",
            "|    policy_loss        | 2.49     |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.0515   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 18/600: Total Reward = -12.78\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 41.7     |\n",
            "|    ep_rew_mean        | -7.84    |\n",
            "|    success_rate       | 0.26     |\n",
            "| time/                 |          |\n",
            "|    fps                | 231      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 14695    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.99    |\n",
            "|    explained_variance | -0.839   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2938     |\n",
            "|    policy_loss        | -2.51    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.0825   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 19/600: Total Reward = -8.54\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 40.4     |\n",
            "|    ep_rew_mean        | -7.62    |\n",
            "|    success_rate       | 0.3      |\n",
            "| time/                 |          |\n",
            "|    fps                | 224      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 15530    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.99    |\n",
            "|    explained_variance | 0.683    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3105     |\n",
            "|    policy_loss        | 0.00647  |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.00259  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 20/600: Total Reward = -8.93\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 41.5     |\n",
            "|    ep_rew_mean        | -7.9     |\n",
            "|    success_rate       | 0.28     |\n",
            "| time/                 |          |\n",
            "|    fps                | 209      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 16365    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.98    |\n",
            "|    explained_variance | -8.86    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3272     |\n",
            "|    policy_loss        | -1.84    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.063    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 21/600: Total Reward = -7.27\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 41.9     |\n",
            "|    ep_rew_mean        | -8.04    |\n",
            "|    success_rate       | 0.27     |\n",
            "| time/                 |          |\n",
            "|    fps                | 238      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 17200    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.99    |\n",
            "|    explained_variance | 0.192    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3439     |\n",
            "|    policy_loss        | 0.266    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.00794  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 22/600: Total Reward = -9.20\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 41       |\n",
            "|    ep_rew_mean        | -7.9     |\n",
            "|    success_rate       | 0.3      |\n",
            "| time/                 |          |\n",
            "|    fps                | 239      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 18035    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.97    |\n",
            "|    explained_variance | -2.31    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3606     |\n",
            "|    policy_loss        | -0.138   |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.00485  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 23/600: Total Reward = -3.62\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 40.4     |\n",
            "|    ep_rew_mean        | -7.9     |\n",
            "|    success_rate       | 0.31     |\n",
            "| time/                 |          |\n",
            "|    fps                | 144      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 18870    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -10      |\n",
            "|    explained_variance | -657     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3773     |\n",
            "|    policy_loss        | -2.89    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.179    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 24/600: Total Reward = -8.73\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 40.6     |\n",
            "|    ep_rew_mean        | -7.67    |\n",
            "|    success_rate       | 0.31     |\n",
            "| time/                 |          |\n",
            "|    fps                | 240      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 19705    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.98    |\n",
            "|    explained_variance | 0.536    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3940     |\n",
            "|    policy_loss        | -3.37    |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.0991   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 25/600: Total Reward = -12.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 40.2     |\n",
            "|    ep_rew_mean        | -7.42    |\n",
            "|    success_rate       | 0.33     |\n",
            "| time/                 |          |\n",
            "|    fps                | 240      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 20540    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.94    |\n",
            "|    explained_variance | -3.64    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4107     |\n",
            "|    policy_loss        | -0.102   |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.00501  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 26/600: Total Reward = -0.68\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 40.7     |\n",
            "|    ep_rew_mean        | -7.26    |\n",
            "|    success_rate       | 0.31     |\n",
            "| time/                 |          |\n",
            "|    fps                | 197      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 21375    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.92    |\n",
            "|    explained_variance | -7.71    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4274     |\n",
            "|    policy_loss        | -4.1     |\n",
            "|    std                | 0.999    |\n",
            "|    value_loss         | 0.17     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 27/600: Total Reward = -3.81\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 40       |\n",
            "|    ep_rew_mean        | -7.08    |\n",
            "|    success_rate       | 0.33     |\n",
            "| time/                 |          |\n",
            "|    fps                | 177      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 22210    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.91    |\n",
            "|    explained_variance | 0.521    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4441     |\n",
            "|    policy_loss        | -0.318   |\n",
            "|    std                | 0.998    |\n",
            "|    value_loss         | 0.0032   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 28/600: Total Reward = -3.63\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 40.8     |\n",
            "|    ep_rew_mean        | -7.22    |\n",
            "|    success_rate       | 0.3      |\n",
            "| time/                 |          |\n",
            "|    fps                | 232      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 23045    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.89    |\n",
            "|    explained_variance | -1.39    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4608     |\n",
            "|    policy_loss        | 2.2      |\n",
            "|    std                | 0.994    |\n",
            "|    value_loss         | 0.0657   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 29/600: Total Reward = -0.42\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 40.2     |\n",
            "|    ep_rew_mean        | -7.28    |\n",
            "|    success_rate       | 0.31     |\n",
            "| time/                 |          |\n",
            "|    fps                | 233      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 23880    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.88    |\n",
            "|    explained_variance | -7.95    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4775     |\n",
            "|    policy_loss        | -1.82    |\n",
            "|    std                | 0.993    |\n",
            "|    value_loss         | 0.0515   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 30/600: Total Reward = -6.81\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 39.5     |\n",
            "|    ep_rew_mean        | -6.96    |\n",
            "|    success_rate       | 0.33     |\n",
            "| time/                 |          |\n",
            "|    fps                | 127      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 24715    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.89    |\n",
            "|    explained_variance | 0.863    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4942     |\n",
            "|    policy_loss        | 0.265    |\n",
            "|    std                | 0.994    |\n",
            "|    value_loss         | 0.00245  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 31/600: Total Reward = -11.96\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 39.3     |\n",
            "|    ep_rew_mean        | -6.89    |\n",
            "|    success_rate       | 0.34     |\n",
            "| time/                 |          |\n",
            "|    fps                | 238      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 25550    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.87    |\n",
            "|    explained_variance | 0.152    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5109     |\n",
            "|    policy_loss        | 0.859    |\n",
            "|    std                | 0.991    |\n",
            "|    value_loss         | 0.0129   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 32/600: Total Reward = -1.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 39.8     |\n",
            "|    ep_rew_mean        | -6.83    |\n",
            "|    success_rate       | 0.31     |\n",
            "| time/                 |          |\n",
            "|    fps                | 222      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 26385    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.9     |\n",
            "|    explained_variance | 0.512    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5276     |\n",
            "|    policy_loss        | -2.22    |\n",
            "|    std                | 0.996    |\n",
            "|    value_loss         | 0.0743   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 33/600: Total Reward = -7.95\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 38.1     |\n",
            "|    ep_rew_mean        | -6.14    |\n",
            "|    success_rate       | 0.39     |\n",
            "| time/                 |          |\n",
            "|    fps                | 194      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 27220    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.85    |\n",
            "|    explained_variance | 0.997    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5443     |\n",
            "|    policy_loss        | -0.454   |\n",
            "|    std                | 0.99     |\n",
            "|    value_loss         | 0.00744  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 34/600: Total Reward = -8.72\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 38.9     |\n",
            "|    ep_rew_mean        | -6.14    |\n",
            "|    success_rate       | 0.39     |\n",
            "| time/                 |          |\n",
            "|    fps                | 227      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 28055    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.88    |\n",
            "|    explained_variance | -2.3     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5610     |\n",
            "|    policy_loss        | 0.448    |\n",
            "|    std                | 0.993    |\n",
            "|    value_loss         | 0.00644  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 35/600: Total Reward = -6.96\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 37.3     |\n",
            "|    ep_rew_mean        | -5.67    |\n",
            "|    success_rate       | 0.44     |\n",
            "| time/                 |          |\n",
            "|    fps                | 233      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 28890    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.89    |\n",
            "|    explained_variance | -0.185   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5777     |\n",
            "|    policy_loss        | -1.8     |\n",
            "|    std                | 0.995    |\n",
            "|    value_loss         | 0.0397   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 36/600: Total Reward = -8.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 36.7     |\n",
            "|    ep_rew_mean        | -5.32    |\n",
            "|    success_rate       | 0.47     |\n",
            "| time/                 |          |\n",
            "|    fps                | 168      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 29725    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.89    |\n",
            "|    explained_variance | 0.331    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 5944     |\n",
            "|    policy_loss        | -0.00233 |\n",
            "|    std                | 0.994    |\n",
            "|    value_loss         | 0.000924 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 37/600: Total Reward = -9.06\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 36.5     |\n",
            "|    ep_rew_mean        | -5.21    |\n",
            "|    success_rate       | 0.45     |\n",
            "| time/                 |          |\n",
            "|    fps                | 219      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 30560    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.91    |\n",
            "|    explained_variance | 0.367    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6111     |\n",
            "|    policy_loss        | -2.74    |\n",
            "|    std                | 0.998    |\n",
            "|    value_loss         | 0.102    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 38/600: Total Reward = -0.85\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 35.5     |\n",
            "|    ep_rew_mean        | -5.02    |\n",
            "|    success_rate       | 0.43     |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 31395    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.88    |\n",
            "|    explained_variance | -1.54    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6278     |\n",
            "|    policy_loss        | -0.46    |\n",
            "|    std                | 0.993    |\n",
            "|    value_loss         | 0.00275  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 39/600: Total Reward = -0.77\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 34.2     |\n",
            "|    ep_rew_mean        | -4.6     |\n",
            "|    success_rate       | 0.47     |\n",
            "| time/                 |          |\n",
            "|    fps                | 178      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 32230    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.88    |\n",
            "|    explained_variance | -103     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6445     |\n",
            "|    policy_loss        | -0.649   |\n",
            "|    std                | 0.993    |\n",
            "|    value_loss         | 0.0219   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 40/600: Total Reward = -12.44\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 33.2     |\n",
            "|    ep_rew_mean        | -4.59    |\n",
            "|    success_rate       | 0.48     |\n",
            "| time/                 |          |\n",
            "|    fps                | 237      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 33065    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.88    |\n",
            "|    explained_variance | -4.01    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6612     |\n",
            "|    policy_loss        | 0.486    |\n",
            "|    std                | 0.993    |\n",
            "|    value_loss         | 0.00241  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 41/600: Total Reward = -5.94\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 32.5     |\n",
            "|    ep_rew_mean        | -4.39    |\n",
            "|    success_rate       | 0.52     |\n",
            "| time/                 |          |\n",
            "|    fps                | 237      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 33900    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.86    |\n",
            "|    explained_variance | -0.602   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6779     |\n",
            "|    policy_loss        | 0.925    |\n",
            "|    std                | 0.99     |\n",
            "|    value_loss         | 0.0106   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 42/600: Total Reward = -7.09\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 32.9     |\n",
            "|    ep_rew_mean        | -4.6     |\n",
            "|    success_rate       | 0.5      |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 34735    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.9     |\n",
            "|    explained_variance | 0.526    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6946     |\n",
            "|    policy_loss        | 0.21     |\n",
            "|    std                | 0.996    |\n",
            "|    value_loss         | 0.000394 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 43/600: Total Reward = -6.08\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 33.9     |\n",
            "|    ep_rew_mean        | -4.97    |\n",
            "|    success_rate       | 0.45     |\n",
            "| time/                 |          |\n",
            "|    fps                | 206      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 35570    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.92    |\n",
            "|    explained_variance | -14.4    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7113     |\n",
            "|    policy_loss        | -1.46    |\n",
            "|    std                | 0.999    |\n",
            "|    value_loss         | 0.0234   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 44/600: Total Reward = -5.09\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 36.7     |\n",
            "|    ep_rew_mean        | -5.33    |\n",
            "|    success_rate       | 0.38     |\n",
            "| time/                 |          |\n",
            "|    fps                | 153      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 36405    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.89    |\n",
            "|    explained_variance | 0.34     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7280     |\n",
            "|    policy_loss        | 0.0546   |\n",
            "|    std                | 0.994    |\n",
            "|    value_loss         | 0.00271  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 45/600: Total Reward = -5.22\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 36.7     |\n",
            "|    ep_rew_mean        | -5.32    |\n",
            "|    success_rate       | 0.34     |\n",
            "| time/                 |          |\n",
            "|    fps                | 219      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 37240    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.89    |\n",
            "|    explained_variance | 0.186    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7447     |\n",
            "|    policy_loss        | -3.88    |\n",
            "|    std                | 0.994    |\n",
            "|    value_loss         | 0.144    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 46/600: Total Reward = -7.65\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 37.2     |\n",
            "|    ep_rew_mean        | -5.23    |\n",
            "|    success_rate       | 0.36     |\n",
            "| time/                 |          |\n",
            "|    fps                | 211      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 38075    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.88    |\n",
            "|    explained_variance | 0.997    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7614     |\n",
            "|    policy_loss        | -1.11    |\n",
            "|    std                | 0.992    |\n",
            "|    value_loss         | 0.0117   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 47/600: Total Reward = -8.51\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 37.5     |\n",
            "|    ep_rew_mean        | -5.22    |\n",
            "|    success_rate       | 0.36     |\n",
            "| time/                 |          |\n",
            "|    fps                | 234      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 38910    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.86    |\n",
            "|    explained_variance | 0.519    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7781     |\n",
            "|    policy_loss        | 57       |\n",
            "|    std                | 0.99     |\n",
            "|    value_loss         | 58.3     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 48/600: Total Reward = -7.36\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 37       |\n",
            "|    ep_rew_mean        | -5.03    |\n",
            "|    success_rate       | 0.37     |\n",
            "| time/                 |          |\n",
            "|    fps                | 236      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 39745    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.88    |\n",
            "|    explained_variance | 0.875    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7948     |\n",
            "|    policy_loss        | 1.43     |\n",
            "|    std                | 0.993    |\n",
            "|    value_loss         | 0.0167   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 49/600: Total Reward = -16.26\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 38       |\n",
            "|    ep_rew_mean        | -5.2     |\n",
            "|    success_rate       | 0.35     |\n",
            "| time/                 |          |\n",
            "|    fps                | 162      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 40580    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.87    |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8115     |\n",
            "|    policy_loss        | -0.126   |\n",
            "|    std                | 0.992    |\n",
            "|    value_loss         | 0.000681 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 50/600: Total Reward = -7.17\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 36.7     |\n",
            "|    ep_rew_mean        | -4.95    |\n",
            "|    success_rate       | 0.4      |\n",
            "| time/                 |          |\n",
            "|    fps                | 234      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 41415    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.86    |\n",
            "|    explained_variance | -1.06    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8282     |\n",
            "|    policy_loss        | -1.11    |\n",
            "|    std                | 0.99     |\n",
            "|    value_loss         | 0.0147   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 51/600: Total Reward = -4.06\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 31.4     |\n",
            "|    ep_rew_mean        | -4.08    |\n",
            "|    success_rate       | 0.51     |\n",
            "| time/                 |          |\n",
            "|    fps                | 223      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 42250    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.87    |\n",
            "|    explained_variance | -11.1    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8449     |\n",
            "|    policy_loss        | 0.723    |\n",
            "|    std                | 0.992    |\n",
            "|    value_loss         | 0.00806  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 52/600: Total Reward = -7.65\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.4     |\n",
            "|    ep_rew_mean        | -3.99    |\n",
            "|    success_rate       | 0.56     |\n",
            "| time/                 |          |\n",
            "|    fps                | 174      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 43085    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.85    |\n",
            "|    explained_variance | -2.12    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8616     |\n",
            "|    policy_loss        | -0.147   |\n",
            "|    std                | 0.989    |\n",
            "|    value_loss         | 0.000449 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 53/600: Total Reward = -9.85\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.8     |\n",
            "|    ep_rew_mean        | -3.78    |\n",
            "|    success_rate       | 0.61     |\n",
            "| time/                 |          |\n",
            "|    fps                | 230      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 43920    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.83    |\n",
            "|    explained_variance | -8.53    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8783     |\n",
            "|    policy_loss        | -0.556   |\n",
            "|    std                | 0.986    |\n",
            "|    value_loss         | 0.00337  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 54/600: Total Reward = -6.30\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.6     |\n",
            "|    ep_rew_mean        | -3.65    |\n",
            "|    success_rate       | 0.64     |\n",
            "| time/                 |          |\n",
            "|    fps                | 235      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 44755    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.81    |\n",
            "|    explained_variance | -1.5     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8950     |\n",
            "|    policy_loss        | 0.0117   |\n",
            "|    std                | 0.984    |\n",
            "|    value_loss         | 0.00293  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 55/600: Total Reward = -10.37\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.6     |\n",
            "|    ep_rew_mean        | -3.36    |\n",
            "|    success_rate       | 0.67     |\n",
            "| time/                 |          |\n",
            "|    fps                | 221      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 45590    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.77    |\n",
            "|    explained_variance | -1.68    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9117     |\n",
            "|    policy_loss        | 1.44     |\n",
            "|    std                | 0.978    |\n",
            "|    value_loss         | 0.0361   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 56/600: Total Reward = -9.23\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.3     |\n",
            "|    ep_rew_mean        | -3.31    |\n",
            "|    success_rate       | 0.68     |\n",
            "| time/                 |          |\n",
            "|    fps                | 179      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 46425    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.76    |\n",
            "|    explained_variance | -12.6    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9284     |\n",
            "|    policy_loss        | -1.32    |\n",
            "|    std                | 0.977    |\n",
            "|    value_loss         | 0.0275   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 57/600: Total Reward = -8.75\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.4     |\n",
            "|    ep_rew_mean        | -3.78    |\n",
            "|    success_rate       | 0.62     |\n",
            "| time/                 |          |\n",
            "|    fps                | 224      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 47260    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.8     |\n",
            "|    explained_variance | -2.7     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9451     |\n",
            "|    policy_loss        | 0.601    |\n",
            "|    std                | 0.983    |\n",
            "|    value_loss         | 0.00651  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 58/600: Total Reward = -11.16\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.5     |\n",
            "|    ep_rew_mean        | -3.99    |\n",
            "|    success_rate       | 0.57     |\n",
            "| time/                 |          |\n",
            "|    fps                | 224      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 48095    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.78    |\n",
            "|    explained_variance | 0.517    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9618     |\n",
            "|    policy_loss        | -1.1     |\n",
            "|    std                | 0.98     |\n",
            "|    value_loss         | 0.015    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 59/600: Total Reward = -4.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 31.9     |\n",
            "|    ep_rew_mean        | -4.24    |\n",
            "|    success_rate       | 0.54     |\n",
            "| time/                 |          |\n",
            "|    fps                | 171      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 48930    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.74    |\n",
            "|    explained_variance | 0.243    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9785     |\n",
            "|    policy_loss        | -0.871   |\n",
            "|    std                | 0.975    |\n",
            "|    value_loss         | 0.00997  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 60/600: Total Reward = -0.37\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 31.4     |\n",
            "|    ep_rew_mean        | -4.13    |\n",
            "|    success_rate       | 0.54     |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 49765    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.73    |\n",
            "|    explained_variance | 0.225    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9952     |\n",
            "|    policy_loss        | -0.35    |\n",
            "|    std                | 0.974    |\n",
            "|    value_loss         | 0.00356  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 61/600: Total Reward = -3.88\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.1     |\n",
            "|    ep_rew_mean        | -3.45    |\n",
            "|    success_rate       | 0.65     |\n",
            "| time/                 |          |\n",
            "|    fps                | 226      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 50600    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.71    |\n",
            "|    explained_variance | -4.07    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10119    |\n",
            "|    policy_loss        | 0.973    |\n",
            "|    std                | 0.971    |\n",
            "|    value_loss         | 0.0167   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 62/600: Total Reward = -5.93\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.6     |\n",
            "|    ep_rew_mean        | -3.06    |\n",
            "|    success_rate       | 0.69     |\n",
            "| time/                 |          |\n",
            "|    fps                | 153      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 51435    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.72    |\n",
            "|    explained_variance | -112     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10286    |\n",
            "|    policy_loss        | 0.703    |\n",
            "|    std                | 0.971    |\n",
            "|    value_loss         | 0.00935  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 63/600: Total Reward = -0.94\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 23.7     |\n",
            "|    ep_rew_mean        | -3.14    |\n",
            "|    success_rate       | 0.7      |\n",
            "| time/                 |          |\n",
            "|    fps                | 225      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 52270    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.71    |\n",
            "|    explained_variance | 0.621    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10453    |\n",
            "|    policy_loss        | 1.11     |\n",
            "|    std                | 0.971    |\n",
            "|    value_loss         | 0.0136   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 64/600: Total Reward = -0.56\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24       |\n",
            "|    ep_rew_mean        | -3.15    |\n",
            "|    success_rate       | 0.69     |\n",
            "| time/                 |          |\n",
            "|    fps                | 227      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 53105    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.73    |\n",
            "|    explained_variance | -147     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10620    |\n",
            "|    policy_loss        | -6.91    |\n",
            "|    std                | 0.974    |\n",
            "|    value_loss         | 0.579    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 65/600: Total Reward = -13.02\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.1     |\n",
            "|    ep_rew_mean        | -3.83    |\n",
            "|    success_rate       | 0.59     |\n",
            "| time/                 |          |\n",
            "|    fps                | 188      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 53940    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.73    |\n",
            "|    explained_variance | 0.142    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10787    |\n",
            "|    policy_loss        | 0.0339   |\n",
            "|    std                | 0.974    |\n",
            "|    value_loss         | 0.00341  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 66/600: Total Reward = -6.65\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.1     |\n",
            "|    ep_rew_mean        | -4.17    |\n",
            "|    success_rate       | 0.51     |\n",
            "| time/                 |          |\n",
            "|    fps                | 226      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 54775    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.72    |\n",
            "|    explained_variance | 0.194    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 10954    |\n",
            "|    policy_loss        | 0.813    |\n",
            "|    std                | 0.972    |\n",
            "|    value_loss         | 0.00733  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 67/600: Total Reward = -7.57\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.2     |\n",
            "|    ep_rew_mean        | -3.72    |\n",
            "|    success_rate       | 0.56     |\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 55610    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.73    |\n",
            "|    explained_variance | -3.01    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11121    |\n",
            "|    policy_loss        | -2.35    |\n",
            "|    std                | 0.973    |\n",
            "|    value_loss         | 0.066    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 68/600: Total Reward = -6.49\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 32.2     |\n",
            "|    ep_rew_mean        | -4.56    |\n",
            "|    success_rate       | 0.45     |\n",
            "| time/                 |          |\n",
            "|    fps                | 228      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 56445    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.73    |\n",
            "|    explained_variance | 0.815    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11288    |\n",
            "|    policy_loss        | -0.783   |\n",
            "|    std                | 0.974    |\n",
            "|    value_loss         | 0.0633   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 69/600: Total Reward = -7.57\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.4     |\n",
            "|    ep_rew_mean        | -4.31    |\n",
            "|    success_rate       | 0.54     |\n",
            "| time/                 |          |\n",
            "|    fps                | 187      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 57280    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.73    |\n",
            "|    explained_variance | -0.832   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11455    |\n",
            "|    policy_loss        | 0.835    |\n",
            "|    std                | 0.973    |\n",
            "|    value_loss         | 0.0142   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 70/600: Total Reward = -0.34\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.7     |\n",
            "|    ep_rew_mean        | -3.95    |\n",
            "|    success_rate       | 0.62     |\n",
            "| time/                 |          |\n",
            "|    fps                | 234      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 58115    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.74    |\n",
            "|    explained_variance | 0.99     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11622    |\n",
            "|    policy_loss        | 0.801    |\n",
            "|    std                | 0.974    |\n",
            "|    value_loss         | 0.0175   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 71/600: Total Reward = -5.61\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.4     |\n",
            "|    ep_rew_mean        | -3.83    |\n",
            "|    success_rate       | 0.61     |\n",
            "| time/                 |          |\n",
            "|    fps                | 224      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 58950    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.73    |\n",
            "|    explained_variance | -14.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11789    |\n",
            "|    policy_loss        | 1.69     |\n",
            "|    std                | 0.973    |\n",
            "|    value_loss         | 0.0434   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 72/600: Total Reward = -8.14\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.5     |\n",
            "|    ep_rew_mean        | -3.01    |\n",
            "|    success_rate       | 0.7      |\n",
            "| time/                 |          |\n",
            "|    fps                | 155      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 59785    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.71    |\n",
            "|    explained_variance | 0.996    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 11956    |\n",
            "|    policy_loss        | 0.835    |\n",
            "|    std                | 0.971    |\n",
            "|    value_loss         | 0.0141   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 73/600: Total Reward = -0.54\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.9     |\n",
            "|    ep_rew_mean        | -3.45    |\n",
            "|    success_rate       | 0.62     |\n",
            "| time/                 |          |\n",
            "|    fps                | 224      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 60620    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.7     |\n",
            "|    explained_variance | 0.465    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12123    |\n",
            "|    policy_loss        | -1.22    |\n",
            "|    std                | 0.97     |\n",
            "|    value_loss         | 0.0189   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 74/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.6     |\n",
            "|    ep_rew_mean        | -3.85    |\n",
            "|    success_rate       | 0.57     |\n",
            "| time/                 |          |\n",
            "|    fps                | 219      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 61455    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.69    |\n",
            "|    explained_variance | -2.9     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12290    |\n",
            "|    policy_loss        | 0.824    |\n",
            "|    std                | 0.968    |\n",
            "|    value_loss         | 0.0122   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 75/600: Total Reward = -2.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.9     |\n",
            "|    ep_rew_mean        | -3.57    |\n",
            "|    success_rate       | 0.61     |\n",
            "| time/                 |          |\n",
            "|    fps                | 168      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 62290    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.69    |\n",
            "|    explained_variance | 0.508    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12457    |\n",
            "|    policy_loss        | -0.331   |\n",
            "|    std                | 0.969    |\n",
            "|    value_loss         | 0.00465  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 76/600: Total Reward = -1.20\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.1     |\n",
            "|    ep_rew_mean        | -3.79    |\n",
            "|    success_rate       | 0.57     |\n",
            "| time/                 |          |\n",
            "|    fps                | 226      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 63125    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.69    |\n",
            "|    explained_variance | -0.0705  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12624    |\n",
            "|    policy_loss        | -0.565   |\n",
            "|    std                | 0.97     |\n",
            "|    value_loss         | 0.00712  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 77/600: Total Reward = -2.60\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.9     |\n",
            "|    ep_rew_mean        | -2.95    |\n",
            "|    success_rate       | 0.67     |\n",
            "| time/                 |          |\n",
            "|    fps                | 229      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 63960    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.71    |\n",
            "|    explained_variance | 0.0542   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12791    |\n",
            "|    policy_loss        | -0.791   |\n",
            "|    std                | 0.972    |\n",
            "|    value_loss         | 0.0103   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 78/600: Total Reward = -1.56\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.3     |\n",
            "|    ep_rew_mean        | -3.14    |\n",
            "|    success_rate       | 0.65     |\n",
            "| time/                 |          |\n",
            "|    fps                | 212      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 64795    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.68    |\n",
            "|    explained_variance | 0.774    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 12958    |\n",
            "|    policy_loss        | -0.193   |\n",
            "|    std                | 0.969    |\n",
            "|    value_loss         | 0.00103  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 79/600: Total Reward = -6.16\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.5     |\n",
            "|    ep_rew_mean        | -2.96    |\n",
            "|    success_rate       | 0.7      |\n",
            "| time/                 |          |\n",
            "|    fps                | 193      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 65630    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.67    |\n",
            "|    explained_variance | -6.94    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13125    |\n",
            "|    policy_loss        | -0.14    |\n",
            "|    std                | 0.968    |\n",
            "|    value_loss         | 0.00135  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 80/600: Total Reward = -5.65\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.8     |\n",
            "|    ep_rew_mean        | -2.93    |\n",
            "|    success_rate       | 0.75     |\n",
            "| time/                 |          |\n",
            "|    fps                | 221      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 66465    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.68    |\n",
            "|    explained_variance | 0.467    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13292    |\n",
            "|    policy_loss        | 0.508    |\n",
            "|    std                | 0.969    |\n",
            "|    value_loss         | 0.00341  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 81/600: Total Reward = -0.27\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.3     |\n",
            "|    ep_rew_mean        | -2.76    |\n",
            "|    success_rate       | 0.76     |\n",
            "| time/                 |          |\n",
            "|    fps                | 225      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 67300    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.69    |\n",
            "|    explained_variance | 0.0985   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13459    |\n",
            "|    policy_loss        | 28.4     |\n",
            "|    std                | 0.969    |\n",
            "|    value_loss         | 25.9     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 82/600: Total Reward = -6.17\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.8     |\n",
            "|    ep_rew_mean        | -2.74    |\n",
            "|    success_rate       | 0.74     |\n",
            "| time/                 |          |\n",
            "|    fps                | 157      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 68135    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.66    |\n",
            "|    explained_variance | -26.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13626    |\n",
            "|    policy_loss        | 0.416    |\n",
            "|    std                | 0.966    |\n",
            "|    value_loss         | 0.00239  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 83/600: Total Reward = -0.31\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 23.6     |\n",
            "|    ep_rew_mean        | -2.45    |\n",
            "|    success_rate       | 0.78     |\n",
            "| time/                 |          |\n",
            "|    fps                | 222      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 68970    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.66    |\n",
            "|    explained_variance | -2.01    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13793    |\n",
            "|    policy_loss        | -0.698   |\n",
            "|    std                | 0.965    |\n",
            "|    value_loss         | 0.0192   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 84/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 23.3     |\n",
            "|    ep_rew_mean        | -2.47    |\n",
            "|    success_rate       | 0.82     |\n",
            "| time/                 |          |\n",
            "|    fps                | 221      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 69805    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.63    |\n",
            "|    explained_variance | 0.793    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 13960    |\n",
            "|    policy_loss        | -0.269   |\n",
            "|    std                | 0.961    |\n",
            "|    value_loss         | 0.00125  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 85/600: Total Reward = -0.63\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 21.3     |\n",
            "|    ep_rew_mean        | -2.2     |\n",
            "|    success_rate       | 0.86     |\n",
            "| time/                 |          |\n",
            "|    fps                | 167      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 70640    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.6     |\n",
            "|    explained_variance | -1.22    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14127    |\n",
            "|    policy_loss        | -1.09    |\n",
            "|    std                | 0.958    |\n",
            "|    value_loss         | 0.0224   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 86/600: Total Reward = -0.85\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 15.3     |\n",
            "|    ep_rew_mean        | -1.51    |\n",
            "|    success_rate       | 0.91     |\n",
            "| time/                 |          |\n",
            "|    fps                | 224      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 71475    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.57    |\n",
            "|    explained_variance | -0.149   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14294    |\n",
            "|    policy_loss        | -2.14    |\n",
            "|    std                | 0.954    |\n",
            "|    value_loss         | 0.064    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 87/600: Total Reward = -0.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 11.4     |\n",
            "|    ep_rew_mean        | -1.05    |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 223      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 72310    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.53    |\n",
            "|    explained_variance | -1.36    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14461    |\n",
            "|    policy_loss        | -3.07    |\n",
            "|    std                | 0.948    |\n",
            "|    value_loss         | 0.141    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 88/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 10.1     |\n",
            "|    ep_rew_mean        | -0.956   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 209      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 73145    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.44    |\n",
            "|    explained_variance | -3.26    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14628    |\n",
            "|    policy_loss        | -1.73    |\n",
            "|    std                | 0.937    |\n",
            "|    value_loss         | 0.0614   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 89/600: Total Reward = -0.77\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8.83     |\n",
            "|    ep_rew_mean        | -0.816   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 190      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 73980    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.42    |\n",
            "|    explained_variance | -20.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14795    |\n",
            "|    policy_loss        | -2.99    |\n",
            "|    std                | 0.934    |\n",
            "|    value_loss         | 0.204    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 90/600: Total Reward = -0.36\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 10.3     |\n",
            "|    ep_rew_mean        | -1.12    |\n",
            "|    success_rate       | 0.95     |\n",
            "| time/                 |          |\n",
            "|    fps                | 227      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 74815    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.4     |\n",
            "|    explained_variance | -3.13    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 14962    |\n",
            "|    policy_loss        | -3.65    |\n",
            "|    std                | 0.933    |\n",
            "|    value_loss         | 0.176    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 91/600: Total Reward = -2.03\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 11.6     |\n",
            "|    ep_rew_mean        | -1.4     |\n",
            "|    success_rate       | 0.92     |\n",
            "| time/                 |          |\n",
            "|    fps                | 213      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 75650    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.37    |\n",
            "|    explained_variance | -0.164   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15129    |\n",
            "|    policy_loss        | 30.2     |\n",
            "|    std                | 0.928    |\n",
            "|    value_loss         | 15.5     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 92/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8.15     |\n",
            "|    ep_rew_mean        | -1.01    |\n",
            "|    success_rate       | 0.97     |\n",
            "| time/                 |          |\n",
            "|    fps                | 152      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 76485    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.34    |\n",
            "|    explained_variance | -13.1    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15296    |\n",
            "|    policy_loss        | -5.69    |\n",
            "|    std                | 0.925    |\n",
            "|    value_loss         | 0.437    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 93/600: Total Reward = -0.52\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 9.71     |\n",
            "|    ep_rew_mean        | -1.39    |\n",
            "|    success_rate       | 0.92     |\n",
            "| time/                 |          |\n",
            "|    fps                | 229      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 77320    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.32    |\n",
            "|    explained_variance | 0.305    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15463    |\n",
            "|    policy_loss        | 39.2     |\n",
            "|    std                | 0.922    |\n",
            "|    value_loss         | 21       |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 94/600: Total Reward = -0.65\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 12.2     |\n",
            "|    ep_rew_mean        | -1.52    |\n",
            "|    success_rate       | 0.9      |\n",
            "| time/                 |          |\n",
            "|    fps                | 220      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 78155    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.36    |\n",
            "|    explained_variance | 0.0849   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15630    |\n",
            "|    policy_loss        | 37.2     |\n",
            "|    std                | 0.927    |\n",
            "|    value_loss         | 29.9     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 95/600: Total Reward = -0.88\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 11.9     |\n",
            "|    ep_rew_mean        | -1.52    |\n",
            "|    success_rate       | 0.89     |\n",
            "| time/                 |          |\n",
            "|    fps                | 170      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 78990    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.32    |\n",
            "|    explained_variance | -190     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15797    |\n",
            "|    policy_loss        | -3.64    |\n",
            "|    std                | 0.921    |\n",
            "|    value_loss         | 0.187    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 96/600: Total Reward = -0.05\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8.6      |\n",
            "|    ep_rew_mean        | -0.933   |\n",
            "|    success_rate       | 0.95     |\n",
            "| time/                 |          |\n",
            "|    fps                | 222      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 79825    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.28    |\n",
            "|    explained_variance | -4.48    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 15964    |\n",
            "|    policy_loss        | 20.6     |\n",
            "|    std                | 0.916    |\n",
            "|    value_loss         | 11.3     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 97/600: Total Reward = -0.42\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 9.35     |\n",
            "|    ep_rew_mean        | -1.1     |\n",
            "|    success_rate       | 0.94     |\n",
            "| time/                 |          |\n",
            "|    fps                | 220      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 80660    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.25    |\n",
            "|    explained_variance | -0.0488  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16131    |\n",
            "|    policy_loss        | 38.2     |\n",
            "|    std                | 0.912    |\n",
            "|    value_loss         | 27.9     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 98/600: Total Reward = -0.91\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 13.1     |\n",
            "|    ep_rew_mean        | -1.96    |\n",
            "|    success_rate       | 0.87     |\n",
            "| time/                 |          |\n",
            "|    fps                | 201      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 81495    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.26    |\n",
            "|    explained_variance | -23.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16298    |\n",
            "|    policy_loss        | 2.97     |\n",
            "|    std                | 0.914    |\n",
            "|    value_loss         | 0.114    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 99/600: Total Reward = -1.14\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 11.5     |\n",
            "|    ep_rew_mean        | -1.6     |\n",
            "|    success_rate       | 0.92     |\n",
            "| time/                 |          |\n",
            "|    fps                | 189      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 82330    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.27    |\n",
            "|    explained_variance | -25.6    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16465    |\n",
            "|    policy_loss        | 1.41     |\n",
            "|    std                | 0.915    |\n",
            "|    value_loss         | 0.0301   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 100/600: Total Reward = -0.64\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 12.4     |\n",
            "|    ep_rew_mean        | -1.8     |\n",
            "|    success_rate       | 0.88     |\n",
            "| time/                 |          |\n",
            "|    fps                | 219      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 83165    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.25    |\n",
            "|    explained_variance | -31      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16632    |\n",
            "|    policy_loss        | 1.97     |\n",
            "|    std                | 0.912    |\n",
            "|    value_loss         | 0.0536   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 101/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 9.63     |\n",
            "|    ep_rew_mean        | -1.1     |\n",
            "|    success_rate       | 0.95     |\n",
            "| time/                 |          |\n",
            "|    fps                | 218      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 84000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.23    |\n",
            "|    explained_variance | -0.314   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16799    |\n",
            "|    policy_loss        | -14.1    |\n",
            "|    std                | 0.91     |\n",
            "|    value_loss         | 2.76     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 102/600: Total Reward = -22.38\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 14.1     |\n",
            "|    ep_rew_mean        | -3.03    |\n",
            "|    success_rate       | 0.83     |\n",
            "| time/                 |          |\n",
            "|    fps                | 157      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 84835    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.26    |\n",
            "|    explained_variance | -323     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 16966    |\n",
            "|    policy_loss        | 3.84     |\n",
            "|    std                | 0.915    |\n",
            "|    value_loss         | 0.189    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 103/600: Total Reward = -21.17\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 19.2     |\n",
            "|    ep_rew_mean        | -4.51    |\n",
            "|    success_rate       | 0.7      |\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 85670    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.26    |\n",
            "|    explained_variance | -81.4    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17133    |\n",
            "|    policy_loss        | 11.7     |\n",
            "|    std                | 0.914    |\n",
            "|    value_loss         | 2.31     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 104/600: Total Reward = -0.76\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.4     |\n",
            "|    ep_rew_mean        | -5.75    |\n",
            "|    success_rate       | 0.57     |\n",
            "| time/                 |          |\n",
            "|    fps                | 209      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 86505    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.25    |\n",
            "|    explained_variance | -727     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17300    |\n",
            "|    policy_loss        | 18.1     |\n",
            "|    std                | 0.912    |\n",
            "|    value_loss         | 3.57     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 105/600: Total Reward = -10.08\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.7     |\n",
            "|    ep_rew_mean        | -5.75    |\n",
            "|    success_rate       | 0.52     |\n",
            "| time/                 |          |\n",
            "|    fps                | 143      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 87340    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.27    |\n",
            "|    explained_variance | -1.62    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17467    |\n",
            "|    policy_loss        | -5.18    |\n",
            "|    std                | 0.915    |\n",
            "|    value_loss         | 0.613    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 106/600: Total Reward = -9.03\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 31       |\n",
            "|    ep_rew_mean        | -6.68    |\n",
            "|    success_rate       | 0.44     |\n",
            "| time/                 |          |\n",
            "|    fps                | 199      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 88175    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.31    |\n",
            "|    explained_variance | -2.89    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17634    |\n",
            "|    policy_loss        | -2.37    |\n",
            "|    std                | 0.92     |\n",
            "|    value_loss         | 0.0789   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 107/600: Total Reward = -16.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 36.9     |\n",
            "|    ep_rew_mean        | -8.13    |\n",
            "|    success_rate       | 0.31     |\n",
            "| time/                 |          |\n",
            "|    fps                | 194      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 89010    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.3     |\n",
            "|    explained_variance | -4.52    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17801    |\n",
            "|    policy_loss        | -1.39    |\n",
            "|    std                | 0.92     |\n",
            "|    value_loss         | 0.0888   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 108/600: Total Reward = -15.78\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 38.5     |\n",
            "|    ep_rew_mean        | -8.26    |\n",
            "|    success_rate       | 0.27     |\n",
            "| time/                 |          |\n",
            "|    fps                | 145      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 89845    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.31    |\n",
            "|    explained_variance | -24.6    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 17968    |\n",
            "|    policy_loss        | -3.16    |\n",
            "|    std                | 0.92     |\n",
            "|    value_loss         | 0.146    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 109/600: Total Reward = -5.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 39.8     |\n",
            "|    ep_rew_mean        | -8.57    |\n",
            "|    success_rate       | 0.23     |\n",
            "| time/                 |          |\n",
            "|    fps                | 212      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 90680    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.25    |\n",
            "|    explained_variance | -0.514   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18135    |\n",
            "|    policy_loss        | 1.27     |\n",
            "|    std                | 0.913    |\n",
            "|    value_loss         | 0.0225   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 110/600: Total Reward = -4.73\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 41.4     |\n",
            "|    ep_rew_mean        | -8.5     |\n",
            "|    success_rate       | 0.2      |\n",
            "| time/                 |          |\n",
            "|    fps                | 210      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 91515    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.27    |\n",
            "|    explained_variance | 0.00535  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18302    |\n",
            "|    policy_loss        | 1.43     |\n",
            "|    std                | 0.915    |\n",
            "|    value_loss         | 0.032    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 111/600: Total Reward = -17.72\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 42.1     |\n",
            "|    ep_rew_mean        | -8.4     |\n",
            "|    success_rate       | 0.19     |\n",
            "| time/                 |          |\n",
            "|    fps                | 146      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 92350    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.29    |\n",
            "|    explained_variance | -64      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18469    |\n",
            "|    policy_loss        | -4.4     |\n",
            "|    std                | 0.919    |\n",
            "|    value_loss         | 0.282    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 112/600: Total Reward = -10.09\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 39.7     |\n",
            "|    ep_rew_mean        | -7.8     |\n",
            "|    success_rate       | 0.25     |\n",
            "| time/                 |          |\n",
            "|    fps                | 209      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 93185    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.3     |\n",
            "|    explained_variance | 0.844    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18636    |\n",
            "|    policy_loss        | -2.51    |\n",
            "|    std                | 0.92     |\n",
            "|    value_loss         | 0.511    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 113/600: Total Reward = -9.46\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 39.4     |\n",
            "|    ep_rew_mean        | -7.56    |\n",
            "|    success_rate       | 0.27     |\n",
            "| time/                 |          |\n",
            "|    fps                | 203      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 94020    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.26    |\n",
            "|    explained_variance | -6.9     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18803    |\n",
            "|    policy_loss        | -1.71    |\n",
            "|    std                | 0.915    |\n",
            "|    value_loss         | 0.141    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 114/600: Total Reward = -14.84\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 38.6     |\n",
            "|    ep_rew_mean        | -7.52    |\n",
            "|    success_rate       | 0.29     |\n",
            "| time/                 |          |\n",
            "|    fps                | 138      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 94855    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.28    |\n",
            "|    explained_variance | 0.371    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 18970    |\n",
            "|    policy_loss        | 1.7      |\n",
            "|    std                | 0.918    |\n",
            "|    value_loss         | 0.0702   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 115/600: Total Reward = -0.03\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 39       |\n",
            "|    ep_rew_mean        | -7.79    |\n",
            "|    success_rate       | 0.27     |\n",
            "| time/                 |          |\n",
            "|    fps                | 202      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 95690    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.3     |\n",
            "|    explained_variance | -71.7    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19137    |\n",
            "|    policy_loss        | 0.609    |\n",
            "|    std                | 0.922    |\n",
            "|    value_loss         | 0.0187   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 116/600: Total Reward = -13.73\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 39       |\n",
            "|    ep_rew_mean        | -7.77    |\n",
            "|    success_rate       | 0.27     |\n",
            "| time/                 |          |\n",
            "|    fps                | 198      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 96525    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.29    |\n",
            "|    explained_variance | 0.616    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19304    |\n",
            "|    policy_loss        | 0.522    |\n",
            "|    std                | 0.92     |\n",
            "|    value_loss         | 0.00361  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 117/600: Total Reward = -10.46\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 39.3     |\n",
            "|    ep_rew_mean        | -7.75    |\n",
            "|    success_rate       | 0.26     |\n",
            "| time/                 |          |\n",
            "|    fps                | 144      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 97360    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.29    |\n",
            "|    explained_variance | -3.86    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19471    |\n",
            "|    policy_loss        | 5.16     |\n",
            "|    std                | 0.92     |\n",
            "|    value_loss         | 0.395    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 118/600: Total Reward = -10.80\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 40.2     |\n",
            "|    ep_rew_mean        | -7.88    |\n",
            "|    success_rate       | 0.23     |\n",
            "| time/                 |          |\n",
            "|    fps                | 210      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 98195    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.3     |\n",
            "|    explained_variance | -217     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19638    |\n",
            "|    policy_loss        | 0.245    |\n",
            "|    std                | 0.921    |\n",
            "|    value_loss         | 0.00902  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 119/600: Total Reward = -10.71\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 40.6     |\n",
            "|    ep_rew_mean        | -7.91    |\n",
            "|    success_rate       | 0.23     |\n",
            "| time/                 |          |\n",
            "|    fps                | 208      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 99030    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.32    |\n",
            "|    explained_variance | -3.08    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19805    |\n",
            "|    policy_loss        | -6.18    |\n",
            "|    std                | 0.924    |\n",
            "|    value_loss         | 0.401    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 120/600: Total Reward = -1.00\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 41.1     |\n",
            "|    ep_rew_mean        | -7.84    |\n",
            "|    success_rate       | 0.23     |\n",
            "| time/                 |          |\n",
            "|    fps                | 139      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 99865    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.3     |\n",
            "|    explained_variance | 0.511    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 19972    |\n",
            "|    policy_loss        | 22       |\n",
            "|    std                | 0.921    |\n",
            "|    value_loss         | 47.4     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 121/600: Total Reward = -13.90\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 40       |\n",
            "|    ep_rew_mean        | -7.45    |\n",
            "|    success_rate       | 0.26     |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 100700   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.34    |\n",
            "|    explained_variance | 0.547    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 20139    |\n",
            "|    policy_loss        | 3.18     |\n",
            "|    std                | 0.925    |\n",
            "|    value_loss         | 0.112    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 122/600: Total Reward = -9.89\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 40.3     |\n",
            "|    ep_rew_mean        | -7.26    |\n",
            "|    success_rate       | 0.27     |\n",
            "| time/                 |          |\n",
            "|    fps                | 217      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 101535   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.35    |\n",
            "|    explained_variance | -8.36    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 20306    |\n",
            "|    policy_loss        | 4.07     |\n",
            "|    std                | 0.927    |\n",
            "|    value_loss         | 0.185    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 123/600: Total Reward = -4.50\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 41.1     |\n",
            "|    ep_rew_mean        | -7.27    |\n",
            "|    success_rate       | 0.26     |\n",
            "| time/                 |          |\n",
            "|    fps                | 151      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 102370   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.33    |\n",
            "|    explained_variance | -39.6    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 20473    |\n",
            "|    policy_loss        | -1.39    |\n",
            "|    std                | 0.924    |\n",
            "|    value_loss         | 0.0324   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 124/600: Total Reward = -0.05\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 39.9     |\n",
            "|    ep_rew_mean        | -6.73    |\n",
            "|    success_rate       | 0.29     |\n",
            "| time/                 |          |\n",
            "|    fps                | 222      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 103205   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.31    |\n",
            "|    explained_variance | 0.054    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 20640    |\n",
            "|    policy_loss        | 0.389    |\n",
            "|    std                | 0.922    |\n",
            "|    value_loss         | 0.022    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 125/600: Total Reward = -0.16\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 35.8     |\n",
            "|    ep_rew_mean        | -5.59    |\n",
            "|    success_rate       | 0.38     |\n",
            "| time/                 |          |\n",
            "|    fps                | 213      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 104040   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.31    |\n",
            "|    explained_variance | -19.9    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 20807    |\n",
            "|    policy_loss        | -3.6     |\n",
            "|    std                | 0.922    |\n",
            "|    value_loss         | 0.206    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 126/600: Total Reward = -1.52\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.2     |\n",
            "|    ep_rew_mean        | -4       |\n",
            "|    success_rate       | 0.54     |\n",
            "| time/                 |          |\n",
            "|    fps                | 184      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 104875   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.32    |\n",
            "|    explained_variance | -24.1    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 20974    |\n",
            "|    policy_loss        | 156      |\n",
            "|    std                | 0.923    |\n",
            "|    value_loss         | 332      |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 127/600: Total Reward = -7.57\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.4     |\n",
            "|    ep_rew_mean        | -3.74    |\n",
            "|    success_rate       | 0.57     |\n",
            "| time/                 |          |\n",
            "|    fps                | 120      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 105710   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.28    |\n",
            "|    explained_variance | 0.998    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 21141    |\n",
            "|    policy_loss        | -1.53    |\n",
            "|    std                | 0.917    |\n",
            "|    value_loss         | 0.0379   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 128/600: Total Reward = -6.84\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.8     |\n",
            "|    ep_rew_mean        | -4.13    |\n",
            "|    success_rate       | 0.54     |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 106545   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.26    |\n",
            "|    explained_variance | 0.406    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 21308    |\n",
            "|    policy_loss        | -0.0132  |\n",
            "|    std                | 0.915    |\n",
            "|    value_loss         | 0.00891  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 129/600: Total Reward = -8.64\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.9     |\n",
            "|    ep_rew_mean        | -4.37    |\n",
            "|    success_rate       | 0.53     |\n",
            "| time/                 |          |\n",
            "|    fps                | 141      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 107380   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.31    |\n",
            "|    explained_variance | -165     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 21475    |\n",
            "|    policy_loss        | -4.64    |\n",
            "|    std                | 0.922    |\n",
            "|    value_loss         | 0.326    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 130/600: Total Reward = -0.61\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 34.4     |\n",
            "|    ep_rew_mean        | -4.94    |\n",
            "|    success_rate       | 0.45     |\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 108215   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.34    |\n",
            "|    explained_variance | -6.8     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 21642    |\n",
            "|    policy_loss        | -1.27    |\n",
            "|    std                | 0.926    |\n",
            "|    value_loss         | 0.0248   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 131/600: Total Reward = -5.58\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 33.8     |\n",
            "|    ep_rew_mean        | -5       |\n",
            "|    success_rate       | 0.46     |\n",
            "| time/                 |          |\n",
            "|    fps                | 220      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 109050   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.35    |\n",
            "|    explained_variance | 0.822    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 21809    |\n",
            "|    policy_loss        | 0.48     |\n",
            "|    std                | 0.928    |\n",
            "|    value_loss         | 0.00381  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 132/600: Total Reward = -0.55\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29       |\n",
            "|    ep_rew_mean        | -4       |\n",
            "|    success_rate       | 0.58     |\n",
            "| time/                 |          |\n",
            "|    fps                | 172      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 109885   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.4     |\n",
            "|    explained_variance | -1.83    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 21976    |\n",
            "|    policy_loss        | -2.9     |\n",
            "|    std                | 0.933    |\n",
            "|    value_loss         | 0.206    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 133/600: Total Reward = -4.09\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.4     |\n",
            "|    ep_rew_mean        | -3.36    |\n",
            "|    success_rate       | 0.66     |\n",
            "| time/                 |          |\n",
            "|    fps                | 219      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 110720   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.38    |\n",
            "|    explained_variance | -0.973   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 22143    |\n",
            "|    policy_loss        | -1.01    |\n",
            "|    std                | 0.93     |\n",
            "|    value_loss         | 0.0261   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 134/600: Total Reward = -0.36\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.1     |\n",
            "|    ep_rew_mean        | -3.27    |\n",
            "|    success_rate       | 0.65     |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 111555   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.36    |\n",
            "|    explained_variance | -1.43    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 22310    |\n",
            "|    policy_loss        | -0.895   |\n",
            "|    std                | 0.928    |\n",
            "|    value_loss         | 0.0205   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 135/600: Total Reward = -5.93\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.4     |\n",
            "|    ep_rew_mean        | -3.42    |\n",
            "|    success_rate       | 0.61     |\n",
            "| time/                 |          |\n",
            "|    fps                | 181      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 112390   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.35    |\n",
            "|    explained_variance | -1.23    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 22477    |\n",
            "|    policy_loss        | 3.9      |\n",
            "|    std                | 0.926    |\n",
            "|    value_loss         | 0.184    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 136/600: Total Reward = -7.18\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.2     |\n",
            "|    ep_rew_mean        | -3.74    |\n",
            "|    success_rate       | 0.56     |\n",
            "| time/                 |          |\n",
            "|    fps                | 208      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 113225   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.32    |\n",
            "|    explained_variance | -7.25    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 22644    |\n",
            "|    policy_loss        | 2.34     |\n",
            "|    std                | 0.923    |\n",
            "|    value_loss         | 0.122    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 137/600: Total Reward = -1.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.9     |\n",
            "|    ep_rew_mean        | -3.72    |\n",
            "|    success_rate       | 0.56     |\n",
            "| time/                 |          |\n",
            "|    fps                | 223      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 114060   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.33    |\n",
            "|    explained_variance | -156     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 22811    |\n",
            "|    policy_loss        | 0.454    |\n",
            "|    std                | 0.923    |\n",
            "|    value_loss         | 0.021    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 138/600: Total Reward = -4.70\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.4     |\n",
            "|    ep_rew_mean        | -3.36    |\n",
            "|    success_rate       | 0.63     |\n",
            "| time/                 |          |\n",
            "|    fps                | 222      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 114895   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.28    |\n",
            "|    explained_variance | -285     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 22978    |\n",
            "|    policy_loss        | -4.06    |\n",
            "|    std                | 0.917    |\n",
            "|    value_loss         | 0.48     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 139/600: Total Reward = -0.32\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.7     |\n",
            "|    ep_rew_mean        | -3.24    |\n",
            "|    success_rate       | 0.66     |\n",
            "| time/                 |          |\n",
            "|    fps                | 161      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 115730   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.29    |\n",
            "|    explained_variance | -15      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 23145    |\n",
            "|    policy_loss        | 3.55     |\n",
            "|    std                | 0.918    |\n",
            "|    value_loss         | 0.196    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 140/600: Total Reward = -1.74\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.2     |\n",
            "|    ep_rew_mean        | -3.04    |\n",
            "|    success_rate       | 0.67     |\n",
            "| time/                 |          |\n",
            "|    fps                | 224      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 116565   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.29    |\n",
            "|    explained_variance | -1.83    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 23312    |\n",
            "|    policy_loss        | 119      |\n",
            "|    std                | 0.919    |\n",
            "|    value_loss         | 137      |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 141/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.3     |\n",
            "|    ep_rew_mean        | -3.01    |\n",
            "|    success_rate       | 0.68     |\n",
            "| time/                 |          |\n",
            "|    fps                | 223      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 117400   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.26    |\n",
            "|    explained_variance | -1.11    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 23479    |\n",
            "|    policy_loss        | 0.561    |\n",
            "|    std                | 0.915    |\n",
            "|    value_loss         | 0.00464  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 142/600: Total Reward = -0.22\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.7     |\n",
            "|    ep_rew_mean        | -2.75    |\n",
            "|    success_rate       | 0.7      |\n",
            "| time/                 |          |\n",
            "|    fps                | 167      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 118235   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.21    |\n",
            "|    explained_variance | -18.4    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 23646    |\n",
            "|    policy_loss        | 0.984    |\n",
            "|    std                | 0.909    |\n",
            "|    value_loss         | 0.0111   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 143/600: Total Reward = -0.25\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.1     |\n",
            "|    ep_rew_mean        | -2.8     |\n",
            "|    success_rate       | 0.72     |\n",
            "| time/                 |          |\n",
            "|    fps                | 229      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 119070   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.23    |\n",
            "|    explained_variance | -5.45    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 23813    |\n",
            "|    policy_loss        | -3.3     |\n",
            "|    std                | 0.911    |\n",
            "|    value_loss         | 0.165    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 144/600: Total Reward = -0.17\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.4     |\n",
            "|    ep_rew_mean        | -3.13    |\n",
            "|    success_rate       | 0.65     |\n",
            "| time/                 |          |\n",
            "|    fps                | 229      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 119905   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.24    |\n",
            "|    explained_variance | -196     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 23980    |\n",
            "|    policy_loss        | -3.71    |\n",
            "|    std                | 0.912    |\n",
            "|    value_loss         | 0.179    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 145/600: Total Reward = -9.82\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.4     |\n",
            "|    ep_rew_mean        | -3.39    |\n",
            "|    success_rate       | 0.61     |\n",
            "| time/                 |          |\n",
            "|    fps                | 217      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 120740   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.23    |\n",
            "|    explained_variance | 0.293    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 24147    |\n",
            "|    policy_loss        | -0.371   |\n",
            "|    std                | 0.912    |\n",
            "|    value_loss         | 0.0107   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 146/600: Total Reward = -3.93\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.6     |\n",
            "|    ep_rew_mean        | -3.8     |\n",
            "|    success_rate       | 0.58     |\n",
            "| time/                 |          |\n",
            "|    fps                | 170      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 121575   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.21    |\n",
            "|    explained_variance | -2.33    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 24314    |\n",
            "|    policy_loss        | 140      |\n",
            "|    std                | 0.91     |\n",
            "|    value_loss         | 242      |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 147/600: Total Reward = -0.23\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.5     |\n",
            "|    ep_rew_mean        | -3.85    |\n",
            "|    success_rate       | 0.59     |\n",
            "| time/                 |          |\n",
            "|    fps                | 218      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 122410   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.21    |\n",
            "|    explained_variance | -32.9    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 24481    |\n",
            "|    policy_loss        | -1.25    |\n",
            "|    std                | 0.909    |\n",
            "|    value_loss         | 0.0207   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 148/600: Total Reward = -8.44\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.8     |\n",
            "|    ep_rew_mean        | -3.81    |\n",
            "|    success_rate       | 0.62     |\n",
            "| time/                 |          |\n",
            "|    fps                | 217      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 123245   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.22    |\n",
            "|    explained_variance | -29.7    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 24648    |\n",
            "|    policy_loss        | -1.45    |\n",
            "|    std                | 0.911    |\n",
            "|    value_loss         | 0.0323   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 149/600: Total Reward = -5.01\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.4     |\n",
            "|    ep_rew_mean        | -3.93    |\n",
            "|    success_rate       | 0.6      |\n",
            "| time/                 |          |\n",
            "|    fps                | 149      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 124080   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.19    |\n",
            "|    explained_variance | -46.7    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 24815    |\n",
            "|    policy_loss        | -0.0429  |\n",
            "|    std                | 0.908    |\n",
            "|    value_loss         | 0.0296   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 150/600: Total Reward = -3.65\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.3     |\n",
            "|    ep_rew_mean        | -3.83    |\n",
            "|    success_rate       | 0.58     |\n",
            "| time/                 |          |\n",
            "|    fps                | 218      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 124915   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.18    |\n",
            "|    explained_variance | -7.55    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 24982    |\n",
            "|    policy_loss        | 2.35     |\n",
            "|    std                | 0.905    |\n",
            "|    value_loss         | 0.0923   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 151/600: Total Reward = -0.45\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30       |\n",
            "|    ep_rew_mean        | -3.76    |\n",
            "|    success_rate       | 0.58     |\n",
            "| time/                 |          |\n",
            "|    fps                | 221      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 125750   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.19    |\n",
            "|    explained_variance | 0.649    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 25149    |\n",
            "|    policy_loss        | -0.44    |\n",
            "|    std                | 0.906    |\n",
            "|    value_loss         | 0.00379  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 152/600: Total Reward = -0.17\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.5     |\n",
            "|    ep_rew_mean        | -3.6     |\n",
            "|    success_rate       | 0.59     |\n",
            "| time/                 |          |\n",
            "|    fps                | 150      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 126585   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.19    |\n",
            "|    explained_variance | -13.1    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 25316    |\n",
            "|    policy_loss        | 0.31     |\n",
            "|    std                | 0.907    |\n",
            "|    value_loss         | 0.036    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 153/600: Total Reward = -5.73\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.1     |\n",
            "|    ep_rew_mean        | -3.73    |\n",
            "|    success_rate       | 0.58     |\n",
            "| time/                 |          |\n",
            "|    fps                | 211      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 127420   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.19    |\n",
            "|    explained_variance | 0.611    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 25483    |\n",
            "|    policy_loss        | -3.52    |\n",
            "|    std                | 0.907    |\n",
            "|    value_loss         | 0.136    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 154/600: Total Reward = -0.20\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.4     |\n",
            "|    ep_rew_mean        | -3.1     |\n",
            "|    success_rate       | 0.67     |\n",
            "| time/                 |          |\n",
            "|    fps                | 219      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 128255   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.2     |\n",
            "|    explained_variance | -0.636   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 25650    |\n",
            "|    policy_loss        | -0.749   |\n",
            "|    std                | 0.91     |\n",
            "|    value_loss         | 0.0138   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 155/600: Total Reward = -6.30\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.2     |\n",
            "|    ep_rew_mean        | -3.21    |\n",
            "|    success_rate       | 0.66     |\n",
            "| time/                 |          |\n",
            "|    fps                | 170      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 129090   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.19    |\n",
            "|    explained_variance | -23      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 25817    |\n",
            "|    policy_loss        | -1.96    |\n",
            "|    std                | 0.907    |\n",
            "|    value_loss         | 0.05     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 156/600: Total Reward = -0.39\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.6     |\n",
            "|    ep_rew_mean        | -3.27    |\n",
            "|    success_rate       | 0.67     |\n",
            "| time/                 |          |\n",
            "|    fps                | 225      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 129925   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.16    |\n",
            "|    explained_variance | -223     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 25984    |\n",
            "|    policy_loss        | 0.92     |\n",
            "|    std                | 0.903    |\n",
            "|    value_loss         | 0.0542   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 157/600: Total Reward = -6.43\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.1     |\n",
            "|    ep_rew_mean        | -3.8     |\n",
            "|    success_rate       | 0.58     |\n",
            "| time/                 |          |\n",
            "|    fps                | 221      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 130760   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.2     |\n",
            "|    explained_variance | 0.319    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 26151    |\n",
            "|    policy_loss        | -0.288   |\n",
            "|    std                | 0.908    |\n",
            "|    value_loss         | 0.00271  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 158/600: Total Reward = -5.47\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.1     |\n",
            "|    ep_rew_mean        | -4.05    |\n",
            "|    success_rate       | 0.57     |\n",
            "| time/                 |          |\n",
            "|    fps                | 223      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 131595   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.14    |\n",
            "|    explained_variance | -30.1    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 26318    |\n",
            "|    policy_loss        | 0.394    |\n",
            "|    std                | 0.9      |\n",
            "|    value_loss         | 0.0195   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 159/600: Total Reward = -4.66\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.4     |\n",
            "|    ep_rew_mean        | -4.35    |\n",
            "|    success_rate       | 0.51     |\n",
            "| time/                 |          |\n",
            "|    fps                | 164      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 132430   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.15    |\n",
            "|    explained_variance | -32.4    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 26485    |\n",
            "|    policy_loss        | -1.42    |\n",
            "|    std                | 0.903    |\n",
            "|    value_loss         | 0.0771   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 160/600: Total Reward = -10.42\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.4     |\n",
            "|    ep_rew_mean        | -4.15    |\n",
            "|    success_rate       | 0.55     |\n",
            "| time/                 |          |\n",
            "|    fps                | 212      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 133265   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.17    |\n",
            "|    explained_variance | -2.2     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 26652    |\n",
            "|    policy_loss        | -0.983   |\n",
            "|    std                | 0.905    |\n",
            "|    value_loss         | 0.0579   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 161/600: Total Reward = -11.57\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.5     |\n",
            "|    ep_rew_mean        | -4.11    |\n",
            "|    success_rate       | 0.55     |\n",
            "| time/                 |          |\n",
            "|    fps                | 218      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 134100   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.15    |\n",
            "|    explained_variance | -17      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 26819    |\n",
            "|    policy_loss        | 1.21     |\n",
            "|    std                | 0.903    |\n",
            "|    value_loss         | 0.0383   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 162/600: Total Reward = -8.97\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 32.7     |\n",
            "|    ep_rew_mean        | -4.94    |\n",
            "|    success_rate       | 0.43     |\n",
            "| time/                 |          |\n",
            "|    fps                | 149      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 134935   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.17    |\n",
            "|    explained_variance | -185     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 26986    |\n",
            "|    policy_loss        | 2.11     |\n",
            "|    std                | 0.905    |\n",
            "|    value_loss         | 0.0897   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 163/600: Total Reward = -0.03\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 31.7     |\n",
            "|    ep_rew_mean        | -4.66    |\n",
            "|    success_rate       | 0.46     |\n",
            "| time/                 |          |\n",
            "|    fps                | 219      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 135770   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.17    |\n",
            "|    explained_variance | -1.72    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 27153    |\n",
            "|    policy_loss        | -1.94    |\n",
            "|    std                | 0.905    |\n",
            "|    value_loss         | 0.0464   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 164/600: Total Reward = -9.47\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 34.2     |\n",
            "|    ep_rew_mean        | -4.87    |\n",
            "|    success_rate       | 0.41     |\n",
            "| time/                 |          |\n",
            "|    fps                | 204      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 136605   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.18    |\n",
            "|    explained_variance | -1.86    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 27320    |\n",
            "|    policy_loss        | 3.43     |\n",
            "|    std                | 0.906    |\n",
            "|    value_loss         | 0.143    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 165/600: Total Reward = -3.94\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 33.6     |\n",
            "|    ep_rew_mean        | -4.7     |\n",
            "|    success_rate       | 0.42     |\n",
            "| time/                 |          |\n",
            "|    fps                | 133      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 137440   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.2     |\n",
            "|    explained_variance | 0.91     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 27487    |\n",
            "|    policy_loss        | -1.86    |\n",
            "|    std                | 0.909    |\n",
            "|    value_loss         | 0.0335   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 166/600: Total Reward = -8.33\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 32.6     |\n",
            "|    ep_rew_mean        | -4.28    |\n",
            "|    success_rate       | 0.49     |\n",
            "| time/                 |          |\n",
            "|    fps                | 209      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 138275   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.21    |\n",
            "|    explained_variance | -110     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 27654    |\n",
            "|    policy_loss        | -2.94    |\n",
            "|    std                | 0.912    |\n",
            "|    value_loss         | 0.145    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 167/600: Total Reward = -0.54\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.8     |\n",
            "|    ep_rew_mean        | -3.8     |\n",
            "|    success_rate       | 0.55     |\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 139110   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.21    |\n",
            "|    explained_variance | -9.12    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 27821    |\n",
            "|    policy_loss        | 0.831    |\n",
            "|    std                | 0.912    |\n",
            "|    value_loss         | 0.0164   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 168/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 32.9     |\n",
            "|    ep_rew_mean        | -3.96    |\n",
            "|    success_rate       | 0.5      |\n",
            "| time/                 |          |\n",
            "|    fps                | 143      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 139945   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.21    |\n",
            "|    explained_variance | -0.0492  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 27988    |\n",
            "|    policy_loss        | -0.601   |\n",
            "|    std                | 0.912    |\n",
            "|    value_loss         | 0.00722  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 169/600: Total Reward = -5.09\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 34       |\n",
            "|    ep_rew_mean        | -4.02    |\n",
            "|    success_rate       | 0.49     |\n",
            "| time/                 |          |\n",
            "|    fps                | 206      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 140780   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.19    |\n",
            "|    explained_variance | -24.4    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 28155    |\n",
            "|    policy_loss        | -0.982   |\n",
            "|    std                | 0.909    |\n",
            "|    value_loss         | 0.015    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 170/600: Total Reward = -7.87\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 31.7     |\n",
            "|    ep_rew_mean        | -3.88    |\n",
            "|    success_rate       | 0.51     |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 141615   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.18    |\n",
            "|    explained_variance | 0.0474   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 28322    |\n",
            "|    policy_loss        | 19.4     |\n",
            "|    std                | 0.908    |\n",
            "|    value_loss         | 31.3     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 171/600: Total Reward = -7.94\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 33.4     |\n",
            "|    ep_rew_mean        | -4.23    |\n",
            "|    success_rate       | 0.45     |\n",
            "| time/                 |          |\n",
            "|    fps                | 151      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 142450   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.21    |\n",
            "|    explained_variance | 0.521    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 28489    |\n",
            "|    policy_loss        | 0.0945   |\n",
            "|    std                | 0.912    |\n",
            "|    value_loss         | 0.000956 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 172/600: Total Reward = -0.49\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 34.5     |\n",
            "|    ep_rew_mean        | -4.6     |\n",
            "|    success_rate       | 0.42     |\n",
            "| time/                 |          |\n",
            "|    fps                | 219      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 143285   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.25    |\n",
            "|    explained_variance | -0.887   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 28656    |\n",
            "|    policy_loss        | 0.259    |\n",
            "|    std                | 0.917    |\n",
            "|    value_loss         | 0.00196  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 173/600: Total Reward = -5.48\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 31.9     |\n",
            "|    ep_rew_mean        | -4.29    |\n",
            "|    success_rate       | 0.47     |\n",
            "| time/                 |          |\n",
            "|    fps                | 203      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 144120   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.2     |\n",
            "|    explained_variance | -1.25    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 28823    |\n",
            "|    policy_loss        | -0.0338  |\n",
            "|    std                | 0.911    |\n",
            "|    value_loss         | 0.00284  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 174/600: Total Reward = -4.49\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 33       |\n",
            "|    ep_rew_mean        | -4.23    |\n",
            "|    success_rate       | 0.45     |\n",
            "| time/                 |          |\n",
            "|    fps                | 164      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 144955   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.2     |\n",
            "|    explained_variance | -25.8    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 28990    |\n",
            "|    policy_loss        | -0.531   |\n",
            "|    std                | 0.91     |\n",
            "|    value_loss         | 0.00659  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 175/600: Total Reward = -5.97\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 32.9     |\n",
            "|    ep_rew_mean        | -4.17    |\n",
            "|    success_rate       | 0.46     |\n",
            "| time/                 |          |\n",
            "|    fps                | 221      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 145790   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.2     |\n",
            "|    explained_variance | -5.56    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 29157    |\n",
            "|    policy_loss        | -0.733   |\n",
            "|    std                | 0.91     |\n",
            "|    value_loss         | 0.00726  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 176/600: Total Reward = -6.69\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 31.2     |\n",
            "|    ep_rew_mean        | -3.78    |\n",
            "|    success_rate       | 0.49     |\n",
            "| time/                 |          |\n",
            "|    fps                | 221      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 146625   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.19    |\n",
            "|    explained_variance | -0.676   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 29324    |\n",
            "|    policy_loss        | 0.691    |\n",
            "|    std                | 0.909    |\n",
            "|    value_loss         | 0.00542  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 177/600: Total Reward = -4.37\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30       |\n",
            "|    ep_rew_mean        | -3.63    |\n",
            "|    success_rate       | 0.53     |\n",
            "| time/                 |          |\n",
            "|    fps                | 198      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 147460   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.18    |\n",
            "|    explained_variance | 0.752    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 29491    |\n",
            "|    policy_loss        | 0.533    |\n",
            "|    std                | 0.908    |\n",
            "|    value_loss         | 0.00556  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 178/600: Total Reward = -0.09\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.2     |\n",
            "|    ep_rew_mean        | -3.42    |\n",
            "|    success_rate       | 0.59     |\n",
            "| time/                 |          |\n",
            "|    fps                | 175      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 148295   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.16    |\n",
            "|    explained_variance | -0.436   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 29658    |\n",
            "|    policy_loss        | 1.04     |\n",
            "|    std                | 0.906    |\n",
            "|    value_loss         | 0.0126   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 179/600: Total Reward = -6.74\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29       |\n",
            "|    ep_rew_mean        | -3.63    |\n",
            "|    success_rate       | 0.55     |\n",
            "| time/                 |          |\n",
            "|    fps                | 207      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 149130   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.15    |\n",
            "|    explained_variance | -1.37    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 29825    |\n",
            "|    policy_loss        | 0.507    |\n",
            "|    std                | 0.904    |\n",
            "|    value_loss         | 0.00912  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 180/600: Total Reward = -0.80\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.7     |\n",
            "|    ep_rew_mean        | -3.52    |\n",
            "|    success_rate       | 0.58     |\n",
            "| time/                 |          |\n",
            "|    fps                | 160      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 149965   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.13    |\n",
            "|    explained_variance | -0.169   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 29992    |\n",
            "|    policy_loss        | 0.41     |\n",
            "|    std                | 0.901    |\n",
            "|    value_loss         | 0.00248  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 181/600: Total Reward = -6.43\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.7     |\n",
            "|    ep_rew_mean        | -3.8     |\n",
            "|    success_rate       | 0.55     |\n",
            "| time/                 |          |\n",
            "|    fps                | 170      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 150800   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.12    |\n",
            "|    explained_variance | 0.993    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 30159    |\n",
            "|    policy_loss        | -0.0252  |\n",
            "|    std                | 0.901    |\n",
            "|    value_loss         | 0.0135   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 182/600: Total Reward = -7.46\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.5     |\n",
            "|    ep_rew_mean        | -3.83    |\n",
            "|    success_rate       | 0.54     |\n",
            "| time/                 |          |\n",
            "|    fps                | 214      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 151635   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.11    |\n",
            "|    explained_variance | -16.7    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 30326    |\n",
            "|    policy_loss        | -1.08    |\n",
            "|    std                | 0.899    |\n",
            "|    value_loss         | 0.0222   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 183/600: Total Reward = -5.67\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30       |\n",
            "|    ep_rew_mean        | -3.66    |\n",
            "|    success_rate       | 0.55     |\n",
            "| time/                 |          |\n",
            "|    fps                | 203      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 152470   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.16    |\n",
            "|    explained_variance | 0.257    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 30493    |\n",
            "|    policy_loss        | -0.514   |\n",
            "|    std                | 0.905    |\n",
            "|    value_loss         | 0.00442  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 184/600: Total Reward = -2.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 31.4     |\n",
            "|    ep_rew_mean        | -3.87    |\n",
            "|    success_rate       | 0.5      |\n",
            "| time/                 |          |\n",
            "|    fps                | 158      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 153305   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.14    |\n",
            "|    explained_variance | -122     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 30660    |\n",
            "|    policy_loss        | -1.05    |\n",
            "|    std                | 0.904    |\n",
            "|    value_loss         | 0.0233   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 185/600: Total Reward = -0.91\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.9     |\n",
            "|    ep_rew_mean        | -3.71    |\n",
            "|    success_rate       | 0.52     |\n",
            "| time/                 |          |\n",
            "|    fps                | 152      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 154140   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.16    |\n",
            "|    explained_variance | 0.943    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 30827    |\n",
            "|    policy_loss        | -0.321   |\n",
            "|    std                | 0.908    |\n",
            "|    value_loss         | 0.00713  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 186/600: Total Reward = -1.05\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 32       |\n",
            "|    ep_rew_mean        | -3.82    |\n",
            "|    success_rate       | 0.5      |\n",
            "| time/                 |          |\n",
            "|    fps                | 193      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 154975   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.15    |\n",
            "|    explained_variance | -13.4    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 30994    |\n",
            "|    policy_loss        | 0.985    |\n",
            "|    std                | 0.907    |\n",
            "|    value_loss         | 0.0176   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 187/600: Total Reward = -1.71\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.8     |\n",
            "|    ep_rew_mean        | -3.52    |\n",
            "|    success_rate       | 0.58     |\n",
            "| time/                 |          |\n",
            "|    fps                | 167      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 155810   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.19    |\n",
            "|    explained_variance | 0.218    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 31161    |\n",
            "|    policy_loss        | 0.242    |\n",
            "|    std                | 0.911    |\n",
            "|    value_loss         | 0.00146  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 188/600: Total Reward = -8.53\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.4     |\n",
            "|    ep_rew_mean        | -3.39    |\n",
            "|    success_rate       | 0.59     |\n",
            "| time/                 |          |\n",
            "|    fps                | 209      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 156645   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.2     |\n",
            "|    explained_variance | -2.6     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 31328    |\n",
            "|    policy_loss        | -1.3     |\n",
            "|    std                | 0.913    |\n",
            "|    value_loss         | 0.019    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 189/600: Total Reward = -0.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.1     |\n",
            "|    ep_rew_mean        | -2.97    |\n",
            "|    success_rate       | 0.66     |\n",
            "| time/                 |          |\n",
            "|    fps                | 216      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 157480   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.2     |\n",
            "|    explained_variance | -6.81    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 31495    |\n",
            "|    policy_loss        | 0.956    |\n",
            "|    std                | 0.914    |\n",
            "|    value_loss         | 0.0172   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 190/600: Total Reward = -0.82\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.1     |\n",
            "|    ep_rew_mean        | -3.07    |\n",
            "|    success_rate       | 0.66     |\n",
            "| time/                 |          |\n",
            "|    fps                | 147      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 158315   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.19    |\n",
            "|    explained_variance | -5.06    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 31662    |\n",
            "|    policy_loss        | 1.43     |\n",
            "|    std                | 0.912    |\n",
            "|    value_loss         | 0.029    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 191/600: Total Reward = -0.42\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.2     |\n",
            "|    ep_rew_mean        | -3.17    |\n",
            "|    success_rate       | 0.67     |\n",
            "| time/                 |          |\n",
            "|    fps                | 207      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 159150   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.17    |\n",
            "|    explained_variance | 0.105    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 31829    |\n",
            "|    policy_loss        | -0.962   |\n",
            "|    std                | 0.908    |\n",
            "|    value_loss         | 0.0161   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 192/600: Total Reward = -3.29\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26       |\n",
            "|    ep_rew_mean        | -3.57    |\n",
            "|    success_rate       | 0.67     |\n",
            "| time/                 |          |\n",
            "|    fps                | 215      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 159985   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.2     |\n",
            "|    explained_variance | 0.715    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 31996    |\n",
            "|    policy_loss        | 2        |\n",
            "|    std                | 0.912    |\n",
            "|    value_loss         | 0.0532   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 193/600: Total Reward = -0.25\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 22.6     |\n",
            "|    ep_rew_mean        | -3.14    |\n",
            "|    success_rate       | 0.71     |\n",
            "| time/                 |          |\n",
            "|    fps                | 133      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 160820   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.17    |\n",
            "|    explained_variance | 0.0889   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 32163    |\n",
            "|    policy_loss        | -5.43    |\n",
            "|    std                | 0.907    |\n",
            "|    value_loss         | 0.34     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 194/600: Total Reward = -0.89\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 21.9     |\n",
            "|    ep_rew_mean        | -2.79    |\n",
            "|    success_rate       | 0.71     |\n",
            "| time/                 |          |\n",
            "|    fps                | 204      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 161655   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.23    |\n",
            "|    explained_variance | -1.19    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 32330    |\n",
            "|    policy_loss        | -0.728   |\n",
            "|    std                | 0.915    |\n",
            "|    value_loss         | 0.0132   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 195/600: Total Reward = -5.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 21.6     |\n",
            "|    ep_rew_mean        | -2.29    |\n",
            "|    success_rate       | 0.74     |\n",
            "| time/                 |          |\n",
            "|    fps                | 212      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 162490   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.21    |\n",
            "|    explained_variance | -0.883   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 32497    |\n",
            "|    policy_loss        | -1.26    |\n",
            "|    std                | 0.913    |\n",
            "|    value_loss         | 0.0244   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 196/600: Total Reward = -7.71\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 23.7     |\n",
            "|    ep_rew_mean        | -2.51    |\n",
            "|    success_rate       | 0.69     |\n",
            "| time/                 |          |\n",
            "|    fps                | 143      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 163325   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.23    |\n",
            "|    explained_variance | -1.13    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 32664    |\n",
            "|    policy_loss        | 0.423    |\n",
            "|    std                | 0.914    |\n",
            "|    value_loss         | 0.00275  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 197/600: Total Reward = -2.45\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.7     |\n",
            "|    ep_rew_mean        | -3.06    |\n",
            "|    success_rate       | 0.6      |\n",
            "| time/                 |          |\n",
            "|    fps                | 208      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 164160   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.22    |\n",
            "|    explained_variance | -1.64    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 32831    |\n",
            "|    policy_loss        | -0.102   |\n",
            "|    std                | 0.913    |\n",
            "|    value_loss         | 0.000892 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 198/600: Total Reward = -0.22\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 27.9     |\n",
            "|    ep_rew_mean        | -3.19    |\n",
            "|    success_rate       | 0.59     |\n",
            "| time/                 |          |\n",
            "|    fps                | 211      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 164995   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.21    |\n",
            "|    explained_variance | -7.11    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 32998    |\n",
            "|    policy_loss        | -0.192   |\n",
            "|    std                | 0.911    |\n",
            "|    value_loss         | 0.00255  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 199/600: Total Reward = -0.80\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 26.9     |\n",
            "|    ep_rew_mean        | -3.11    |\n",
            "|    success_rate       | 0.6      |\n",
            "| time/                 |          |\n",
            "|    fps                | 158      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 165830   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.23    |\n",
            "|    explained_variance | -3.37    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 33165    |\n",
            "|    policy_loss        | -0.2     |\n",
            "|    std                | 0.914    |\n",
            "|    value_loss         | 0.00918  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 200/600: Total Reward = -4.66\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 20.4     |\n",
            "|    ep_rew_mean        | -2.25    |\n",
            "|    success_rate       | 0.75     |\n",
            "| time/                 |          |\n",
            "|    fps                | 198      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 166665   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.24    |\n",
            "|    explained_variance | -2.04    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 33332    |\n",
            "|    policy_loss        | -0.322   |\n",
            "|    std                | 0.914    |\n",
            "|    value_loss         | 0.00257  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 201/600: Total Reward = -6.81\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 21.1     |\n",
            "|    ep_rew_mean        | -2.33    |\n",
            "|    success_rate       | 0.74     |\n",
            "| time/                 |          |\n",
            "|    fps                | 187      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 167500   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.23    |\n",
            "|    explained_variance | 0.986    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 33499    |\n",
            "|    policy_loss        | 0.575    |\n",
            "|    std                | 0.913    |\n",
            "|    value_loss         | 0.0189   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 202/600: Total Reward = -3.75\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 20.6     |\n",
            "|    ep_rew_mean        | -2.26    |\n",
            "|    success_rate       | 0.72     |\n",
            "| time/                 |          |\n",
            "|    fps                | 154      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 168335   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.22    |\n",
            "|    explained_variance | 0.952    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 33666    |\n",
            "|    policy_loss        | 0.714    |\n",
            "|    std                | 0.911    |\n",
            "|    value_loss         | 0.0098   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 203/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.4     |\n",
            "|    ep_rew_mean        | -2.62    |\n",
            "|    success_rate       | 0.67     |\n",
            "| time/                 |          |\n",
            "|    fps                | 196      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 169170   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.22    |\n",
            "|    explained_variance | -1.15    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 33833    |\n",
            "|    policy_loss        | 0.0607   |\n",
            "|    std                | 0.912    |\n",
            "|    value_loss         | 0.00175  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 204/600: Total Reward = -6.29\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.6     |\n",
            "|    ep_rew_mean        | -2.56    |\n",
            "|    success_rate       | 0.7      |\n",
            "| time/                 |          |\n",
            "|    fps                | 204      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 170005   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.21    |\n",
            "|    explained_variance | -3.51    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 34000    |\n",
            "|    policy_loss        | 0.171    |\n",
            "|    std                | 0.91     |\n",
            "|    value_loss         | 0.00235  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 205/600: Total Reward = -1.71\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.3     |\n",
            "|    ep_rew_mean        | -2.43    |\n",
            "|    success_rate       | 0.76     |\n",
            "| time/                 |          |\n",
            "|    fps                | 155      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 170840   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.17    |\n",
            "|    explained_variance | -22.2    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 34167    |\n",
            "|    policy_loss        | 0.67     |\n",
            "|    std                | 0.905    |\n",
            "|    value_loss         | 0.00704  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 206/600: Total Reward = -0.18\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 20.4     |\n",
            "|    ep_rew_mean        | -2       |\n",
            "|    success_rate       | 0.83     |\n",
            "| time/                 |          |\n",
            "|    fps                | 200      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 171675   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.15    |\n",
            "|    explained_variance | -5.58    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 34334    |\n",
            "|    policy_loss        | -0.165   |\n",
            "|    std                | 0.902    |\n",
            "|    value_loss         | 0.00268  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 207/600: Total Reward = -0.40\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 19.1     |\n",
            "|    ep_rew_mean        | -1.79    |\n",
            "|    success_rate       | 0.85     |\n",
            "| time/                 |          |\n",
            "|    fps                | 155      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 172510   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.12    |\n",
            "|    explained_variance | -2.41    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 34501    |\n",
            "|    policy_loss        | -0.146   |\n",
            "|    std                | 0.899    |\n",
            "|    value_loss         | 0.00391  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 208/600: Total Reward = -0.65\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 19       |\n",
            "|    ep_rew_mean        | -1.81    |\n",
            "|    success_rate       | 0.85     |\n",
            "| time/                 |          |\n",
            "|    fps                | 145      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 173345   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.1     |\n",
            "|    explained_variance | 0.374    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 34668    |\n",
            "|    policy_loss        | 13.3     |\n",
            "|    std                | 0.898    |\n",
            "|    value_loss         | 4.35     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 209/600: Total Reward = -0.48\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 14.1     |\n",
            "|    ep_rew_mean        | -1.28    |\n",
            "|    success_rate       | 0.97     |\n",
            "| time/                 |          |\n",
            "|    fps                | 203      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 174180   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.08    |\n",
            "|    explained_variance | -1.16    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 34835    |\n",
            "|    policy_loss        | -1.22    |\n",
            "|    std                | 0.894    |\n",
            "|    value_loss         | 0.0206   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 210/600: Total Reward = -0.93\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 15.1     |\n",
            "|    ep_rew_mean        | -1.34    |\n",
            "|    success_rate       | 0.93     |\n",
            "| time/                 |          |\n",
            "|    fps                | 197      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 175015   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.08    |\n",
            "|    explained_variance | 0.668    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 35002    |\n",
            "|    policy_loss        | 25.6     |\n",
            "|    std                | 0.895    |\n",
            "|    value_loss         | 7.78     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 211/600: Total Reward = -5.91\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 11.7     |\n",
            "|    ep_rew_mean        | -1.04    |\n",
            "|    success_rate       | 0.97     |\n",
            "| time/                 |          |\n",
            "|    fps                | 147      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 175850   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.08    |\n",
            "|    explained_variance | -0.525   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 35169    |\n",
            "|    policy_loss        | -0.53    |\n",
            "|    std                | 0.893    |\n",
            "|    value_loss         | 0.0172   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 212/600: Total Reward = -0.94\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 11.4     |\n",
            "|    ep_rew_mean        | -1.11    |\n",
            "|    success_rate       | 0.93     |\n",
            "| time/                 |          |\n",
            "|    fps                | 203      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 176685   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.06    |\n",
            "|    explained_variance | -5.3     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 35336    |\n",
            "|    policy_loss        | -2.93    |\n",
            "|    std                | 0.891    |\n",
            "|    value_loss         | 0.103    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 213/600: Total Reward = -0.78\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 12.1     |\n",
            "|    ep_rew_mean        | -1.12    |\n",
            "|    success_rate       | 0.92     |\n",
            "| time/                 |          |\n",
            "|    fps                | 201      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 177520   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.1     |\n",
            "|    explained_variance | -30.6    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 35503    |\n",
            "|    policy_loss        | 1.19     |\n",
            "|    std                | 0.896    |\n",
            "|    value_loss         | 0.0404   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 214/600: Total Reward = -0.28\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 15.5     |\n",
            "|    ep_rew_mean        | -1.67    |\n",
            "|    success_rate       | 0.82     |\n",
            "| time/                 |          |\n",
            "|    fps                | 155      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 178355   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.1     |\n",
            "|    explained_variance | -1.47    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 35670    |\n",
            "|    policy_loss        | 0.116    |\n",
            "|    std                | 0.896    |\n",
            "|    value_loss         | 0.00293  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 215/600: Total Reward = -6.69\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 21.6     |\n",
            "|    ep_rew_mean        | -2.62    |\n",
            "|    success_rate       | 0.69     |\n",
            "| time/                 |          |\n",
            "|    fps                | 204      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 179190   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.02    |\n",
            "|    explained_variance | -61.5    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 35837    |\n",
            "|    policy_loss        | -2.72    |\n",
            "|    std                | 0.885    |\n",
            "|    value_loss         | 0.244    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 216/600: Total Reward = -1.50\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 23.9     |\n",
            "|    ep_rew_mean        | -2.94    |\n",
            "|    success_rate       | 0.65     |\n",
            "| time/                 |          |\n",
            "|    fps                | 187      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 180025   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9       |\n",
            "|    explained_variance | -0.788   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 36004    |\n",
            "|    policy_loss        | -4.95    |\n",
            "|    std                | 0.883    |\n",
            "|    value_loss         | 0.366    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 217/600: Total Reward = -6.21\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28       |\n",
            "|    ep_rew_mean        | -3.39    |\n",
            "|    success_rate       | 0.58     |\n",
            "| time/                 |          |\n",
            "|    fps                | 103      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 180860   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.99    |\n",
            "|    explained_variance | 0.762    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 36171    |\n",
            "|    policy_loss        | 1.48     |\n",
            "|    std                | 0.882    |\n",
            "|    value_loss         | 0.0365   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 218/600: Total Reward = -0.10\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 19.5     |\n",
            "|    ep_rew_mean        | -2.06    |\n",
            "|    success_rate       | 0.78     |\n",
            "| time/                 |          |\n",
            "|    fps                | 185      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 181695   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.02    |\n",
            "|    explained_variance | -0.553   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 36338    |\n",
            "|    policy_loss        | -0.95    |\n",
            "|    std                | 0.884    |\n",
            "|    value_loss         | 0.011    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 219/600: Total Reward = -2.48\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 10       |\n",
            "|    ep_rew_mean        | -0.886   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 187      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 182530   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.99    |\n",
            "|    explained_variance | -0.422   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 36505    |\n",
            "|    policy_loss        | 0.301    |\n",
            "|    std                | 0.882    |\n",
            "|    value_loss         | 0.00999  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 220/600: Total Reward = -1.54\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 11.1     |\n",
            "|    ep_rew_mean        | -0.964   |\n",
            "|    success_rate       | 0.97     |\n",
            "| time/                 |          |\n",
            "|    fps                | 116      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 183365   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.97    |\n",
            "|    explained_variance | -0.815   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 36672    |\n",
            "|    policy_loss        | -0.32    |\n",
            "|    std                | 0.878    |\n",
            "|    value_loss         | 0.00754  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 221/600: Total Reward = -2.05\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8.31     |\n",
            "|    ep_rew_mean        | -0.706   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 193      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 184200   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.93    |\n",
            "|    explained_variance | -0.773   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 36839    |\n",
            "|    policy_loss        | -0.766   |\n",
            "|    std                | 0.874    |\n",
            "|    value_loss         | 0.0114   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 222/600: Total Reward = -1.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8.38     |\n",
            "|    ep_rew_mean        | -0.704   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 179      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 185035   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.91    |\n",
            "|    explained_variance | -0.0423  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 37006    |\n",
            "|    policy_loss        | 3.96     |\n",
            "|    std                | 0.872    |\n",
            "|    value_loss         | 0.205    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 223/600: Total Reward = -6.93\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8.74     |\n",
            "|    ep_rew_mean        | -0.774   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 127      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 185870   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.92    |\n",
            "|    explained_variance | 0.631    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 37173    |\n",
            "|    policy_loss        | 18.8     |\n",
            "|    std                | 0.873    |\n",
            "|    value_loss         | 5.73     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 224/600: Total Reward = -0.48\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 10.3     |\n",
            "|    ep_rew_mean        | -0.934   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 192      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 186705   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.89    |\n",
            "|    explained_variance | -3.52    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 37340    |\n",
            "|    policy_loss        | -1.82    |\n",
            "|    std                | 0.87     |\n",
            "|    value_loss         | 0.0568   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 225/600: Total Reward = -0.79\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 7.46     |\n",
            "|    ep_rew_mean        | -0.642   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 185      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 187540   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.88    |\n",
            "|    explained_variance | -4.44    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 37507    |\n",
            "|    policy_loss        | -6.81    |\n",
            "|    std                | 0.867    |\n",
            "|    value_loss         | 0.506    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 226/600: Total Reward = -1.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.86     |\n",
            "|    ep_rew_mean        | -0.488   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 138      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 188375   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.81    |\n",
            "|    explained_variance | -1.85    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 37674    |\n",
            "|    policy_loss        | -0.846   |\n",
            "|    std                | 0.86     |\n",
            "|    value_loss         | 0.0386   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 227/600: Total Reward = -0.42\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.11     |\n",
            "|    ep_rew_mean        | -0.511   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 190      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 189210   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.82    |\n",
            "|    explained_variance | -1.58    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 37841    |\n",
            "|    policy_loss        | -1.86    |\n",
            "|    std                | 0.861    |\n",
            "|    value_loss         | 0.0434   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 228/600: Total Reward = -0.70\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8.29     |\n",
            "|    ep_rew_mean        | -0.697   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 190045   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.81    |\n",
            "|    explained_variance | -30.3    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 38008    |\n",
            "|    policy_loss        | -5.1     |\n",
            "|    std                | 0.861    |\n",
            "|    value_loss         | 0.516    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 229/600: Total Reward = -0.20\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.6      |\n",
            "|    ep_rew_mean        | -0.449   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 144      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 190880   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.81    |\n",
            "|    explained_variance | 0.568    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 38175    |\n",
            "|    policy_loss        | -0.317   |\n",
            "|    std                | 0.861    |\n",
            "|    value_loss         | 0.0281   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 230/600: Total Reward = -0.43\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.15     |\n",
            "|    ep_rew_mean        | -0.449   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 188      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 191715   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.78    |\n",
            "|    explained_variance | 0.99     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 38342    |\n",
            "|    policy_loss        | 2.54     |\n",
            "|    std                | 0.857    |\n",
            "|    value_loss         | 0.0869   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 231/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.98     |\n",
            "|    ep_rew_mean        | -0.404   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 146      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 192550   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.76    |\n",
            "|    explained_variance | 0.21     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 38509    |\n",
            "|    policy_loss        | -1.08    |\n",
            "|    std                | 0.854    |\n",
            "|    value_loss         | 0.0193   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 232/600: Total Reward = -0.50\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.76     |\n",
            "|    ep_rew_mean        | -0.491   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 193385   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.76    |\n",
            "|    explained_variance | -1.11    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 38676    |\n",
            "|    policy_loss        | 0.435    |\n",
            "|    std                | 0.854    |\n",
            "|    value_loss         | 0.0292   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 233/600: Total Reward = -0.23\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.3      |\n",
            "|    ep_rew_mean        | -0.449   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 185      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 194220   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.7     |\n",
            "|    explained_variance | 0.0392   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 38843    |\n",
            "|    policy_loss        | 1.2      |\n",
            "|    std                | 0.847    |\n",
            "|    value_loss         | 0.0312   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 234/600: Total Reward = -0.14\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.44     |\n",
            "|    ep_rew_mean        | -0.467   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 132      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 195055   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.66    |\n",
            "|    explained_variance | 0.893    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 39010    |\n",
            "|    policy_loss        | -0.816   |\n",
            "|    std                | 0.841    |\n",
            "|    value_loss         | 0.0264   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 235/600: Total Reward = -0.65\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.98     |\n",
            "|    ep_rew_mean        | -0.409   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 184      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 195890   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.63    |\n",
            "|    explained_variance | -0.695   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 39177    |\n",
            "|    policy_loss        | 1.33     |\n",
            "|    std                | 0.838    |\n",
            "|    value_loss         | 0.0371   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 236/600: Total Reward = -0.63\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.19     |\n",
            "|    ep_rew_mean        | -0.537   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 171      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 196725   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.59    |\n",
            "|    explained_variance | -1.72    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 39344    |\n",
            "|    policy_loss        | -1.76    |\n",
            "|    std                | 0.835    |\n",
            "|    value_loss         | 0.0591   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 237/600: Total Reward = -0.28\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.17     |\n",
            "|    ep_rew_mean        | -0.436   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 115      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 197560   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.56    |\n",
            "|    explained_variance | 0.976    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 39511    |\n",
            "|    policy_loss        | 0.653    |\n",
            "|    std                | 0.83     |\n",
            "|    value_loss         | 0.00584  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 238/600: Total Reward = -0.10\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.35     |\n",
            "|    ep_rew_mean        | -0.539   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 178      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 198395   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.53    |\n",
            "|    explained_variance | 0.193    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 39678    |\n",
            "|    policy_loss        | 0.89     |\n",
            "|    std                | 0.827    |\n",
            "|    value_loss         | 0.0406   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 239/600: Total Reward = -0.43\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8.32     |\n",
            "|    ep_rew_mean        | -0.706   |\n",
            "|    success_rate       | 0.97     |\n",
            "| time/                 |          |\n",
            "|    fps                | 183      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 199230   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.56    |\n",
            "|    explained_variance | -2.36    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 39845    |\n",
            "|    policy_loss        | 0.779    |\n",
            "|    std                | 0.831    |\n",
            "|    value_loss         | 0.0213   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 240/600: Total Reward = -0.84\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.29     |\n",
            "|    ep_rew_mean        | -0.448   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 129      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 200065   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.58    |\n",
            "|    explained_variance | 0.524    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 40012    |\n",
            "|    policy_loss        | 1.72     |\n",
            "|    std                | 0.833    |\n",
            "|    value_loss         | 0.0653   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 241/600: Total Reward = -0.40\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.48     |\n",
            "|    ep_rew_mean        | -0.463   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 179      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 200900   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.6     |\n",
            "|    explained_variance | 0.992    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 40179    |\n",
            "|    policy_loss        | 3.08     |\n",
            "|    std                | 0.836    |\n",
            "|    value_loss         | 0.0946   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 242/600: Total Reward = -0.26\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.12     |\n",
            "|    ep_rew_mean        | -0.441   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 176      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 201735   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.59    |\n",
            "|    explained_variance | -1.18    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 40346    |\n",
            "|    policy_loss        | -0.844   |\n",
            "|    std                | 0.836    |\n",
            "|    value_loss         | 0.0323   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 243/600: Total Reward = -0.03\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.99     |\n",
            "|    ep_rew_mean        | -0.411   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 144      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 202570   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.62    |\n",
            "|    explained_variance | 0.904    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 40513    |\n",
            "|    policy_loss        | 0.779    |\n",
            "|    std                | 0.838    |\n",
            "|    value_loss         | 0.0117   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 244/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.26     |\n",
            "|    ep_rew_mean        | -0.349   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 203405   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.64    |\n",
            "|    explained_variance | -0.423   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 40680    |\n",
            "|    policy_loss        | 2.78     |\n",
            "|    std                | 0.841    |\n",
            "|    value_loss         | 0.209    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 245/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.19     |\n",
            "|    ep_rew_mean        | -0.462   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 170      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 204240   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.61    |\n",
            "|    explained_variance | 0.492    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 40847    |\n",
            "|    policy_loss        | 1.46     |\n",
            "|    std                | 0.838    |\n",
            "|    value_loss         | 0.038    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 246/600: Total Reward = -0.66\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.66     |\n",
            "|    ep_rew_mean        | -0.487   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 161      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 205075   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.61    |\n",
            "|    explained_variance | 0.502    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 41014    |\n",
            "|    policy_loss        | 3.12     |\n",
            "|    std                | 0.836    |\n",
            "|    value_loss         | 0.262    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 247/600: Total Reward = -0.78\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.41     |\n",
            "|    ep_rew_mean        | -0.359   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 181      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 205910   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.59    |\n",
            "|    explained_variance | 0.237    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 41181    |\n",
            "|    policy_loss        | -1.45    |\n",
            "|    std                | 0.833    |\n",
            "|    value_loss         | 0.0288   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 248/600: Total Reward = -0.58\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.07     |\n",
            "|    ep_rew_mean        | -0.335   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 141      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 206745   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.56    |\n",
            "|    explained_variance | 0.931    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 41348    |\n",
            "|    policy_loss        | -0.0757  |\n",
            "|    std                | 0.831    |\n",
            "|    value_loss         | 0.002    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 249/600: Total Reward = -0.50\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.72     |\n",
            "|    ep_rew_mean        | -0.389   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 181      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 207580   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.58    |\n",
            "|    explained_variance | 0.937    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 41515    |\n",
            "|    policy_loss        | -0.357   |\n",
            "|    std                | 0.833    |\n",
            "|    value_loss         | 0.00565  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 250/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.18     |\n",
            "|    ep_rew_mean        | -0.335   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 180      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 208415   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.52    |\n",
            "|    explained_variance | -2.82    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 41682    |\n",
            "|    policy_loss        | 0.889    |\n",
            "|    std                | 0.826    |\n",
            "|    value_loss         | 0.0212   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 251/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.06     |\n",
            "|    ep_rew_mean        | -0.327   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 123      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 209250   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.49    |\n",
            "|    explained_variance | 0.543    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 41849    |\n",
            "|    policy_loss        | -1.31    |\n",
            "|    std                | 0.821    |\n",
            "|    value_loss         | 0.0259   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 252/600: Total Reward = -0.23\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.67     |\n",
            "|    ep_rew_mean        | -0.397   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 186      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 210085   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.5     |\n",
            "|    explained_variance | -0.409   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 42016    |\n",
            "|    policy_loss        | -3.29    |\n",
            "|    std                | 0.822    |\n",
            "|    value_loss         | 0.144    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 253/600: Total Reward = -0.65\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.65     |\n",
            "|    ep_rew_mean        | -0.384   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 180      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 210920   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.48    |\n",
            "|    explained_variance | 0.409    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 42183    |\n",
            "|    policy_loss        | 0.402    |\n",
            "|    std                | 0.82     |\n",
            "|    value_loss         | 0.015    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 254/600: Total Reward = -0.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.59     |\n",
            "|    ep_rew_mean        | -0.383   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 114      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 211755   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.44    |\n",
            "|    explained_variance | 0.837    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 42350    |\n",
            "|    policy_loss        | -0.213   |\n",
            "|    std                | 0.815    |\n",
            "|    value_loss         | 0.00144  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 255/600: Total Reward = -0.26\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.97     |\n",
            "|    ep_rew_mean        | -0.322   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 180      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 212590   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.45    |\n",
            "|    explained_variance | -0.752   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 42517    |\n",
            "|    policy_loss        | -0.47    |\n",
            "|    std                | 0.816    |\n",
            "|    value_loss         | 0.0137   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 256/600: Total Reward = -0.54\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4        |\n",
            "|    ep_rew_mean        | -0.313   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 182      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 213425   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.42    |\n",
            "|    explained_variance | 0.854    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 42684    |\n",
            "|    policy_loss        | 0.233    |\n",
            "|    std                | 0.812    |\n",
            "|    value_loss         | 0.00342  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 257/600: Total Reward = -0.32\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.62     |\n",
            "|    ep_rew_mean        | -0.286   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 109      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 214260   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.37    |\n",
            "|    explained_variance | 0.905    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 42851    |\n",
            "|    policy_loss        | 0.138    |\n",
            "|    std                | 0.806    |\n",
            "|    value_loss         | 0.00118  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 258/600: Total Reward = -0.47\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.18     |\n",
            "|    ep_rew_mean        | -0.328   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 183      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 215095   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.38    |\n",
            "|    explained_variance | 0.949    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 43018    |\n",
            "|    policy_loss        | -0.629   |\n",
            "|    std                | 0.808    |\n",
            "|    value_loss         | 0.00566  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 259/600: Total Reward = -0.34\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.12     |\n",
            "|    ep_rew_mean        | -0.341   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 178      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 215930   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.34    |\n",
            "|    explained_variance | 0.904    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 43185    |\n",
            "|    policy_loss        | -0.398   |\n",
            "|    std                | 0.804    |\n",
            "|    value_loss         | 0.00793  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 260/600: Total Reward = -0.42\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.56     |\n",
            "|    ep_rew_mean        | -0.292   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 139      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 216765   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.27    |\n",
            "|    explained_variance | 0.964    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 43352    |\n",
            "|    policy_loss        | 0.192    |\n",
            "|    std                | 0.797    |\n",
            "|    value_loss         | 0.0019   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 261/600: Total Reward = -0.21\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.99     |\n",
            "|    ep_rew_mean        | -0.327   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 181      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 217600   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.29    |\n",
            "|    explained_variance | -4.46    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 43519    |\n",
            "|    policy_loss        | -7.2     |\n",
            "|    std                | 0.798    |\n",
            "|    value_loss         | 0.734    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 262/600: Total Reward = -0.16\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.49     |\n",
            "|    ep_rew_mean        | -0.278   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 146      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 218435   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.26    |\n",
            "|    explained_variance | 0.463    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 43686    |\n",
            "|    policy_loss        | -0.784   |\n",
            "|    std                | 0.795    |\n",
            "|    value_loss         | 0.0102   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 263/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.72     |\n",
            "|    ep_rew_mean        | -0.289   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 174      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 219270   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.31    |\n",
            "|    explained_variance | 0.962    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 43853    |\n",
            "|    policy_loss        | -0.765   |\n",
            "|    std                | 0.801    |\n",
            "|    value_loss         | 0.011    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 264/600: Total Reward = -0.65\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.37     |\n",
            "|    ep_rew_mean        | -0.358   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 177      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 220105   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.28    |\n",
            "|    explained_variance | 0.897    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 44020    |\n",
            "|    policy_loss        | 1.15     |\n",
            "|    std                | 0.799    |\n",
            "|    value_loss         | 0.0225   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 265/600: Total Reward = -0.40\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.11     |\n",
            "|    ep_rew_mean        | -0.32    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 117      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 220940   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.28    |\n",
            "|    explained_variance | 0.227    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 44187    |\n",
            "|    policy_loss        | -0.049   |\n",
            "|    std                | 0.798    |\n",
            "|    value_loss         | 0.0119   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 266/600: Total Reward = -0.48\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.81     |\n",
            "|    ep_rew_mean        | -0.395   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 165      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 221775   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.3     |\n",
            "|    explained_variance | 0.578    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 44354    |\n",
            "|    policy_loss        | 2.15     |\n",
            "|    std                | 0.801    |\n",
            "|    value_loss         | 0.0702   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 267/600: Total Reward = -0.34\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.5      |\n",
            "|    ep_rew_mean        | -0.361   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 175      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 222610   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.31    |\n",
            "|    explained_variance | 0.345    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 44521    |\n",
            "|    policy_loss        | -0.437   |\n",
            "|    std                | 0.802    |\n",
            "|    value_loss         | 0.0483   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 268/600: Total Reward = -0.48\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.96     |\n",
            "|    ep_rew_mean        | -0.322   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 110      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 223445   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.3     |\n",
            "|    explained_variance | 0.916    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 44688    |\n",
            "|    policy_loss        | -0.694   |\n",
            "|    std                | 0.801    |\n",
            "|    value_loss         | 0.00848  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 269/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.26     |\n",
            "|    ep_rew_mean        | -0.341   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 173      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 224280   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.27    |\n",
            "|    explained_variance | 0.988    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 44855    |\n",
            "|    policy_loss        | 0.0128   |\n",
            "|    std                | 0.799    |\n",
            "|    value_loss         | 0.000261 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 270/600: Total Reward = -0.21\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.37     |\n",
            "|    ep_rew_mean        | -0.368   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 168      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 225115   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.25    |\n",
            "|    explained_variance | 0.51     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 45022    |\n",
            "|    policy_loss        | 0.065    |\n",
            "|    std                | 0.798    |\n",
            "|    value_loss         | 0.00276  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 271/600: Total Reward = -0.72\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.06     |\n",
            "|    ep_rew_mean        | -0.328   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 152      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 225950   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.24    |\n",
            "|    explained_variance | 0.941    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 45189    |\n",
            "|    policy_loss        | 0.162    |\n",
            "|    std                | 0.796    |\n",
            "|    value_loss         | 0.00142  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 272/600: Total Reward = -0.28\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.75     |\n",
            "|    ep_rew_mean        | -0.311   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 173      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 226785   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.27    |\n",
            "|    explained_variance | 0.865    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 45356    |\n",
            "|    policy_loss        | 0.498    |\n",
            "|    std                | 0.8      |\n",
            "|    value_loss         | 0.00475  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 273/600: Total Reward = -0.26\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.9      |\n",
            "|    ep_rew_mean        | -0.314   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 129      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 227620   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.29    |\n",
            "|    explained_variance | 0.944    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 45523    |\n",
            "|    policy_loss        | -0.13    |\n",
            "|    std                | 0.802    |\n",
            "|    value_loss         | 0.00123  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 274/600: Total Reward = -0.38\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.11     |\n",
            "|    ep_rew_mean        | -0.411   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 169      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 228455   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.26    |\n",
            "|    explained_variance | 0.922    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 45690    |\n",
            "|    policy_loss        | -0.35    |\n",
            "|    std                | 0.8      |\n",
            "|    value_loss         | 0.00269  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 275/600: Total Reward = -0.14\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.9      |\n",
            "|    ep_rew_mean        | -0.412   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 168      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 229290   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.24    |\n",
            "|    explained_variance | 0.972    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 45857    |\n",
            "|    policy_loss        | 0.132    |\n",
            "|    std                | 0.798    |\n",
            "|    value_loss         | 0.00173  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 276/600: Total Reward = -0.10\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.14     |\n",
            "|    ep_rew_mean        | -0.339   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 107      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 230125   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.22    |\n",
            "|    explained_variance | 0.849    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 46024    |\n",
            "|    policy_loss        | -0.299   |\n",
            "|    std                | 0.795    |\n",
            "|    value_loss         | 0.0095   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 277/600: Total Reward = -0.40\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.92     |\n",
            "|    ep_rew_mean        | -0.309   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 171      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 230960   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.23    |\n",
            "|    explained_variance | -0.362   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 46191    |\n",
            "|    policy_loss        | -0.0236  |\n",
            "|    std                | 0.796    |\n",
            "|    value_loss         | 0.00693  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 278/600: Total Reward = -0.28\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.31     |\n",
            "|    ep_rew_mean        | -0.347   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 171      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 231795   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.23    |\n",
            "|    explained_variance | 0.857    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 46358    |\n",
            "|    policy_loss        | 0.034    |\n",
            "|    std                | 0.797    |\n",
            "|    value_loss         | 0.00192  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 279/600: Total Reward = -0.14\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.32     |\n",
            "|    ep_rew_mean        | -0.358   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 120      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 232630   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.23    |\n",
            "|    explained_variance | -0.422   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 46525    |\n",
            "|    policy_loss        | 1.29     |\n",
            "|    std                | 0.798    |\n",
            "|    value_loss         | 0.0457   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 280/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.89     |\n",
            "|    ep_rew_mean        | -0.307   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 165      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 233465   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.19    |\n",
            "|    explained_variance | -1.4     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 46692    |\n",
            "|    policy_loss        | 1.94     |\n",
            "|    std                | 0.794    |\n",
            "|    value_loss         | 0.0631   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 281/600: Total Reward = -0.09\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.1      |\n",
            "|    ep_rew_mean        | -0.334   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 155      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 234300   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.2     |\n",
            "|    explained_variance | 0.831    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 46859    |\n",
            "|    policy_loss        | 0.317    |\n",
            "|    std                | 0.796    |\n",
            "|    value_loss         | 0.00502  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 282/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.1      |\n",
            "|    ep_rew_mean        | -0.403   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 163      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 235135   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.18    |\n",
            "|    explained_variance | 0.979    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 47026    |\n",
            "|    policy_loss        | 0.261    |\n",
            "|    std                | 0.793    |\n",
            "|    value_loss         | 0.00226  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 283/600: Total Reward = -0.59\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.15     |\n",
            "|    ep_rew_mean        | -0.348   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 166      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 235970   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.15    |\n",
            "|    explained_variance | 0.453    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 47193    |\n",
            "|    policy_loss        | 0.801    |\n",
            "|    std                | 0.79     |\n",
            "|    value_loss         | 0.0121   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 284/600: Total Reward = -0.27\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.78     |\n",
            "|    ep_rew_mean        | -0.309   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 131      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 236805   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.13    |\n",
            "|    explained_variance | 0.815    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 47360    |\n",
            "|    policy_loss        | 0.136    |\n",
            "|    std                | 0.788    |\n",
            "|    value_loss         | 0.00228  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 285/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4        |\n",
            "|    ep_rew_mean        | -0.329   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 174      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 237640   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.14    |\n",
            "|    explained_variance | 0.934    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 47527    |\n",
            "|    policy_loss        | -0.34    |\n",
            "|    std                | 0.789    |\n",
            "|    value_loss         | 0.00223  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 286/600: Total Reward = -0.37\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.62     |\n",
            "|    ep_rew_mean        | -0.298   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 171      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 238475   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.11    |\n",
            "|    explained_variance | 0.999    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 47694    |\n",
            "|    policy_loss        | -0.0206  |\n",
            "|    std                | 0.786    |\n",
            "|    value_loss         | 1.32e-05 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 287/600: Total Reward = -0.09\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.76     |\n",
            "|    ep_rew_mean        | -0.305   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 103      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 239310   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.08    |\n",
            "|    explained_variance | 0.906    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 47861    |\n",
            "|    policy_loss        | -0.327   |\n",
            "|    std                | 0.782    |\n",
            "|    value_loss         | 0.00773  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 288/600: Total Reward = -0.83\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.27     |\n",
            "|    ep_rew_mean        | -0.354   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 169      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 240145   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.09    |\n",
            "|    explained_variance | 0.735    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 48028    |\n",
            "|    policy_loss        | -0.576   |\n",
            "|    std                | 0.783    |\n",
            "|    value_loss         | 0.00896  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 289/600: Total Reward = -0.32\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.67     |\n",
            "|    ep_rew_mean        | -0.307   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 150      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 240980   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.03    |\n",
            "|    explained_variance | 0.781    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 48195    |\n",
            "|    policy_loss        | -0.748   |\n",
            "|    std                | 0.777    |\n",
            "|    value_loss         | 0.0128   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 290/600: Total Reward = -0.56\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.97     |\n",
            "|    ep_rew_mean        | -0.324   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 147      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 241815   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.03    |\n",
            "|    explained_variance | 0.99     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 48362    |\n",
            "|    policy_loss        | 0.142    |\n",
            "|    std                | 0.778    |\n",
            "|    value_loss         | 0.000477 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 291/600: Total Reward = -0.29\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4        |\n",
            "|    ep_rew_mean        | -0.33    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 171      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 242650   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.02    |\n",
            "|    explained_variance | 0.885    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 48529    |\n",
            "|    policy_loss        | 0.947    |\n",
            "|    std                | 0.778    |\n",
            "|    value_loss         | 0.0106   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 292/600: Total Reward = -0.43\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.81     |\n",
            "|    ep_rew_mean        | -0.305   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 121      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 243485   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8       |\n",
            "|    explained_variance | 0.962    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 48696    |\n",
            "|    policy_loss        | -0.233   |\n",
            "|    std                | 0.777    |\n",
            "|    value_loss         | 0.0016   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 293/600: Total Reward = -0.39\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.94     |\n",
            "|    ep_rew_mean        | -0.329   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 173      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 244320   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.01    |\n",
            "|    explained_variance | 0.662    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 48863    |\n",
            "|    policy_loss        | -0.376   |\n",
            "|    std                | 0.779    |\n",
            "|    value_loss         | 0.00556  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 294/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.87     |\n",
            "|    ep_rew_mean        | -0.3     |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 171      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 245155   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.01    |\n",
            "|    explained_variance | 0.974    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 49030    |\n",
            "|    policy_loss        | -0.175   |\n",
            "|    std                | 0.779    |\n",
            "|    value_loss         | 0.00198  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 295/600: Total Reward = -0.15\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.98     |\n",
            "|    ep_rew_mean        | -0.327   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 100      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 245990   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.03    |\n",
            "|    explained_variance | 0.577    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 49197    |\n",
            "|    policy_loss        | -0.161   |\n",
            "|    std                | 0.781    |\n",
            "|    value_loss         | 0.00259  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 296/600: Total Reward = -1.01\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.83     |\n",
            "|    ep_rew_mean        | -0.296   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 171      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 246825   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.04    |\n",
            "|    explained_variance | 0.834    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 49364    |\n",
            "|    policy_loss        | -0.0213  |\n",
            "|    std                | 0.783    |\n",
            "|    value_loss         | 0.00218  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 297/600: Total Reward = -0.43\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.79     |\n",
            "|    ep_rew_mean        | -0.305   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 142      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 247660   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.03    |\n",
            "|    explained_variance | 0.85     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 49531    |\n",
            "|    policy_loss        | -0.581   |\n",
            "|    std                | 0.781    |\n",
            "|    value_loss         | 0.00537  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 298/600: Total Reward = -0.42\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.79     |\n",
            "|    ep_rew_mean        | -0.294   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 166      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 248495   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.02    |\n",
            "|    explained_variance | 0.848    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 49698    |\n",
            "|    policy_loss        | -0.289   |\n",
            "|    std                | 0.782    |\n",
            "|    value_loss         | 0.00214  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 299/600: Total Reward = -0.17\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.42     |\n",
            "|    ep_rew_mean        | -0.261   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 171      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 249330   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8       |\n",
            "|    explained_variance | 0.592    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 49865    |\n",
            "|    policy_loss        | 0.287    |\n",
            "|    std                | 0.779    |\n",
            "|    value_loss         | 0.00604  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 300/600: Total Reward = -0.24\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.73     |\n",
            "|    ep_rew_mean        | -0.303   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 101      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 250165   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.05    |\n",
            "|    explained_variance | 0.451    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 50032    |\n",
            "|    policy_loss        | -1.02    |\n",
            "|    std                | 0.784    |\n",
            "|    value_loss         | 0.0244   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 301/600: Total Reward = -0.25\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.68     |\n",
            "|    ep_rew_mean        | -0.3     |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 163      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 251000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.07    |\n",
            "|    explained_variance | 0.758    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 50199    |\n",
            "|    policy_loss        | -0.582   |\n",
            "|    std                | 0.787    |\n",
            "|    value_loss         | 0.00691  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 302/600: Total Reward = -0.10\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.49     |\n",
            "|    ep_rew_mean        | -0.282   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 159      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 251835   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8.04    |\n",
            "|    explained_variance | 0.972    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 50366    |\n",
            "|    policy_loss        | 0.548    |\n",
            "|    std                | 0.783    |\n",
            "|    value_loss         | 0.00463  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 303/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.49     |\n",
            "|    ep_rew_mean        | -0.362   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 121      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 252670   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.98    |\n",
            "|    explained_variance | 0.61     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 50533    |\n",
            "|    policy_loss        | 0.126    |\n",
            "|    std                | 0.778    |\n",
            "|    value_loss         | 0.00163  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 304/600: Total Reward = -0.16\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.78     |\n",
            "|    ep_rew_mean        | -0.313   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 159      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 253505   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.96    |\n",
            "|    explained_variance | 0.977    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 50700    |\n",
            "|    policy_loss        | -0.367   |\n",
            "|    std                | 0.776    |\n",
            "|    value_loss         | 0.0043   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 305/600: Total Reward = -0.33\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.19     |\n",
            "|    ep_rew_mean        | -0.338   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 113      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 254340   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.93    |\n",
            "|    explained_variance | 0.52     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 50867    |\n",
            "|    policy_loss        | 0.867    |\n",
            "|    std                | 0.772    |\n",
            "|    value_loss         | 0.0199   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 306/600: Total Reward = -0.33\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.14     |\n",
            "|    ep_rew_mean        | -0.347   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 161      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 255175   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.92    |\n",
            "|    explained_variance | 0.873    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 51034    |\n",
            "|    policy_loss        | -0.0862  |\n",
            "|    std                | 0.771    |\n",
            "|    value_loss         | 0.0012   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 307/600: Total Reward = -0.55\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.08     |\n",
            "|    ep_rew_mean        | -0.331   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 166      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 256010   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.91    |\n",
            "|    explained_variance | 0.83     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 51201    |\n",
            "|    policy_loss        | -0.842   |\n",
            "|    std                | 0.772    |\n",
            "|    value_loss         | 0.0136   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 308/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.1      |\n",
            "|    ep_rew_mean        | -0.337   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 115      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 256845   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.92    |\n",
            "|    explained_variance | -0.238   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 51368    |\n",
            "|    policy_loss        | -1.06    |\n",
            "|    std                | 0.774    |\n",
            "|    value_loss         | 0.0275   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 309/600: Total Reward = -0.55\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.53     |\n",
            "|    ep_rew_mean        | -0.276   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 159      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 257680   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.88    |\n",
            "|    explained_variance | 0.998    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 51535    |\n",
            "|    policy_loss        | 0.0767   |\n",
            "|    std                | 0.768    |\n",
            "|    value_loss         | 0.000135 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 310/600: Total Reward = -0.33\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.75     |\n",
            "|    ep_rew_mean        | -0.302   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 125      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 258515   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.91    |\n",
            "|    explained_variance | 0.96     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 51702    |\n",
            "|    policy_loss        | -0.332   |\n",
            "|    std                | 0.772    |\n",
            "|    value_loss         | 0.00177  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 311/600: Total Reward = -0.14\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.68     |\n",
            "|    ep_rew_mean        | -0.297   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 153      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 259350   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.91    |\n",
            "|    explained_variance | 0.977    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 51869    |\n",
            "|    policy_loss        | 0.335    |\n",
            "|    std                | 0.771    |\n",
            "|    value_loss         | 0.00231  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 312/600: Total Reward = -0.31\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.59     |\n",
            "|    ep_rew_mean        | -0.278   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 156      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 260185   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.9     |\n",
            "|    explained_variance | -0.321   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 52036    |\n",
            "|    policy_loss        | -0.727   |\n",
            "|    std                | 0.771    |\n",
            "|    value_loss         | 0.0209   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 313/600: Total Reward = -0.35\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.55     |\n",
            "|    ep_rew_mean        | -0.366   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 104      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 261020   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.89    |\n",
            "|    explained_variance | 0.935    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 52203    |\n",
            "|    policy_loss        | 0.273    |\n",
            "|    std                | 0.769    |\n",
            "|    value_loss         | 0.00618  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 314/600: Total Reward = -0.15\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.29     |\n",
            "|    ep_rew_mean        | -0.355   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 158      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 261855   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.84    |\n",
            "|    explained_variance | 0.829    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 52370    |\n",
            "|    policy_loss        | 0.387    |\n",
            "|    std                | 0.764    |\n",
            "|    value_loss         | 0.0132   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 315/600: Total Reward = -0.20\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.85     |\n",
            "|    ep_rew_mean        | -0.313   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 129      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 262690   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.8     |\n",
            "|    explained_variance | 0.889    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 52537    |\n",
            "|    policy_loss        | 0.414    |\n",
            "|    std                | 0.76     |\n",
            "|    value_loss         | 0.00744  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 316/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.47     |\n",
            "|    ep_rew_mean        | -0.369   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 167      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 263525   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.79    |\n",
            "|    explained_variance | 0.999    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 52704    |\n",
            "|    policy_loss        | -0.175   |\n",
            "|    std                | 0.759    |\n",
            "|    value_loss         | 0.000755 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 317/600: Total Reward = -0.27\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.99     |\n",
            "|    ep_rew_mean        | -0.397   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 163      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 264360   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.77    |\n",
            "|    explained_variance | 0.302    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 52871    |\n",
            "|    policy_loss        | -1.09    |\n",
            "|    std                | 0.755    |\n",
            "|    value_loss         | 0.0198   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 318/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.32     |\n",
            "|    ep_rew_mean        | -0.345   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 99       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 265195   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.76    |\n",
            "|    explained_variance | 0.984    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 53038    |\n",
            "|    policy_loss        | 0.475    |\n",
            "|    std                | 0.755    |\n",
            "|    value_loss         | 0.00258  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 319/600: Total Reward = -0.03\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.94     |\n",
            "|    ep_rew_mean        | -0.316   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 156      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 266030   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.76    |\n",
            "|    explained_variance | 0.273    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 53205    |\n",
            "|    policy_loss        | 0.548    |\n",
            "|    std                | 0.755    |\n",
            "|    value_loss         | 0.0082   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 320/600: Total Reward = -0.29\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.36     |\n",
            "|    ep_rew_mean        | -0.362   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 138      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 266865   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.75    |\n",
            "|    explained_variance | -0.104   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 53372    |\n",
            "|    policy_loss        | 0.37     |\n",
            "|    std                | 0.755    |\n",
            "|    value_loss         | 0.0116   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 321/600: Total Reward = -0.65\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.05     |\n",
            "|    ep_rew_mean        | -0.326   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 160      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 267700   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.74    |\n",
            "|    explained_variance | 0.78     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 53539    |\n",
            "|    policy_loss        | -1.33    |\n",
            "|    std                | 0.754    |\n",
            "|    value_loss         | 0.0152   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 322/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.08     |\n",
            "|    ep_rew_mean        | -0.335   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 154      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 268535   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.71    |\n",
            "|    explained_variance | 0.929    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 53706    |\n",
            "|    policy_loss        | -0.119   |\n",
            "|    std                | 0.75     |\n",
            "|    value_loss         | 0.000786 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 323/600: Total Reward = -0.52\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.09     |\n",
            "|    ep_rew_mean        | -0.336   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 94       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 269370   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.72    |\n",
            "|    explained_variance | 0.995    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 53873    |\n",
            "|    policy_loss        | -0.0493  |\n",
            "|    std                | 0.752    |\n",
            "|    value_loss         | 0.000374 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 324/600: Total Reward = -0.28\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.26     |\n",
            "|    ep_rew_mean        | -0.353   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 156      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 270205   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.65    |\n",
            "|    explained_variance | 0.818    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 54040    |\n",
            "|    policy_loss        | -0.435   |\n",
            "|    std                | 0.745    |\n",
            "|    value_loss         | 0.00407  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 325/600: Total Reward = -0.10\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.72     |\n",
            "|    ep_rew_mean        | -0.314   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 126      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 271040   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.62    |\n",
            "|    explained_variance | 0.133    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 54207    |\n",
            "|    policy_loss        | -1.29    |\n",
            "|    std                | 0.742    |\n",
            "|    value_loss         | 0.035    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 326/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.16     |\n",
            "|    ep_rew_mean        | -0.351   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 161      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 271875   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.63    |\n",
            "|    explained_variance | 0.995    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 54374    |\n",
            "|    policy_loss        | 0.311    |\n",
            "|    std                | 0.743    |\n",
            "|    value_loss         | 0.00186  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 327/600: Total Reward = -0.21\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.6      |\n",
            "|    ep_rew_mean        | -0.286   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 155      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 272710   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.61    |\n",
            "|    explained_variance | 0.842    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 54541    |\n",
            "|    policy_loss        | -0.347   |\n",
            "|    std                | 0.742    |\n",
            "|    value_loss         | 0.00215  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 328/600: Total Reward = -0.03\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.86     |\n",
            "|    ep_rew_mean        | -0.319   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 96       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 273545   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.6     |\n",
            "|    explained_variance | 0.999    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 54708    |\n",
            "|    policy_loss        | 0.275    |\n",
            "|    std                | 0.739    |\n",
            "|    value_loss         | 0.00136  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 329/600: Total Reward = -0.64\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.64     |\n",
            "|    ep_rew_mean        | -0.291   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 154      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 274380   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.55    |\n",
            "|    explained_variance | 0.996    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 54875    |\n",
            "|    policy_loss        | 0.00573  |\n",
            "|    std                | 0.735    |\n",
            "|    value_loss         | 9.15e-05 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 330/600: Total Reward = -0.41\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.74     |\n",
            "|    ep_rew_mean        | -0.37    |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 120      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 275215   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.53    |\n",
            "|    explained_variance | -0.266   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 55042    |\n",
            "|    policy_loss        | -0.517   |\n",
            "|    std                | 0.732    |\n",
            "|    value_loss         | 0.0492   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 331/600: Total Reward = -0.68\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.92     |\n",
            "|    ep_rew_mean        | -0.321   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 158      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 276050   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.52    |\n",
            "|    explained_variance | 0.838    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 55209    |\n",
            "|    policy_loss        | -0.0426  |\n",
            "|    std                | 0.731    |\n",
            "|    value_loss         | 0.0015   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 332/600: Total Reward = -0.56\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.41     |\n",
            "|    ep_rew_mean        | -0.271   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 145      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 276885   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.49    |\n",
            "|    explained_variance | 0.996    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 55376    |\n",
            "|    policy_loss        | 0.0259   |\n",
            "|    std                | 0.728    |\n",
            "|    value_loss         | 6.44e-05 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 333/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.96     |\n",
            "|    ep_rew_mean        | -0.302   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 101      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 277720   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.49    |\n",
            "|    explained_variance | 0.876    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 55543    |\n",
            "|    policy_loss        | -0.289   |\n",
            "|    std                | 0.728    |\n",
            "|    value_loss         | 0.00203  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 334/600: Total Reward = -0.16\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.82     |\n",
            "|    ep_rew_mean        | -0.308   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 150      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 278555   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.47    |\n",
            "|    explained_variance | 0.149    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 55710    |\n",
            "|    policy_loss        | -0.174   |\n",
            "|    std                | 0.725    |\n",
            "|    value_loss         | 0.0118   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 335/600: Total Reward = -0.14\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.16     |\n",
            "|    ep_rew_mean        | -0.331   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 96       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 279390   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.47    |\n",
            "|    explained_variance | 0.778    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 55877    |\n",
            "|    policy_loss        | 0.398    |\n",
            "|    std                | 0.726    |\n",
            "|    value_loss         | 0.00438  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 336/600: Total Reward = -0.27\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.23     |\n",
            "|    ep_rew_mean        | -0.339   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 154      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 280225   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.44    |\n",
            "|    explained_variance | 0.687    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 56044    |\n",
            "|    policy_loss        | -0.138   |\n",
            "|    std                | 0.723    |\n",
            "|    value_loss         | 0.0141   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 337/600: Total Reward = -0.57\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.2      |\n",
            "|    ep_rew_mean        | -0.337   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 151      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 281060   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.42    |\n",
            "|    explained_variance | 0.743    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 56211    |\n",
            "|    policy_loss        | -0.217   |\n",
            "|    std                | 0.719    |\n",
            "|    value_loss         | 0.00135  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 338/600: Total Reward = -0.16\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.66     |\n",
            "|    ep_rew_mean        | -0.298   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 121      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 281895   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.38    |\n",
            "|    explained_variance | 0.83     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 56378    |\n",
            "|    policy_loss        | -0.06    |\n",
            "|    std                | 0.715    |\n",
            "|    value_loss         | 0.00335  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 339/600: Total Reward = -0.41\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.09     |\n",
            "|    ep_rew_mean        | -0.336   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 152      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 282730   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.34    |\n",
            "|    explained_variance | 0.754    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 56545    |\n",
            "|    policy_loss        | -0.116   |\n",
            "|    std                | 0.71     |\n",
            "|    value_loss         | 0.00333  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 340/600: Total Reward = -0.32\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.76     |\n",
            "|    ep_rew_mean        | -0.295   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 91       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 283565   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.31    |\n",
            "|    explained_variance | 0.94     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 56712    |\n",
            "|    policy_loss        | 1        |\n",
            "|    std                | 0.707    |\n",
            "|    value_loss         | 0.0265   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 341/600: Total Reward = -0.03\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.28     |\n",
            "|    ep_rew_mean        | -0.352   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 150      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 284400   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.27    |\n",
            "|    explained_variance | 0.913    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 56879    |\n",
            "|    policy_loss        | -0.7     |\n",
            "|    std                | 0.703    |\n",
            "|    value_loss         | 0.00735  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 342/600: Total Reward = -4.01\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.82     |\n",
            "|    ep_rew_mean        | -0.312   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 118      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 285235   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.26    |\n",
            "|    explained_variance | 0.932    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 57046    |\n",
            "|    policy_loss        | 0.247    |\n",
            "|    std                | 0.703    |\n",
            "|    value_loss         | 0.00241  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 343/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.81     |\n",
            "|    ep_rew_mean        | -0.306   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 147      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 286070   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.26    |\n",
            "|    explained_variance | 0.858    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 57213    |\n",
            "|    policy_loss        | -0.306   |\n",
            "|    std                | 0.705    |\n",
            "|    value_loss         | 0.00562  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 344/600: Total Reward = -0.54\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.79     |\n",
            "|    ep_rew_mean        | -0.312   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 151      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 286905   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.24    |\n",
            "|    explained_variance | 0.98     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 57380    |\n",
            "|    policy_loss        | -0.244   |\n",
            "|    std                | 0.702    |\n",
            "|    value_loss         | 0.00104  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 345/600: Total Reward = -0.15\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.68     |\n",
            "|    ep_rew_mean        | -0.302   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 105      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 287740   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.21    |\n",
            "|    explained_variance | 0.963    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 57547    |\n",
            "|    policy_loss        | -0.113   |\n",
            "|    std                | 0.7      |\n",
            "|    value_loss         | 0.000849 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 346/600: Total Reward = -0.17\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.98     |\n",
            "|    ep_rew_mean        | -0.329   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 150      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 288575   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.2     |\n",
            "|    explained_variance | 0.79     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 57714    |\n",
            "|    policy_loss        | 0.969    |\n",
            "|    std                | 0.699    |\n",
            "|    value_loss         | 0.0186   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 347/600: Total Reward = -0.14\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.9      |\n",
            "|    ep_rew_mean        | -0.403   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 93       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 289410   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.19    |\n",
            "|    explained_variance | 0.226    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 57881    |\n",
            "|    policy_loss        | 1.94     |\n",
            "|    std                | 0.699    |\n",
            "|    value_loss         | 0.0913   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 348/600: Total Reward = -0.63\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.05     |\n",
            "|    ep_rew_mean        | -0.398   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 141      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 290245   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.21    |\n",
            "|    explained_variance | -0.041   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 58048    |\n",
            "|    policy_loss        | 3.06     |\n",
            "|    std                | 0.701    |\n",
            "|    value_loss         | 0.192    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 349/600: Total Reward = -0.53\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.14     |\n",
            "|    ep_rew_mean        | -0.422   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 136      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 291080   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.18    |\n",
            "|    explained_variance | 0.353    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 58215    |\n",
            "|    policy_loss        | -1.94    |\n",
            "|    std                | 0.699    |\n",
            "|    value_loss         | 0.0869   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 350/600: Total Reward = -0.60\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.42     |\n",
            "|    ep_rew_mean        | -0.355   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 147      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 291915   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.14    |\n",
            "|    explained_variance | 0.989    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 58382    |\n",
            "|    policy_loss        | -0.235   |\n",
            "|    std                | 0.694    |\n",
            "|    value_loss         | 0.000922 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 351/600: Total Reward = -0.32\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.76     |\n",
            "|    ep_rew_mean        | -0.38    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 153      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 292750   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.11    |\n",
            "|    explained_variance | 0.465    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 58549    |\n",
            "|    policy_loss        | -0.152   |\n",
            "|    std                | 0.691    |\n",
            "|    value_loss         | 0.00388  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 352/600: Total Reward = -0.63\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.62     |\n",
            "|    ep_rew_mean        | -0.472   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 88       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 293585   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.12    |\n",
            "|    explained_variance | 0.116    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 58716    |\n",
            "|    policy_loss        | 3.93     |\n",
            "|    std                | 0.691    |\n",
            "|    value_loss         | 0.635    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 353/600: Total Reward = -0.03\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.13     |\n",
            "|    ep_rew_mean        | -0.415   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 138      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 294420   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.12    |\n",
            "|    explained_variance | 0.97     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 58883    |\n",
            "|    policy_loss        | -0.141   |\n",
            "|    std                | 0.69     |\n",
            "|    value_loss         | 0.000917 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 354/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.3      |\n",
            "|    ep_rew_mean        | -0.337   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 114      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 295255   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.11    |\n",
            "|    explained_variance | 0.248    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 59050    |\n",
            "|    policy_loss        | -0.335   |\n",
            "|    std                | 0.689    |\n",
            "|    value_loss         | 0.00308  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 355/600: Total Reward = -0.35\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.67     |\n",
            "|    ep_rew_mean        | -0.288   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 155      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 296090   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.09    |\n",
            "|    explained_variance | 0.768    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 59217    |\n",
            "|    policy_loss        | 0.0985   |\n",
            "|    std                | 0.687    |\n",
            "|    value_loss         | 0.00177  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 356/600: Total Reward = -0.17\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.86     |\n",
            "|    ep_rew_mean        | -0.32    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 150      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 296925   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.09    |\n",
            "|    explained_variance | 0.978    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 59384    |\n",
            "|    policy_loss        | 0.166    |\n",
            "|    std                | 0.687    |\n",
            "|    value_loss         | 0.00177  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 357/600: Total Reward = -0.37\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.31     |\n",
            "|    ep_rew_mean        | -0.265   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 99       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 297760   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.09    |\n",
            "|    explained_variance | 0.8      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 59551    |\n",
            "|    policy_loss        | 0.575    |\n",
            "|    std                | 0.688    |\n",
            "|    value_loss         | 0.00648  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 358/600: Total Reward = -0.75\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.46     |\n",
            "|    ep_rew_mean        | -0.271   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 142      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 298595   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.07    |\n",
            "|    explained_variance | -0.111   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 59718    |\n",
            "|    policy_loss        | 0.372    |\n",
            "|    std                | 0.686    |\n",
            "|    value_loss         | 0.00538  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 359/600: Total Reward = -0.21\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.91     |\n",
            "|    ep_rew_mean        | -0.319   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 94       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 299430   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.06    |\n",
            "|    explained_variance | 0.942    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 59885    |\n",
            "|    policy_loss        | -0.0626  |\n",
            "|    std                | 0.685    |\n",
            "|    value_loss         | 0.000195 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 360/600: Total Reward = -0.37\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.17     |\n",
            "|    ep_rew_mean        | -0.34    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 148      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 300265   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.04    |\n",
            "|    explained_variance | 0.883    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 60052    |\n",
            "|    policy_loss        | -0.353   |\n",
            "|    std                | 0.683    |\n",
            "|    value_loss         | 0.00595  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 361/600: Total Reward = -0.47\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.49     |\n",
            "|    ep_rew_mean        | -0.373   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 133      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 301100   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.01    |\n",
            "|    explained_variance | 0.894    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 60219    |\n",
            "|    policy_loss        | -0.667   |\n",
            "|    std                | 0.681    |\n",
            "|    value_loss         | 0.0108   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 362/600: Total Reward = -0.37\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.77     |\n",
            "|    ep_rew_mean        | -0.309   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 154      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 301935   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.02    |\n",
            "|    explained_variance | 0.91     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 60386    |\n",
            "|    policy_loss        | 0.681    |\n",
            "|    std                | 0.683    |\n",
            "|    value_loss         | 0.00821  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 363/600: Total Reward = -0.16\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.77     |\n",
            "|    ep_rew_mean        | -0.308   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 145      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 302770   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.04    |\n",
            "|    explained_variance | -0.0864  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 60553    |\n",
            "|    policy_loss        | 0.962    |\n",
            "|    std                | 0.685    |\n",
            "|    value_loss         | 0.0182   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 364/600: Total Reward = -0.20\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.46     |\n",
            "|    ep_rew_mean        | -0.287   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 94       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 303605   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.02    |\n",
            "|    explained_variance | 0.978    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 60720    |\n",
            "|    policy_loss        | 0.00779  |\n",
            "|    std                | 0.683    |\n",
            "|    value_loss         | 0.000364 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 365/600: Total Reward = -0.40\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.71     |\n",
            "|    ep_rew_mean        | -0.287   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 145      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 304440   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.03    |\n",
            "|    explained_variance | 0.499    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 60887    |\n",
            "|    policy_loss        | -0.87    |\n",
            "|    std                | 0.685    |\n",
            "|    value_loss         | 0.0322   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 366/600: Total Reward = -0.66\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.89     |\n",
            "|    ep_rew_mean        | -0.315   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 102      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 305275   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.04    |\n",
            "|    explained_variance | 0.99     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 61054    |\n",
            "|    policy_loss        | 0.0711   |\n",
            "|    std                | 0.684    |\n",
            "|    value_loss         | 0.0006   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 367/600: Total Reward = -0.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.82     |\n",
            "|    ep_rew_mean        | -0.301   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 149      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 306110   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.03    |\n",
            "|    explained_variance | 0.864    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 61221    |\n",
            "|    policy_loss        | 0.968    |\n",
            "|    std                | 0.683    |\n",
            "|    value_loss         | 0.0183   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 368/600: Total Reward = -0.29\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.78     |\n",
            "|    ep_rew_mean        | -0.301   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 147      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 306945   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7       |\n",
            "|    explained_variance | -0.253   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 61388    |\n",
            "|    policy_loss        | 0.0826   |\n",
            "|    std                | 0.681    |\n",
            "|    value_loss         | 0.00118  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 369/600: Total Reward = -0.33\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.63     |\n",
            "|    ep_rew_mean        | -0.301   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 109      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 307780   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.97    |\n",
            "|    explained_variance | 0.943    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 61555    |\n",
            "|    policy_loss        | -0.149   |\n",
            "|    std                | 0.679    |\n",
            "|    value_loss         | 0.00142  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 370/600: Total Reward = -0.75\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.47     |\n",
            "|    ep_rew_mean        | -0.277   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 141      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 308615   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.95    |\n",
            "|    explained_variance | 0.857    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 61722    |\n",
            "|    policy_loss        | 0.0173   |\n",
            "|    std                | 0.676    |\n",
            "|    value_loss         | 0.00115  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 371/600: Total Reward = -0.39\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.83     |\n",
            "|    ep_rew_mean        | -0.304   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 89       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 309450   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.96    |\n",
            "|    explained_variance | 0.877    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 61889    |\n",
            "|    policy_loss        | 0.543    |\n",
            "|    std                | 0.676    |\n",
            "|    value_loss         | 0.00691  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 372/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.89     |\n",
            "|    ep_rew_mean        | -0.319   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 149      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 310285   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.96    |\n",
            "|    explained_variance | 0.988    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 62056    |\n",
            "|    policy_loss        | -0.523   |\n",
            "|    std                | 0.677    |\n",
            "|    value_loss         | 0.00923  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 373/600: Total Reward = -0.45\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.58     |\n",
            "|    ep_rew_mean        | -0.389   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 129      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 311120   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.94    |\n",
            "|    explained_variance | 0.432    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 62223    |\n",
            "|    policy_loss        | 1.12     |\n",
            "|    std                | 0.676    |\n",
            "|    value_loss         | 0.0293   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 374/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.05     |\n",
            "|    ep_rew_mean        | -0.317   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 155      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 311955   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.93    |\n",
            "|    explained_variance | 0.747    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 62390    |\n",
            "|    policy_loss        | 0.197    |\n",
            "|    std                | 0.675    |\n",
            "|    value_loss         | 0.00178  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 375/600: Total Reward = -0.10\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.36     |\n",
            "|    ep_rew_mean        | -0.269   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 145      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 312790   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.95    |\n",
            "|    explained_variance | 0.324    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 62557    |\n",
            "|    policy_loss        | 0.634    |\n",
            "|    std                | 0.678    |\n",
            "|    value_loss         | 0.0161   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 376/600: Total Reward = -0.20\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.92     |\n",
            "|    ep_rew_mean        | -0.314   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 90       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 313625   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.95    |\n",
            "|    explained_variance | 0.251    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 62724    |\n",
            "|    policy_loss        | -0.203   |\n",
            "|    std                | 0.679    |\n",
            "|    value_loss         | 0.0033   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 377/600: Total Reward = -0.63\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.86     |\n",
            "|    ep_rew_mean        | -0.308   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 146      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 314460   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.97    |\n",
            "|    explained_variance | 0.983    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 62891    |\n",
            "|    policy_loss        | 0.0749   |\n",
            "|    std                | 0.681    |\n",
            "|    value_loss         | 0.000229 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 378/600: Total Reward = -0.15\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.3      |\n",
            "|    ep_rew_mean        | -0.332   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 92       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 315295   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.94    |\n",
            "|    explained_variance | 0.945    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 63058    |\n",
            "|    policy_loss        | 0.133    |\n",
            "|    std                | 0.678    |\n",
            "|    value_loss         | 0.00073  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 379/600: Total Reward = -0.44\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.3      |\n",
            "|    ep_rew_mean        | -0.345   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 144      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 316130   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.9     |\n",
            "|    explained_variance | 0.933    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 63225    |\n",
            "|    policy_loss        | -0.209   |\n",
            "|    std                | 0.674    |\n",
            "|    value_loss         | 0.00246  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 380/600: Total Reward = -0.59\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.3      |\n",
            "|    ep_rew_mean        | -0.351   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 136      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 316965   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.87    |\n",
            "|    explained_variance | 0.982    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 63392    |\n",
            "|    policy_loss        | 0.54     |\n",
            "|    std                | 0.671    |\n",
            "|    value_loss         | 0.00579  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 381/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.23     |\n",
            "|    ep_rew_mean        | -0.339   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 137      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 317800   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.91    |\n",
            "|    explained_variance | 0.138    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 63559    |\n",
            "|    policy_loss        | 0.605    |\n",
            "|    std                | 0.675    |\n",
            "|    value_loss         | 0.00984  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 382/600: Total Reward = -0.10\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.8      |\n",
            "|    ep_rew_mean        | -0.299   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 145      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 318635   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.91    |\n",
            "|    explained_variance | 0.955    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 63726    |\n",
            "|    policy_loss        | 0.436    |\n",
            "|    std                | 0.674    |\n",
            "|    value_loss         | 0.00526  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 383/600: Total Reward = -0.09\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.91     |\n",
            "|    ep_rew_mean        | -0.316   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 85       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 319470   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.9     |\n",
            "|    explained_variance | 0.962    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 63893    |\n",
            "|    policy_loss        | 0.155    |\n",
            "|    std                | 0.674    |\n",
            "|    value_loss         | 0.00134  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 384/600: Total Reward = -0.36\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.46     |\n",
            "|    ep_rew_mean        | -0.465   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 148      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 320305   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.9     |\n",
            "|    explained_variance | -0.555   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 64060    |\n",
            "|    policy_loss        | 2.33     |\n",
            "|    std                | 0.674    |\n",
            "|    value_loss         | 0.161    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 385/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.72     |\n",
            "|    ep_rew_mean        | -0.455   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 99       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 321140   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.94    |\n",
            "|    explained_variance | -0.446   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 64227    |\n",
            "|    policy_loss        | -0.962   |\n",
            "|    std                | 0.679    |\n",
            "|    value_loss         | 0.0226   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 386/600: Total Reward = -0.05\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.11     |\n",
            "|    ep_rew_mean        | -0.329   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 141      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 321975   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.95    |\n",
            "|    explained_variance | 0.188    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 64394    |\n",
            "|    policy_loss        | 0.337    |\n",
            "|    std                | 0.68     |\n",
            "|    value_loss         | 0.0108   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 387/600: Total Reward = -0.60\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.66     |\n",
            "|    ep_rew_mean        | -0.393   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 145      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 322810   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.94    |\n",
            "|    explained_variance | -0.774   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 64561    |\n",
            "|    policy_loss        | 0.387    |\n",
            "|    std                | 0.678    |\n",
            "|    value_loss         | 0.00816  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 388/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.12     |\n",
            "|    ep_rew_mean        | -0.42    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 124      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 323645   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.92    |\n",
            "|    explained_variance | 0.947    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 64728    |\n",
            "|    policy_loss        | -0.254   |\n",
            "|    std                | 0.676    |\n",
            "|    value_loss         | 0.00283  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 389/600: Total Reward = -0.30\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.43     |\n",
            "|    ep_rew_mean        | -0.351   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 150      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 324480   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.95    |\n",
            "|    explained_variance | 0.773    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 64895    |\n",
            "|    policy_loss        | 0.486    |\n",
            "|    std                | 0.678    |\n",
            "|    value_loss         | 0.0126   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 390/600: Total Reward = -0.34\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.03     |\n",
            "|    ep_rew_mean        | -0.335   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 325315   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.96    |\n",
            "|    explained_variance | 0.858    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 65062    |\n",
            "|    policy_loss        | -0.468   |\n",
            "|    std                | 0.68     |\n",
            "|    value_loss         | 0.00527  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 391/600: Total Reward = -0.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.21     |\n",
            "|    ep_rew_mean        | -0.334   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 139      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 326150   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.94    |\n",
            "|    explained_variance | 0.596    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 65229    |\n",
            "|    policy_loss        | 0.138    |\n",
            "|    std                | 0.679    |\n",
            "|    value_loss         | 0.0025   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 392/600: Total Reward = -0.22\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.07     |\n",
            "|    ep_rew_mean        | -0.313   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 94       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 326985   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.93    |\n",
            "|    explained_variance | 0.816    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 65396    |\n",
            "|    policy_loss        | 0.266    |\n",
            "|    std                | 0.678    |\n",
            "|    value_loss         | 0.00524  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 393/600: Total Reward = -0.23\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.69     |\n",
            "|    ep_rew_mean        | -0.279   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 138      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 327820   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.93    |\n",
            "|    explained_variance | 0.925    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 65563    |\n",
            "|    policy_loss        | -0.165   |\n",
            "|    std                | 0.678    |\n",
            "|    value_loss         | 0.00237  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 394/600: Total Reward = -0.40\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.91     |\n",
            "|    ep_rew_mean        | -0.313   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 132      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 328655   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.93    |\n",
            "|    explained_variance | 0.984    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 65730    |\n",
            "|    policy_loss        | -0.129   |\n",
            "|    std                | 0.677    |\n",
            "|    value_loss         | 0.00095  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 395/600: Total Reward = -0.43\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.9      |\n",
            "|    ep_rew_mean        | -0.319   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 67       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 329490   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.92    |\n",
            "|    explained_variance | 0.884    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 65897    |\n",
            "|    policy_loss        | 0.473    |\n",
            "|    std                | 0.676    |\n",
            "|    value_loss         | 0.00597  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 396/600: Total Reward = -0.34\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.66     |\n",
            "|    ep_rew_mean        | -0.291   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 84       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 330325   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.89    |\n",
            "|    explained_variance | 0.976    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 66064    |\n",
            "|    policy_loss        | 0.166    |\n",
            "|    std                | 0.673    |\n",
            "|    value_loss         | 0.000944 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 397/600: Total Reward = -0.56\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.73     |\n",
            "|    ep_rew_mean        | -0.29    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 131      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 331160   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.87    |\n",
            "|    explained_variance | 0.98     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 66231    |\n",
            "|    policy_loss        | 0.172    |\n",
            "|    std                | 0.67     |\n",
            "|    value_loss         | 0.00132  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 398/600: Total Reward = -0.42\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.12     |\n",
            "|    ep_rew_mean        | -0.324   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 108      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 331995   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.88    |\n",
            "|    explained_variance | 0.699    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 66398    |\n",
            "|    policy_loss        | -0.255   |\n",
            "|    std                | 0.672    |\n",
            "|    value_loss         | 0.00258  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 399/600: Total Reward = -0.35\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.87     |\n",
            "|    ep_rew_mean        | -0.307   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 142      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 332830   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.88    |\n",
            "|    explained_variance | 0.842    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 66565    |\n",
            "|    policy_loss        | 0.0753   |\n",
            "|    std                | 0.67     |\n",
            "|    value_loss         | 0.00117  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 400/600: Total Reward = -0.31\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.84     |\n",
            "|    ep_rew_mean        | -0.311   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 135      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 333665   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.82    |\n",
            "|    explained_variance | 0.751    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 66732    |\n",
            "|    policy_loss        | -0.0103  |\n",
            "|    std                | 0.665    |\n",
            "|    value_loss         | 0.00488  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 401/600: Total Reward = -0.07\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.82     |\n",
            "|    ep_rew_mean        | -0.306   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 114      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 334500   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.82    |\n",
            "|    explained_variance | 0.699    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 66899    |\n",
            "|    policy_loss        | 0.388    |\n",
            "|    std                | 0.666    |\n",
            "|    value_loss         | 0.00593  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 402/600: Total Reward = -0.25\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.65     |\n",
            "|    ep_rew_mean        | -0.298   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 132      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 335335   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.79    |\n",
            "|    explained_variance | 0.894    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 67066    |\n",
            "|    policy_loss        | 0.448    |\n",
            "|    std                | 0.662    |\n",
            "|    value_loss         | 0.00662  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 403/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.97     |\n",
            "|    ep_rew_mean        | -0.339   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 86       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 336170   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.79    |\n",
            "|    explained_variance | 0.966    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 67233    |\n",
            "|    policy_loss        | -0.2     |\n",
            "|    std                | 0.663    |\n",
            "|    value_loss         | 0.000921 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 404/600: Total Reward = -0.64\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.11     |\n",
            "|    ep_rew_mean        | -0.329   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 137      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 337005   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.76    |\n",
            "|    explained_variance | 0.855    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 67400    |\n",
            "|    policy_loss        | 0.697    |\n",
            "|    std                | 0.66     |\n",
            "|    value_loss         | 0.0101   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 405/600: Total Reward = -0.87\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.04     |\n",
            "|    ep_rew_mean        | -0.325   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 86       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 337840   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.75    |\n",
            "|    explained_variance | 0.833    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 67567    |\n",
            "|    policy_loss        | -0.317   |\n",
            "|    std                | 0.66     |\n",
            "|    value_loss         | 0.00458  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 406/600: Total Reward = -0.61\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.05     |\n",
            "|    ep_rew_mean        | -0.329   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 135      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 338675   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.72    |\n",
            "|    explained_variance | 0.979    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 67734    |\n",
            "|    policy_loss        | 0.399    |\n",
            "|    std                | 0.657    |\n",
            "|    value_loss         | 0.0035   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 407/600: Total Reward = -0.32\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.76     |\n",
            "|    ep_rew_mean        | -0.303   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 111      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 339510   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.74    |\n",
            "|    explained_variance | 0.994    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 67901    |\n",
            "|    policy_loss        | 0.315    |\n",
            "|    std                | 0.658    |\n",
            "|    value_loss         | 0.00248  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 408/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.96     |\n",
            "|    ep_rew_mean        | -0.32    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 143      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 340345   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.7     |\n",
            "|    explained_variance | 0.686    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 68068    |\n",
            "|    policy_loss        | 0.423    |\n",
            "|    std                | 0.655    |\n",
            "|    value_loss         | 0.0103   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 409/600: Total Reward = -0.72\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.07     |\n",
            "|    ep_rew_mean        | -0.332   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 135      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 341180   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.67    |\n",
            "|    explained_variance | 0.948    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 68235    |\n",
            "|    policy_loss        | 0.323    |\n",
            "|    std                | 0.652    |\n",
            "|    value_loss         | 0.00532  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 410/600: Total Reward = -0.16\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.17     |\n",
            "|    ep_rew_mean        | -0.328   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 100      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 342015   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.67    |\n",
            "|    explained_variance | 0.949    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 68402    |\n",
            "|    policy_loss        | 0.0739   |\n",
            "|    std                | 0.651    |\n",
            "|    value_loss         | 0.000284 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 411/600: Total Reward = -0.29\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.55     |\n",
            "|    ep_rew_mean        | -0.283   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 132      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 342850   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.66    |\n",
            "|    explained_variance | 0.958    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 68569    |\n",
            "|    policy_loss        | -0.0214  |\n",
            "|    std                | 0.651    |\n",
            "|    value_loss         | 0.00108  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 412/600: Total Reward = -0.10\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.57     |\n",
            "|    ep_rew_mean        | -0.385   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 82       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 343685   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.62    |\n",
            "|    explained_variance | 0.886    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 68736    |\n",
            "|    policy_loss        | -0.209   |\n",
            "|    std                | 0.647    |\n",
            "|    value_loss         | 0.00253  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 413/600: Total Reward = -0.20\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.6      |\n",
            "|    ep_rew_mean        | -0.284   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 136      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 344520   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.57    |\n",
            "|    explained_variance | 0.933    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 68903    |\n",
            "|    policy_loss        | 0.0325   |\n",
            "|    std                | 0.644    |\n",
            "|    value_loss         | 0.000586 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 414/600: Total Reward = -0.24\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.05     |\n",
            "|    ep_rew_mean        | -0.326   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 85       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 345355   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.57    |\n",
            "|    explained_variance | 0.654    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 69070    |\n",
            "|    policy_loss        | -0.126   |\n",
            "|    std                | 0.644    |\n",
            "|    value_loss         | 0.0016   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 415/600: Total Reward = -0.34\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.55     |\n",
            "|    ep_rew_mean        | -0.286   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 136      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 346190   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.55    |\n",
            "|    explained_variance | 0.968    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 69237    |\n",
            "|    policy_loss        | 0.283    |\n",
            "|    std                | 0.642    |\n",
            "|    value_loss         | 0.00172  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 416/600: Total Reward = -0.27\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.69     |\n",
            "|    ep_rew_mean        | -0.296   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 103      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 347025   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.51    |\n",
            "|    explained_variance | 0.962    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 69404    |\n",
            "|    policy_loss        | 0.049    |\n",
            "|    std                | 0.639    |\n",
            "|    value_loss         | 0.00227  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 417/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.05     |\n",
            "|    ep_rew_mean        | -0.32    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 143      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 347860   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.52    |\n",
            "|    explained_variance | 0.892    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 69571    |\n",
            "|    policy_loss        | 0.246    |\n",
            "|    std                | 0.64     |\n",
            "|    value_loss         | 0.00958  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 418/600: Total Reward = -0.47\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.54     |\n",
            "|    ep_rew_mean        | -0.351   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 136      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 348695   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.51    |\n",
            "|    explained_variance | -0.18    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 69738    |\n",
            "|    policy_loss        | -1.38    |\n",
            "|    std                | 0.638    |\n",
            "|    value_loss         | 0.0554   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 419/600: Total Reward = -0.16\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.86     |\n",
            "|    ep_rew_mean        | -0.308   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 112      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 349530   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.51    |\n",
            "|    explained_variance | 0.999    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 69905    |\n",
            "|    policy_loss        | 0.101    |\n",
            "|    std                | 0.637    |\n",
            "|    value_loss         | 0.000245 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 420/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.71     |\n",
            "|    ep_rew_mean        | -0.286   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 139      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 350365   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.5     |\n",
            "|    explained_variance | -0.475   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 70072    |\n",
            "|    policy_loss        | -0.611   |\n",
            "|    std                | 0.637    |\n",
            "|    value_loss         | 0.0413   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 421/600: Total Reward = -0.41\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.42     |\n",
            "|    ep_rew_mean        | -0.276   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 80       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 351200   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.48    |\n",
            "|    explained_variance | 0.836    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 70239    |\n",
            "|    policy_loss        | -0.23    |\n",
            "|    std                | 0.636    |\n",
            "|    value_loss         | 0.00232  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 422/600: Total Reward = -0.64\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.04     |\n",
            "|    ep_rew_mean        | -0.324   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 137      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 352035   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.47    |\n",
            "|    explained_variance | 0.979    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 70406    |\n",
            "|    policy_loss        | -0.117   |\n",
            "|    std                | 0.636    |\n",
            "|    value_loss         | 0.00089  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 423/600: Total Reward = -0.70\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.89     |\n",
            "|    ep_rew_mean        | -0.295   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 352870   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.46    |\n",
            "|    explained_variance | 0.881    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 70573    |\n",
            "|    policy_loss        | -0.0739  |\n",
            "|    std                | 0.633    |\n",
            "|    value_loss         | 0.00098  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 424/600: Total Reward = -0.25\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.03     |\n",
            "|    ep_rew_mean        | -0.323   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 132      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 353705   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.43    |\n",
            "|    explained_variance | 0.983    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 70740    |\n",
            "|    policy_loss        | -0.095   |\n",
            "|    std                | 0.631    |\n",
            "|    value_loss         | 0.000518 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 425/600: Total Reward = -1.03\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.89     |\n",
            "|    ep_rew_mean        | -0.315   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 86       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 354540   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.44    |\n",
            "|    explained_variance | 0.528    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 70907    |\n",
            "|    policy_loss        | -0.747   |\n",
            "|    std                | 0.632    |\n",
            "|    value_loss         | 0.0215   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 426/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.96     |\n",
            "|    ep_rew_mean        | -0.325   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 133      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 355375   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.42    |\n",
            "|    explained_variance | 0.987    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 71074    |\n",
            "|    policy_loss        | -0.231   |\n",
            "|    std                | 0.631    |\n",
            "|    value_loss         | 0.00136  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 427/600: Total Reward = -0.45\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.72     |\n",
            "|    ep_rew_mean        | -0.295   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 112      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 356210   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.38    |\n",
            "|    explained_variance | 0.996    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 71241    |\n",
            "|    policy_loss        | -0.11    |\n",
            "|    std                | 0.627    |\n",
            "|    value_loss         | 0.000295 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 428/600: Total Reward = -0.21\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.8      |\n",
            "|    ep_rew_mean        | -0.304   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 140      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 357045   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.35    |\n",
            "|    explained_variance | -0.314   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 71408    |\n",
            "|    policy_loss        | -0.275   |\n",
            "|    std                | 0.625    |\n",
            "|    value_loss         | 0.0126   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 429/600: Total Reward = -0.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.84     |\n",
            "|    ep_rew_mean        | -0.317   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 135      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 357880   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.29    |\n",
            "|    explained_variance | 0.99     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 71575    |\n",
            "|    policy_loss        | 0.27     |\n",
            "|    std                | 0.619    |\n",
            "|    value_loss         | 0.00176  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 430/600: Total Reward = -0.23\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.46     |\n",
            "|    ep_rew_mean        | -0.374   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 105      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 358715   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.31    |\n",
            "|    explained_variance | 0.94     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 71742    |\n",
            "|    policy_loss        | 0.128    |\n",
            "|    std                | 0.621    |\n",
            "|    value_loss         | 0.00311  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 431/600: Total Reward = -0.35\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.81     |\n",
            "|    ep_rew_mean        | -0.315   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 134      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 359550   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.31    |\n",
            "|    explained_variance | 0.932    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 71909    |\n",
            "|    policy_loss        | 0.485    |\n",
            "|    std                | 0.621    |\n",
            "|    value_loss         | 0.00711  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 432/600: Total Reward = -0.15\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.82     |\n",
            "|    ep_rew_mean        | -0.309   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 360385   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.27    |\n",
            "|    explained_variance | 0.923    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 72076    |\n",
            "|    policy_loss        | 0.224    |\n",
            "|    std                | 0.617    |\n",
            "|    value_loss         | 0.00297  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 433/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.73     |\n",
            "|    ep_rew_mean        | -0.299   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 129      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 361220   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.28    |\n",
            "|    explained_variance | 0.763    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 72243    |\n",
            "|    policy_loss        | -0.206   |\n",
            "|    std                | 0.619    |\n",
            "|    value_loss         | 0.00127  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 434/600: Total Reward = -0.07\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.77     |\n",
            "|    ep_rew_mean        | -0.298   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 79       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 362055   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.27    |\n",
            "|    explained_variance | 0.988    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 72410    |\n",
            "|    policy_loss        | -0.36    |\n",
            "|    std                | 0.618    |\n",
            "|    value_loss         | 0.00439  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 435/600: Total Reward = -0.37\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.1      |\n",
            "|    ep_rew_mean        | -0.339   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 124      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 362890   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.29    |\n",
            "|    explained_variance | 0.526    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 72577    |\n",
            "|    policy_loss        | -0.112   |\n",
            "|    std                | 0.62     |\n",
            "|    value_loss         | 0.00698  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 436/600: Total Reward = -0.15\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.64     |\n",
            "|    ep_rew_mean        | -0.3     |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 363725   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.3     |\n",
            "|    explained_variance | 0.967    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 72744    |\n",
            "|    policy_loss        | 0.462    |\n",
            "|    std                | 0.62     |\n",
            "|    value_loss         | 0.0121   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 437/600: Total Reward = -0.30\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.25     |\n",
            "|    ep_rew_mean        | -0.438   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 132      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 364560   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.25    |\n",
            "|    explained_variance | 0.965    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 72911    |\n",
            "|    policy_loss        | 0.0682   |\n",
            "|    std                | 0.617    |\n",
            "|    value_loss         | 0.00111  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 438/600: Total Reward = -0.17\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.86     |\n",
            "|    ep_rew_mean        | -0.306   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 91       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 365395   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.25    |\n",
            "|    explained_variance | 0.601    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 73078    |\n",
            "|    policy_loss        | -0.559   |\n",
            "|    std                | 0.617    |\n",
            "|    value_loss         | 0.00845  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 439/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.87     |\n",
            "|    ep_rew_mean        | -0.336   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 135      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 366230   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.29    |\n",
            "|    explained_variance | 0.986    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 73245    |\n",
            "|    policy_loss        | 0.476    |\n",
            "|    std                | 0.62     |\n",
            "|    value_loss         | 0.00799  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 440/600: Total Reward = -0.24\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.6      |\n",
            "|    ep_rew_mean        | -0.389   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 116      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 367065   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.27    |\n",
            "|    explained_variance | 0.552    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 73412    |\n",
            "|    policy_loss        | 0.0433   |\n",
            "|    std                | 0.618    |\n",
            "|    value_loss         | 0.00165  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 441/600: Total Reward = -0.33\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.63     |\n",
            "|    ep_rew_mean        | -0.368   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 130      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 367900   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.29    |\n",
            "|    explained_variance | 0.222    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 73579    |\n",
            "|    policy_loss        | -0.941   |\n",
            "|    std                | 0.619    |\n",
            "|    value_loss         | 0.0356   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 442/600: Total Reward = -0.60\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.05     |\n",
            "|    ep_rew_mean        | -0.33    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 123      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 368735   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.29    |\n",
            "|    explained_variance | 0.789    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 73746    |\n",
            "|    policy_loss        | 0.099    |\n",
            "|    std                | 0.618    |\n",
            "|    value_loss         | 0.00123  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 443/600: Total Reward = -0.28\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.95     |\n",
            "|    ep_rew_mean        | -0.32    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 115      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 369570   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.28    |\n",
            "|    explained_variance | 0.702    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 73913    |\n",
            "|    policy_loss        | -0.399   |\n",
            "|    std                | 0.617    |\n",
            "|    value_loss         | 0.00932  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 444/600: Total Reward = -0.02\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.29     |\n",
            "|    ep_rew_mean        | -0.348   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 124      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 370405   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.29    |\n",
            "|    explained_variance | 0.965    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 74080    |\n",
            "|    policy_loss        | -0.402   |\n",
            "|    std                | 0.619    |\n",
            "|    value_loss         | 0.00599  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 445/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.51     |\n",
            "|    ep_rew_mean        | -0.287   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 106      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 371240   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.3     |\n",
            "|    explained_variance | 0.903    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 74247    |\n",
            "|    policy_loss        | -0.473   |\n",
            "|    std                | 0.619    |\n",
            "|    value_loss         | 0.00389  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 446/600: Total Reward = -0.46\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.93     |\n",
            "|    ep_rew_mean        | -0.312   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 123      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 372075   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.28    |\n",
            "|    explained_variance | 0.849    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 74414    |\n",
            "|    policy_loss        | 0.642    |\n",
            "|    std                | 0.617    |\n",
            "|    value_loss         | 0.00972  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 447/600: Total Reward = -0.59\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.37     |\n",
            "|    ep_rew_mean        | -0.276   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 93       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 372910   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.28    |\n",
            "|    explained_variance | 0.975    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 74581    |\n",
            "|    policy_loss        | 0.0328   |\n",
            "|    std                | 0.618    |\n",
            "|    value_loss         | 0.00117  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 448/600: Total Reward = -0.38\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.72     |\n",
            "|    ep_rew_mean        | -0.307   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 125      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 373745   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.29    |\n",
            "|    explained_variance | 0.996    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 74748    |\n",
            "|    policy_loss        | -0.238   |\n",
            "|    std                | 0.618    |\n",
            "|    value_loss         | 0.00211  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 449/600: Total Reward = -0.23\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.96     |\n",
            "|    ep_rew_mean        | -0.331   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 86       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 374580   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.28    |\n",
            "|    explained_variance | 0.988    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 74915    |\n",
            "|    policy_loss        | -0.0917  |\n",
            "|    std                | 0.618    |\n",
            "|    value_loss         | 0.000394 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 450/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.5      |\n",
            "|    ep_rew_mean        | -0.399   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 120      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 375415   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.27    |\n",
            "|    explained_variance | 0.977    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 75082    |\n",
            "|    policy_loss        | 0.136    |\n",
            "|    std                | 0.617    |\n",
            "|    value_loss         | 0.000604 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 451/600: Total Reward = -0.08\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.99     |\n",
            "|    ep_rew_mean        | -0.329   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 376250   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.25    |\n",
            "|    explained_variance | 0.987    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 75249    |\n",
            "|    policy_loss        | 0.162    |\n",
            "|    std                | 0.616    |\n",
            "|    value_loss         | 0.000942 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 452/600: Total Reward = -0.20\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.98     |\n",
            "|    ep_rew_mean        | -0.343   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 123      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 377085   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.26    |\n",
            "|    explained_variance | 0.962    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 75416    |\n",
            "|    policy_loss        | 0.216    |\n",
            "|    std                | 0.616    |\n",
            "|    value_loss         | 0.00184  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 453/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.99     |\n",
            "|    ep_rew_mean        | -0.334   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 377920   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.29    |\n",
            "|    explained_variance | 0.943    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 75583    |\n",
            "|    policy_loss        | 0.56     |\n",
            "|    std                | 0.618    |\n",
            "|    value_loss         | 0.0135   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 454/600: Total Reward = -0.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.29     |\n",
            "|    ep_rew_mean        | -0.345   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 125      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 378755   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.26    |\n",
            "|    explained_variance | 0.989    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 75750    |\n",
            "|    policy_loss        | 0.415    |\n",
            "|    std                | 0.615    |\n",
            "|    value_loss         | 0.00759  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 455/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.27     |\n",
            "|    ep_rew_mean        | -0.342   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 379590   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.22    |\n",
            "|    explained_variance | 0.987    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 75917    |\n",
            "|    policy_loss        | -1.06    |\n",
            "|    std                | 0.611    |\n",
            "|    value_loss         | 0.0222   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 456/600: Total Reward = -0.27\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.96     |\n",
            "|    ep_rew_mean        | -0.317   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 130      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 380425   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.23    |\n",
            "|    explained_variance | -0.0219  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 76084    |\n",
            "|    policy_loss        | -0.933   |\n",
            "|    std                | 0.614    |\n",
            "|    value_loss         | 0.0565   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 457/600: Total Reward = -0.81\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4        |\n",
            "|    ep_rew_mean        | -0.33    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 381260   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.22    |\n",
            "|    explained_variance | 0.985    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 76251    |\n",
            "|    policy_loss        | 0.102    |\n",
            "|    std                | 0.612    |\n",
            "|    value_loss         | 0.00187  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 458/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.6      |\n",
            "|    ep_rew_mean        | -0.279   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 126      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 382095   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.21    |\n",
            "|    explained_variance | 0.903    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 76418    |\n",
            "|    policy_loss        | -0.396   |\n",
            "|    std                | 0.613    |\n",
            "|    value_loss         | 0.0055   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 459/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.95     |\n",
            "|    ep_rew_mean        | -0.314   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 382930   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.17    |\n",
            "|    explained_variance | 0.253    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 76585    |\n",
            "|    policy_loss        | -0.343   |\n",
            "|    std                | 0.61     |\n",
            "|    value_loss         | 0.0118   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 460/600: Total Reward = -0.22\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.14     |\n",
            "|    ep_rew_mean        | -0.336   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 115      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 383765   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.18    |\n",
            "|    explained_variance | 0.908    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 76752    |\n",
            "|    policy_loss        | -0.0353  |\n",
            "|    std                | 0.611    |\n",
            "|    value_loss         | 0.000821 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 461/600: Total Reward = -0.15\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.22     |\n",
            "|    ep_rew_mean        | -0.339   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 61       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 384600   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.2     |\n",
            "|    explained_variance | 0.201    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 76919    |\n",
            "|    policy_loss        | 0.334    |\n",
            "|    std                | 0.613    |\n",
            "|    value_loss         | 0.00566  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 462/600: Total Reward = -0.32\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4        |\n",
            "|    ep_rew_mean        | -0.319   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 95       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 385435   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.17    |\n",
            "|    explained_variance | 0.944    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 77086    |\n",
            "|    policy_loss        | 0.105    |\n",
            "|    std                | 0.61     |\n",
            "|    value_loss         | 0.000706 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 463/600: Total Reward = -0.23\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.38     |\n",
            "|    ep_rew_mean        | -0.347   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 126      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 386270   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.16    |\n",
            "|    explained_variance | 0.776    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 77253    |\n",
            "|    policy_loss        | 0.508    |\n",
            "|    std                | 0.61     |\n",
            "|    value_loss         | 0.00696  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 464/600: Total Reward = -0.34\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.93     |\n",
            "|    ep_rew_mean        | -0.316   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 90       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 387105   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.15    |\n",
            "|    explained_variance | 0.953    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 77420    |\n",
            "|    policy_loss        | -0.544   |\n",
            "|    std                | 0.608    |\n",
            "|    value_loss         | 0.00598  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 465/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.46     |\n",
            "|    ep_rew_mean        | -0.367   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 118      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 387940   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.13    |\n",
            "|    explained_variance | 0.934    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 77587    |\n",
            "|    policy_loss        | 0.511    |\n",
            "|    std                | 0.606    |\n",
            "|    value_loss         | 0.0118   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 466/600: Total Reward = -0.29\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.39     |\n",
            "|    ep_rew_mean        | -0.477   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 82       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 388775   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.11    |\n",
            "|    explained_variance | 0.839    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 77754    |\n",
            "|    policy_loss        | -0.432   |\n",
            "|    std                | 0.604    |\n",
            "|    value_loss         | 0.00884  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 467/600: Total Reward = -0.25\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.03     |\n",
            "|    ep_rew_mean        | -0.354   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 114      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 389610   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.09    |\n",
            "|    explained_variance | -0.0693  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 77921    |\n",
            "|    policy_loss        | 2.16     |\n",
            "|    std                | 0.603    |\n",
            "|    value_loss         | 0.165    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 468/600: Total Reward = -0.03\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.78     |\n",
            "|    ep_rew_mean        | -0.4     |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 73       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 390445   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.11    |\n",
            "|    explained_variance | 0.974    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 78088    |\n",
            "|    policy_loss        | 0.0607   |\n",
            "|    std                | 0.606    |\n",
            "|    value_loss         | 0.000318 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 469/600: Total Reward = -0.23\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.72     |\n",
            "|    ep_rew_mean        | -0.389   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 119      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 391280   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.1     |\n",
            "|    explained_variance | 0.989    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 78255    |\n",
            "|    policy_loss        | 0.169    |\n",
            "|    std                | 0.604    |\n",
            "|    value_loss         | 0.000894 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 470/600: Total Reward = -0.36\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.71     |\n",
            "|    ep_rew_mean        | -0.285   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 74       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 392115   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.11    |\n",
            "|    explained_variance | 0.81     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 78422    |\n",
            "|    policy_loss        | 0.815    |\n",
            "|    std                | 0.606    |\n",
            "|    value_loss         | 0.0179   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 471/600: Total Reward = -0.71\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.65     |\n",
            "|    ep_rew_mean        | -0.296   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 127      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 392950   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.07    |\n",
            "|    explained_variance | 0.888    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 78589    |\n",
            "|    policy_loss        | 0.253    |\n",
            "|    std                | 0.602    |\n",
            "|    value_loss         | 0.0038   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 472/600: Total Reward = -0.38\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.58     |\n",
            "|    ep_rew_mean        | -0.282   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 393785   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.06    |\n",
            "|    explained_variance | 0.737    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 78756    |\n",
            "|    policy_loss        | 0.548    |\n",
            "|    std                | 0.602    |\n",
            "|    value_loss         | 0.0127   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 473/600: Total Reward = -0.30\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.47     |\n",
            "|    ep_rew_mean        | -0.262   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 127      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 394620   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.04    |\n",
            "|    explained_variance | 0.955    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 78923    |\n",
            "|    policy_loss        | -0.109   |\n",
            "|    std                | 0.6      |\n",
            "|    value_loss         | 0.00212  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 474/600: Total Reward = -1.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.97     |\n",
            "|    ep_rew_mean        | -0.32    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 74       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 395455   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.01    |\n",
            "|    explained_variance | 0.984    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 79090    |\n",
            "|    policy_loss        | 0.104    |\n",
            "|    std                | 0.598    |\n",
            "|    value_loss         | 0.000562 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 475/600: Total Reward = -0.45\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.1      |\n",
            "|    ep_rew_mean        | -0.34    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 131      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 396290   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.99    |\n",
            "|    explained_variance | 0.504    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 79257    |\n",
            "|    policy_loss        | -0.614   |\n",
            "|    std                | 0.596    |\n",
            "|    value_loss         | 0.0092   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 476/600: Total Reward = -0.33\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.12     |\n",
            "|    ep_rew_mean        | -0.342   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 74       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 397125   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.01    |\n",
            "|    explained_variance | 0.696    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 79424    |\n",
            "|    policy_loss        | -0.382   |\n",
            "|    std                | 0.598    |\n",
            "|    value_loss         | 0.00792  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 477/600: Total Reward = -0.35\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.02     |\n",
            "|    ep_rew_mean        | -0.325   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 122      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 397960   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.99    |\n",
            "|    explained_variance | 0.921    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 79591    |\n",
            "|    policy_loss        | -0.296   |\n",
            "|    std                | 0.596    |\n",
            "|    value_loss         | 0.00324  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 478/600: Total Reward = -0.15\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.6      |\n",
            "|    ep_rew_mean        | -0.276   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 72       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 398795   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.96    |\n",
            "|    explained_variance | 0.99     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 79758    |\n",
            "|    policy_loss        | -0.257   |\n",
            "|    std                | 0.592    |\n",
            "|    value_loss         | 0.00125  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 479/600: Total Reward = -0.44\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.81     |\n",
            "|    ep_rew_mean        | -0.306   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 122      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 399630   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.96    |\n",
            "|    explained_variance | 0.786    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 79925    |\n",
            "|    policy_loss        | -0.259   |\n",
            "|    std                | 0.592    |\n",
            "|    value_loss         | 0.00329  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 480/600: Total Reward = -0.25\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.33     |\n",
            "|    ep_rew_mean        | -0.263   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 400465   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.95    |\n",
            "|    explained_variance | 0.989    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 80092    |\n",
            "|    policy_loss        | -0.0605  |\n",
            "|    std                | 0.591    |\n",
            "|    value_loss         | 0.000203 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 481/600: Total Reward = -0.21\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.26     |\n",
            "|    ep_rew_mean        | -0.338   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 125      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 401300   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.9     |\n",
            "|    explained_variance | 0.97     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 80259    |\n",
            "|    policy_loss        | -0.295   |\n",
            "|    std                | 0.588    |\n",
            "|    value_loss         | 0.00301  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 482/600: Total Reward = -0.05\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.26     |\n",
            "|    ep_rew_mean        | -0.351   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 402135   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.9     |\n",
            "|    explained_variance | 0.844    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 80426    |\n",
            "|    policy_loss        | -0.185   |\n",
            "|    std                | 0.589    |\n",
            "|    value_loss         | 0.000988 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 483/600: Total Reward = -0.34\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.23     |\n",
            "|    ep_rew_mean        | -0.354   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 126      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 402970   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.93    |\n",
            "|    explained_variance | 0.54     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 80593    |\n",
            "|    policy_loss        | 0.166    |\n",
            "|    std                | 0.592    |\n",
            "|    value_loss         | 0.00156  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 484/600: Total Reward = -0.27\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.87     |\n",
            "|    ep_rew_mean        | -0.321   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 403805   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.93    |\n",
            "|    explained_variance | 0.983    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 80760    |\n",
            "|    policy_loss        | -0.169   |\n",
            "|    std                | 0.593    |\n",
            "|    value_loss         | 0.00128  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 485/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.83     |\n",
            "|    ep_rew_mean        | -0.318   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 129      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 404640   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.95    |\n",
            "|    explained_variance | 0.94     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 80927    |\n",
            "|    policy_loss        | -0.00603 |\n",
            "|    std                | 0.595    |\n",
            "|    value_loss         | 0.000731 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 486/600: Total Reward = -0.17\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.9      |\n",
            "|    ep_rew_mean        | -0.322   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 405475   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6       |\n",
            "|    explained_variance | 0.971    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 81094    |\n",
            "|    policy_loss        | -0.0625  |\n",
            "|    std                | 0.598    |\n",
            "|    value_loss         | 0.000517 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 487/600: Total Reward = -0.30\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.97     |\n",
            "|    ep_rew_mean        | -0.406   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 121      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 406310   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.05    |\n",
            "|    explained_variance | 0.785    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 81261    |\n",
            "|    policy_loss        | 0.111    |\n",
            "|    std                | 0.602    |\n",
            "|    value_loss         | 0.0034   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 488/600: Total Reward = -0.39\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.12     |\n",
            "|    ep_rew_mean        | -0.339   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 96       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 407145   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.06    |\n",
            "|    explained_variance | 0.86     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 81428    |\n",
            "|    policy_loss        | -0.779   |\n",
            "|    std                | 0.602    |\n",
            "|    value_loss         | 0.0267   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 489/600: Total Reward = -0.33\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.12     |\n",
            "|    ep_rew_mean        | -0.325   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 116      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 407980   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6       |\n",
            "|    explained_variance | 0.968    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 81595    |\n",
            "|    policy_loss        | -0.255   |\n",
            "|    std                | 0.598    |\n",
            "|    value_loss         | 0.00208  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 490/600: Total Reward = -0.38\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.31     |\n",
            "|    ep_rew_mean        | -0.262   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 107      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 408815   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6       |\n",
            "|    explained_variance | 0.975    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 81762    |\n",
            "|    policy_loss        | 0.301    |\n",
            "|    std                | 0.598    |\n",
            "|    value_loss         | 0.00473  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 491/600: Total Reward = -0.10\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.54     |\n",
            "|    ep_rew_mean        | -0.285   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 124      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 409650   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.97    |\n",
            "|    explained_variance | 0.969    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 81929    |\n",
            "|    policy_loss        | 0.355    |\n",
            "|    std                | 0.597    |\n",
            "|    value_loss         | 0.00462  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 492/600: Total Reward = -0.08\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.79     |\n",
            "|    ep_rew_mean        | -0.315   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 125      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 410485   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.98    |\n",
            "|    explained_variance | 0.98     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 82096    |\n",
            "|    policy_loss        | 0.145    |\n",
            "|    std                | 0.597    |\n",
            "|    value_loss         | 0.00152  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 493/600: Total Reward = -0.51\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.52     |\n",
            "|    ep_rew_mean        | -0.384   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 109      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 411320   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.95    |\n",
            "|    explained_variance | 0.974    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 82263    |\n",
            "|    policy_loss        | 0.314    |\n",
            "|    std                | 0.596    |\n",
            "|    value_loss         | 0.0022   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 494/600: Total Reward = -0.02\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.76     |\n",
            "|    ep_rew_mean        | -0.299   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 125      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 412155   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.94    |\n",
            "|    explained_variance | 0.994    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 82430    |\n",
            "|    policy_loss        | 0.285    |\n",
            "|    std                | 0.596    |\n",
            "|    value_loss         | 0.00307  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 495/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.76     |\n",
            "|    ep_rew_mean        | -0.304   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 90       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 412990   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.92    |\n",
            "|    explained_variance | -0.572   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 82597    |\n",
            "|    policy_loss        | -0.635   |\n",
            "|    std                | 0.595    |\n",
            "|    value_loss         | 0.035    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 496/600: Total Reward = -0.09\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.08     |\n",
            "|    ep_rew_mean        | -0.35    |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 125      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 413825   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.96    |\n",
            "|    explained_variance | 0.982    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 82764    |\n",
            "|    policy_loss        | 0.125    |\n",
            "|    std                | 0.599    |\n",
            "|    value_loss         | 0.000995 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 497/600: Total Reward = -0.02\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.91     |\n",
            "|    ep_rew_mean        | -0.319   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 414660   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.97    |\n",
            "|    explained_variance | 0.971    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 82931    |\n",
            "|    policy_loss        | -0.0435  |\n",
            "|    std                | 0.599    |\n",
            "|    value_loss         | 0.000421 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 498/600: Total Reward = -0.29\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.48     |\n",
            "|    ep_rew_mean        | -0.377   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 122      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 415495   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.03    |\n",
            "|    explained_variance | 0.991    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 83098    |\n",
            "|    policy_loss        | -0.134   |\n",
            "|    std                | 0.603    |\n",
            "|    value_loss         | 0.00114  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 499/600: Total Reward = -0.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.84     |\n",
            "|    ep_rew_mean        | -0.32    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 416330   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.04    |\n",
            "|    explained_variance | 0.903    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 83265    |\n",
            "|    policy_loss        | 0.243    |\n",
            "|    std                | 0.605    |\n",
            "|    value_loss         | 0.00298  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 500/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.8      |\n",
            "|    ep_rew_mean        | -0.294   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 106      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 417165   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.06    |\n",
            "|    explained_variance | 0.918    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 83432    |\n",
            "|    policy_loss        | 0.301    |\n",
            "|    std                | 0.606    |\n",
            "|    value_loss         | 0.0026   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 501/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.08     |\n",
            "|    ep_rew_mean        | -0.331   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 418000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.05    |\n",
            "|    explained_variance | 0.452    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 83599    |\n",
            "|    policy_loss        | -0.525   |\n",
            "|    std                | 0.604    |\n",
            "|    value_loss         | 0.0271   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 502/600: Total Reward = -0.42\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.16     |\n",
            "|    ep_rew_mean        | -0.345   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 124      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 418835   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.02    |\n",
            "|    explained_variance | 0.964    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 83766    |\n",
            "|    policy_loss        | -0.0578  |\n",
            "|    std                | 0.603    |\n",
            "|    value_loss         | 0.000854 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 503/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.76     |\n",
            "|    ep_rew_mean        | -0.308   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 419670   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.98    |\n",
            "|    explained_variance | 0.125    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 83933    |\n",
            "|    policy_loss        | -0.247   |\n",
            "|    std                | 0.6      |\n",
            "|    value_loss         | 0.00757  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 504/600: Total Reward = -0.62\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.78     |\n",
            "|    ep_rew_mean        | -0.304   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 125      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 420505   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.01    |\n",
            "|    explained_variance | 0.993    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 84100    |\n",
            "|    policy_loss        | 0.44     |\n",
            "|    std                | 0.602    |\n",
            "|    value_loss         | 0.00688  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 505/600: Total Reward = -0.27\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.48     |\n",
            "|    ep_rew_mean        | -0.285   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 421340   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.04    |\n",
            "|    explained_variance | 0.936    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 84267    |\n",
            "|    policy_loss        | 0.117    |\n",
            "|    std                | 0.606    |\n",
            "|    value_loss         | 0.00194  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 506/600: Total Reward = -0.35\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.99     |\n",
            "|    ep_rew_mean        | -0.314   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 125      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 422175   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.05    |\n",
            "|    explained_variance | 0.956    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 84434    |\n",
            "|    policy_loss        | 0.474    |\n",
            "|    std                | 0.606    |\n",
            "|    value_loss         | 0.00556  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 507/600: Total Reward = -0.41\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.74     |\n",
            "|    ep_rew_mean        | -0.307   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 103      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 423010   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.04    |\n",
            "|    explained_variance | 0.915    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 84601    |\n",
            "|    policy_loss        | -0.515   |\n",
            "|    std                | 0.606    |\n",
            "|    value_loss         | 0.00687  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 508/600: Total Reward = -0.16\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.62     |\n",
            "|    ep_rew_mean        | -0.291   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 129      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 423845   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.02    |\n",
            "|    explained_variance | 0.931    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 84768    |\n",
            "|    policy_loss        | 0.248    |\n",
            "|    std                | 0.604    |\n",
            "|    value_loss         | 0.00308  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 509/600: Total Reward = -0.38\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.05     |\n",
            "|    ep_rew_mean        | -0.329   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 133      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 424680   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -6.03    |\n",
            "|    explained_variance | 0.904    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 84935    |\n",
            "|    policy_loss        | -0.0218  |\n",
            "|    std                | 0.606    |\n",
            "|    value_loss         | 0.00205  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 510/600: Total Reward = -0.21\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.08     |\n",
            "|    ep_rew_mean        | -0.321   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 129      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 425515   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.94    |\n",
            "|    explained_variance | 0.975    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 85102    |\n",
            "|    policy_loss        | -0.26    |\n",
            "|    std                | 0.599    |\n",
            "|    value_loss         | 0.0025   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 511/600: Total Reward = -0.09\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.69     |\n",
            "|    ep_rew_mean        | -0.297   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 128      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 426350   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.9     |\n",
            "|    explained_variance | 0.0287   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 85269    |\n",
            "|    policy_loss        | 0.41     |\n",
            "|    std                | 0.595    |\n",
            "|    value_loss         | 0.00898  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 512/600: Total Reward = -0.36\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.94     |\n",
            "|    ep_rew_mean        | -0.308   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 126      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 427185   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.89    |\n",
            "|    explained_variance | 0.802    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 85436    |\n",
            "|    policy_loss        | -0.217   |\n",
            "|    std                | 0.593    |\n",
            "|    value_loss         | 0.00354  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 513/600: Total Reward = -0.42\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.58     |\n",
            "|    ep_rew_mean        | -0.375   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 120      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 428020   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.91    |\n",
            "|    explained_variance | 0.832    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 85603    |\n",
            "|    policy_loss        | -0.0776  |\n",
            "|    std                | 0.594    |\n",
            "|    value_loss         | 0.00141  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 514/600: Total Reward = -0.03\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.65     |\n",
            "|    ep_rew_mean        | -0.296   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 108      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 428855   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.92    |\n",
            "|    explained_variance | 0.964    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 85770    |\n",
            "|    policy_loss        | 0.158    |\n",
            "|    std                | 0.595    |\n",
            "|    value_loss         | 0.00132  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 515/600: Total Reward = -0.17\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.79     |\n",
            "|    ep_rew_mean        | -0.305   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 127      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 429690   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.93    |\n",
            "|    explained_variance | 0.997    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 85937    |\n",
            "|    policy_loss        | 0.19     |\n",
            "|    std                | 0.596    |\n",
            "|    value_loss         | 0.00169  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 516/600: Total Reward = -0.50\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.96     |\n",
            "|    ep_rew_mean        | -0.323   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 80       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 430525   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.92    |\n",
            "|    explained_variance | 0.216    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 86104    |\n",
            "|    policy_loss        | -0.124   |\n",
            "|    std                | 0.596    |\n",
            "|    value_loss         | 0.00559  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 517/600: Total Reward = -0.29\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.94     |\n",
            "|    ep_rew_mean        | -0.321   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 122      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 431360   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.87    |\n",
            "|    explained_variance | 0.624    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 86271    |\n",
            "|    policy_loss        | -0.381   |\n",
            "|    std                | 0.592    |\n",
            "|    value_loss         | 0.0108   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 518/600: Total Reward = -0.11\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.88     |\n",
            "|    ep_rew_mean        | -0.319   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 73       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 432195   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.83    |\n",
            "|    explained_variance | 0.871    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 86438    |\n",
            "|    policy_loss        | 0.59     |\n",
            "|    std                | 0.588    |\n",
            "|    value_loss         | 0.0148   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 519/600: Total Reward = -0.44\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.23     |\n",
            "|    ep_rew_mean        | -0.348   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 130      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 433030   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.86    |\n",
            "|    explained_variance | 0.995    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 86605    |\n",
            "|    policy_loss        | -0.143   |\n",
            "|    std                | 0.589    |\n",
            "|    value_loss         | 0.000786 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 520/600: Total Reward = -0.12\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.76     |\n",
            "|    ep_rew_mean        | -0.388   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 433865   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.82    |\n",
            "|    explained_variance | 0.9      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 86772    |\n",
            "|    policy_loss        | -0.044   |\n",
            "|    std                | 0.586    |\n",
            "|    value_loss         | 0.00096  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 521/600: Total Reward = -0.67\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.27     |\n",
            "|    ep_rew_mean        | -0.338   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 127      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 434700   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.82    |\n",
            "|    explained_variance | 0.869    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 86939    |\n",
            "|    policy_loss        | 0.328    |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.00463  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 522/600: Total Reward = -0.20\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.25     |\n",
            "|    ep_rew_mean        | -0.428   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 84       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 435535   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.82    |\n",
            "|    explained_variance | 0.37     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 87106    |\n",
            "|    policy_loss        | 0.198    |\n",
            "|    std                | 0.586    |\n",
            "|    value_loss         | 0.00736  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 523/600: Total Reward = -0.35\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.85     |\n",
            "|    ep_rew_mean        | -0.316   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 140      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 436370   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.82    |\n",
            "|    explained_variance | 0.974    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 87273    |\n",
            "|    policy_loss        | -0.0137  |\n",
            "|    std                | 0.587    |\n",
            "|    value_loss         | 0.000183 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 524/600: Total Reward = -0.43\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.86     |\n",
            "|    ep_rew_mean        | -0.323   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 89       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 437205   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.81    |\n",
            "|    explained_variance | 0.997    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 87440    |\n",
            "|    policy_loss        | -0.149   |\n",
            "|    std                | 0.586    |\n",
            "|    value_loss         | 0.000791 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 525/600: Total Reward = -0.39\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.81     |\n",
            "|    ep_rew_mean        | -0.315   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 123      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 438040   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.8     |\n",
            "|    explained_variance | 0.971    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 87607    |\n",
            "|    policy_loss        | -0.162   |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.00144  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 526/600: Total Reward = -0.02\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.65     |\n",
            "|    ep_rew_mean        | -0.291   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 121      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 438875   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.83    |\n",
            "|    explained_variance | 0.824    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 87774    |\n",
            "|    policy_loss        | -0.113   |\n",
            "|    std                | 0.586    |\n",
            "|    value_loss         | 0.000857 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 527/600: Total Reward = -0.21\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.85     |\n",
            "|    ep_rew_mean        | -0.31    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 95       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 439710   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.85    |\n",
            "|    explained_variance | 0.972    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 87941    |\n",
            "|    policy_loss        | 0.163    |\n",
            "|    std                | 0.587    |\n",
            "|    value_loss         | 0.0013   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 528/600: Total Reward = -0.40\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.26     |\n",
            "|    ep_rew_mean        | -0.251   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 120      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 440545   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.85    |\n",
            "|    explained_variance | 0.64     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 88108    |\n",
            "|    policy_loss        | -0.442   |\n",
            "|    std                | 0.589    |\n",
            "|    value_loss         | 0.012    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 529/600: Total Reward = -0.51\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.55     |\n",
            "|    ep_rew_mean        | -0.273   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 71       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 441380   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.81    |\n",
            "|    explained_variance | -8.13    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 88275    |\n",
            "|    policy_loss        | 1.96     |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.165    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 530/600: Total Reward = -0.53\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.22     |\n",
            "|    ep_rew_mean        | -0.419   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 124      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 442215   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.84    |\n",
            "|    explained_variance | 0.932    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 88442    |\n",
            "|    policy_loss        | 0.842    |\n",
            "|    std                | 0.587    |\n",
            "|    value_loss         | 0.0153   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 531/600: Total Reward = -0.14\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.89     |\n",
            "|    ep_rew_mean        | -0.301   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 70       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 443050   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.84    |\n",
            "|    explained_variance | 0.987    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 88609    |\n",
            "|    policy_loss        | -0.299   |\n",
            "|    std                | 0.588    |\n",
            "|    value_loss         | 0.00245  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 532/600: Total Reward = -0.61\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.55     |\n",
            "|    ep_rew_mean        | -0.274   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 122      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 443885   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.85    |\n",
            "|    explained_variance | 0.121    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 88776    |\n",
            "|    policy_loss        | 0.0418   |\n",
            "|    std                | 0.588    |\n",
            "|    value_loss         | 0.000901 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 533/600: Total Reward = -0.14\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.71     |\n",
            "|    ep_rew_mean        | -0.298   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 444720   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.84    |\n",
            "|    explained_variance | 0.986    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 88943    |\n",
            "|    policy_loss        | 0.625    |\n",
            "|    std                | 0.587    |\n",
            "|    value_loss         | 0.0103   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 534/600: Total Reward = -0.27\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.84     |\n",
            "|    ep_rew_mean        | -0.311   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 131      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 445555   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.84    |\n",
            "|    explained_variance | 0.918    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 89110    |\n",
            "|    policy_loss        | -0.162   |\n",
            "|    std                | 0.588    |\n",
            "|    value_loss         | 0.00103  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 535/600: Total Reward = -0.14\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.03     |\n",
            "|    ep_rew_mean        | -0.33    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 133      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 446390   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.84    |\n",
            "|    explained_variance | 0.97     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 89277    |\n",
            "|    policy_loss        | 0.0358   |\n",
            "|    std                | 0.588    |\n",
            "|    value_loss         | 0.000241 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 536/600: Total Reward = -0.59\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.08     |\n",
            "|    ep_rew_mean        | -0.343   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 120      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 447225   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.83    |\n",
            "|    explained_variance | 0.997    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 89444    |\n",
            "|    policy_loss        | -0.127   |\n",
            "|    std                | 0.588    |\n",
            "|    value_loss         | 0.000544 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 537/600: Total Reward = -0.30\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.95     |\n",
            "|    ep_rew_mean        | -0.4     |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 123      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 448060   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.78    |\n",
            "|    explained_variance | 0.79     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 89611    |\n",
            "|    policy_loss        | 0.0434   |\n",
            "|    std                | 0.584    |\n",
            "|    value_loss         | 0.00117  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 538/600: Total Reward = -0.37\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.03     |\n",
            "|    ep_rew_mean        | -0.326   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 448895   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.75    |\n",
            "|    explained_variance | 0.961    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 89778    |\n",
            "|    policy_loss        | -0.0038  |\n",
            "|    std                | 0.581    |\n",
            "|    value_loss         | 0.000711 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 539/600: Total Reward = -0.10\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.75     |\n",
            "|    ep_rew_mean        | -0.296   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 120      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 449730   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.75    |\n",
            "|    explained_variance | 0.998    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 89945    |\n",
            "|    policy_loss        | 0.133    |\n",
            "|    std                | 0.581    |\n",
            "|    value_loss         | 0.00105  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 540/600: Total Reward = -0.38\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.16     |\n",
            "|    ep_rew_mean        | -0.332   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 72       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 450565   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.76    |\n",
            "|    explained_variance | 0.461    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 90112    |\n",
            "|    policy_loss        | 0.124    |\n",
            "|    std                | 0.584    |\n",
            "|    value_loss         | 0.00198  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 541/600: Total Reward = -0.02\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.34     |\n",
            "|    ep_rew_mean        | -0.261   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 120      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 451400   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.75    |\n",
            "|    explained_variance | 0.988    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 90279    |\n",
            "|    policy_loss        | 0.269    |\n",
            "|    std                | 0.582    |\n",
            "|    value_loss         | 0.00193  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 542/600: Total Reward = -0.37\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.71     |\n",
            "|    ep_rew_mean        | -0.301   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 452235   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.74    |\n",
            "|    explained_variance | 0.846    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 90446    |\n",
            "|    policy_loss        | -0.0856  |\n",
            "|    std                | 0.583    |\n",
            "|    value_loss         | 0.00144  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 543/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.64     |\n",
            "|    ep_rew_mean        | -0.293   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 123      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 453070   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.75    |\n",
            "|    explained_variance | 0.978    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 90613    |\n",
            "|    policy_loss        | 0.228    |\n",
            "|    std                | 0.583    |\n",
            "|    value_loss         | 0.0024   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 544/600: Total Reward = -0.46\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.99     |\n",
            "|    ep_rew_mean        | -0.324   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 90       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 453905   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.75    |\n",
            "|    explained_variance | 0.593    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 90780    |\n",
            "|    policy_loss        | -0.0748  |\n",
            "|    std                | 0.584    |\n",
            "|    value_loss         | 0.00169  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 545/600: Total Reward = -0.38\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.01     |\n",
            "|    ep_rew_mean        | -0.328   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 121      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 454740   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.73    |\n",
            "|    explained_variance | 0.851    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 90947    |\n",
            "|    policy_loss        | 0.176    |\n",
            "|    std                | 0.583    |\n",
            "|    value_loss         | 0.00232  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 546/600: Total Reward = -0.30\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.17     |\n",
            "|    ep_rew_mean        | -0.346   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 125      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 455575   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.71    |\n",
            "|    explained_variance | 0.924    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 91114    |\n",
            "|    policy_loss        | -0.0204  |\n",
            "|    std                | 0.581    |\n",
            "|    value_loss         | 0.000674 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 547/600: Total Reward = -0.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.01     |\n",
            "|    ep_rew_mean        | -0.329   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 109      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 456410   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.7     |\n",
            "|    explained_variance | 0.899    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 91281    |\n",
            "|    policy_loss        | -0.641   |\n",
            "|    std                | 0.581    |\n",
            "|    value_loss         | 0.00996  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 548/600: Total Reward = -0.65\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.84     |\n",
            "|    ep_rew_mean        | -0.31    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 123      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 457245   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.72    |\n",
            "|    explained_variance | 0.453    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 91448    |\n",
            "|    policy_loss        | -0.374   |\n",
            "|    std                | 0.583    |\n",
            "|    value_loss         | 0.00723  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 549/600: Total Reward = -0.08\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.93     |\n",
            "|    ep_rew_mean        | -0.407   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 458080   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.75    |\n",
            "|    explained_variance | 0.737    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 91615    |\n",
            "|    policy_loss        | -0.619   |\n",
            "|    std                | 0.586    |\n",
            "|    value_loss         | 0.0125   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 550/600: Total Reward = -0.20\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.02     |\n",
            "|    ep_rew_mean        | -0.328   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 121      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 458915   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.78    |\n",
            "|    explained_variance | 0.867    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 91782    |\n",
            "|    policy_loss        | -0.213   |\n",
            "|    std                | 0.587    |\n",
            "|    value_loss         | 0.00244  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 551/600: Total Reward = -0.42\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.65     |\n",
            "|    ep_rew_mean        | -0.296   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 459750   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.75    |\n",
            "|    explained_variance | 0.533    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 91949    |\n",
            "|    policy_loss        | -0.237   |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.00249  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 552/600: Total Reward = -0.21\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.86     |\n",
            "|    ep_rew_mean        | -0.305   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 129      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 460585   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.77    |\n",
            "|    explained_variance | 0.992    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 92116    |\n",
            "|    policy_loss        | 0.0207   |\n",
            "|    std                | 0.586    |\n",
            "|    value_loss         | 0.000271 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 553/600: Total Reward = -0.03\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.78     |\n",
            "|    ep_rew_mean        | -0.298   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 99       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 461420   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.73    |\n",
            "|    explained_variance | 0.994    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 92283    |\n",
            "|    policy_loss        | 0.139    |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.000646 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 554/600: Total Reward = -0.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.2      |\n",
            "|    ep_rew_mean        | -0.331   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 122      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 462255   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.75    |\n",
            "|    explained_variance | 0.971    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 92450    |\n",
            "|    policy_loss        | 0.52     |\n",
            "|    std                | 0.586    |\n",
            "|    value_loss         | 0.00656  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 555/600: Total Reward = -0.43\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.66     |\n",
            "|    ep_rew_mean        | -0.371   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 118      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 463090   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.73    |\n",
            "|    explained_variance | 0.988    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 92617    |\n",
            "|    policy_loss        | 0.999    |\n",
            "|    std                | 0.584    |\n",
            "|    value_loss         | 0.0436   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 556/600: Total Reward = -0.32\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 7.71     |\n",
            "|    ep_rew_mean        | -0.684   |\n",
            "|    success_rate       | 0.94     |\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 463925   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.72    |\n",
            "|    explained_variance | 0.822    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 92784    |\n",
            "|    policy_loss        | -0.569   |\n",
            "|    std                | 0.584    |\n",
            "|    value_loss         | 0.0273   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 557/600: Total Reward = -0.16\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.3      |\n",
            "|    ep_rew_mean        | -0.558   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 122      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 464760   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.73    |\n",
            "|    explained_variance | -1.41    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 92951    |\n",
            "|    policy_loss        | -1.69    |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.175    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 558/600: Total Reward = -0.82\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.56     |\n",
            "|    ep_rew_mean        | -0.588   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 72       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 465595   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.67    |\n",
            "|    explained_variance | 0.935    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 93118    |\n",
            "|    policy_loss        | 0.545    |\n",
            "|    std                | 0.578    |\n",
            "|    value_loss         | 0.0188   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 559/600: Total Reward = -0.20\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.21     |\n",
            "|    ep_rew_mean        | -0.449   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 120      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 466430   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.72    |\n",
            "|    explained_variance | 0.992    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 93285    |\n",
            "|    policy_loss        | -0.0205  |\n",
            "|    std                | 0.583    |\n",
            "|    value_loss         | 0.000135 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 560/600: Total Reward = -0.38\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.59     |\n",
            "|    ep_rew_mean        | -0.377   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 109      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 467265   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.72    |\n",
            "|    explained_variance | 0.956    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 93452    |\n",
            "|    policy_loss        | 0.362    |\n",
            "|    std                | 0.584    |\n",
            "|    value_loss         | 0.00706  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 561/600: Total Reward = -0.18\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.81     |\n",
            "|    ep_rew_mean        | -0.481   |\n",
            "|    success_rate       | 0.97     |\n",
            "| time/                 |          |\n",
            "|    fps                | 130      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 468100   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.7     |\n",
            "|    explained_variance | 0.161    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 93619    |\n",
            "|    policy_loss        | 1.48     |\n",
            "|    std                | 0.583    |\n",
            "|    value_loss         | 0.0532   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 562/600: Total Reward = -0.09\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.5      |\n",
            "|    ep_rew_mean        | -0.36    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 107      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 468935   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.7     |\n",
            "|    explained_variance | 0.382    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 93786    |\n",
            "|    policy_loss        | 1.23     |\n",
            "|    std                | 0.583    |\n",
            "|    value_loss         | 0.0692   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 563/600: Total Reward = -0.24\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.12     |\n",
            "|    ep_rew_mean        | -0.412   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 77       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 469770   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.72    |\n",
            "|    explained_variance | -11.1    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 93953    |\n",
            "|    policy_loss        | -2.64    |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.245    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 564/600: Total Reward = -0.24\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.97     |\n",
            "|    ep_rew_mean        | -0.44    |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 129      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 470605   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.73    |\n",
            "|    explained_variance | 0.942    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 94120    |\n",
            "|    policy_loss        | -0.539   |\n",
            "|    std                | 0.586    |\n",
            "|    value_loss         | 0.0129   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 565/600: Total Reward = -0.33\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.48     |\n",
            "|    ep_rew_mean        | -0.373   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 471440   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.74    |\n",
            "|    explained_variance | 0.365    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 94287    |\n",
            "|    policy_loss        | -0.0916  |\n",
            "|    std                | 0.588    |\n",
            "|    value_loss         | 0.00317  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 566/600: Total Reward = -0.30\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.29     |\n",
            "|    ep_rew_mean        | -0.342   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 113      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 472275   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.77    |\n",
            "|    explained_variance | 0.38     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 94454    |\n",
            "|    policy_loss        | 0.437    |\n",
            "|    std                | 0.59     |\n",
            "|    value_loss         | 0.00852  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 567/600: Total Reward = -0.46\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.88     |\n",
            "|    ep_rew_mean        | -0.389   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 105      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 473110   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.74    |\n",
            "|    explained_variance | 0.766    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 94621    |\n",
            "|    policy_loss        | 0.401    |\n",
            "|    std                | 0.589    |\n",
            "|    value_loss         | 0.0421   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 568/600: Total Reward = -0.95\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.39     |\n",
            "|    ep_rew_mean        | -0.425   |\n",
            "|    success_rate       | 0.98     |\n",
            "| time/                 |          |\n",
            "|    fps                | 112      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 473945   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.71    |\n",
            "|    explained_variance | -2.37    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 94788    |\n",
            "|    policy_loss        | -1.07    |\n",
            "|    std                | 0.587    |\n",
            "|    value_loss         | 0.0609   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 569/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.27     |\n",
            "|    ep_rew_mean        | -0.342   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 131      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 474780   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.72    |\n",
            "|    explained_variance | 0.602    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 94955    |\n",
            "|    policy_loss        | -0.274   |\n",
            "|    std                | 0.587    |\n",
            "|    value_loss         | 0.00404  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 570/600: Total Reward = -0.14\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.16     |\n",
            "|    ep_rew_mean        | -0.343   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 72       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 475615   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.69    |\n",
            "|    explained_variance | 0.932    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 95122    |\n",
            "|    policy_loss        | -0.00937 |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.00128  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 571/600: Total Reward = -0.07\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.91     |\n",
            "|    ep_rew_mean        | -0.302   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 119      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 476450   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.72    |\n",
            "|    explained_variance | 0.931    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 95289    |\n",
            "|    policy_loss        | 0.244    |\n",
            "|    std                | 0.587    |\n",
            "|    value_loss         | 0.00593  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 572/600: Total Reward = -0.18\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.81     |\n",
            "|    ep_rew_mean        | -0.389   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 72       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 477285   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.66    |\n",
            "|    explained_variance | -0.873   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 95456    |\n",
            "|    policy_loss        | -0.887   |\n",
            "|    std                | 0.583    |\n",
            "|    value_loss         | 0.0343   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 573/600: Total Reward = -4.22\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.76     |\n",
            "|    ep_rew_mean        | -0.473   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 121      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 478120   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.64    |\n",
            "|    explained_variance | 0.435    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 95623    |\n",
            "|    policy_loss        | 1.83     |\n",
            "|    std                | 0.582    |\n",
            "|    value_loss         | 0.199    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 574/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.23     |\n",
            "|    ep_rew_mean        | -0.336   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 115      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 478955   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.67    |\n",
            "|    explained_variance | 0.992    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 95790    |\n",
            "|    policy_loss        | 0.248    |\n",
            "|    std                | 0.586    |\n",
            "|    value_loss         | 0.00272  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 575/600: Total Reward = -0.10\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.68     |\n",
            "|    ep_rew_mean        | -0.284   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 479790   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.66    |\n",
            "|    explained_variance | 0.646    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 95957    |\n",
            "|    policy_loss        | 0.592    |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.0178   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 576/600: Total Reward = -0.52\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.8      |\n",
            "|    ep_rew_mean        | -0.298   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 119      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 480625   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.72    |\n",
            "|    explained_variance | 0.929    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 96124    |\n",
            "|    policy_loss        | -1.44    |\n",
            "|    std                | 0.59     |\n",
            "|    value_loss         | 0.0749   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 577/600: Total Reward = -0.10\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.39     |\n",
            "|    ep_rew_mean        | -0.353   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 73       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 481460   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.68    |\n",
            "|    explained_variance | 0.974    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 96291    |\n",
            "|    policy_loss        | -0.619   |\n",
            "|    std                | 0.587    |\n",
            "|    value_loss         | 0.0108   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 578/600: Total Reward = -0.21\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.05     |\n",
            "|    ep_rew_mean        | -0.322   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 129      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 482295   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.65    |\n",
            "|    explained_variance | 0.99     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 96458    |\n",
            "|    policy_loss        | -0.0796  |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.000614 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 579/600: Total Reward = -0.23\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.61     |\n",
            "|    ep_rew_mean        | -0.52    |\n",
            "|    success_rate       | 0.97     |\n",
            "| time/                 |          |\n",
            "|    fps                | 83       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 483130   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.66    |\n",
            "|    explained_variance | 0.874    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 96625    |\n",
            "|    policy_loss        | 0.00827  |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.00111  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 580/600: Total Reward = -0.04\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.77     |\n",
            "|    ep_rew_mean        | -0.594   |\n",
            "|    success_rate       | 0.96     |\n",
            "| time/                 |          |\n",
            "|    fps                | 128      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 483965   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.64    |\n",
            "|    explained_variance | 0.662    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 96792    |\n",
            "|    policy_loss        | -1.7     |\n",
            "|    std                | 0.583    |\n",
            "|    value_loss         | 0.114    |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 581/600: Total Reward = -0.77\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.94     |\n",
            "|    ep_rew_mean        | -0.5     |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 123      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 484800   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.63    |\n",
            "|    explained_variance | -0.163   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 96959    |\n",
            "|    policy_loss        | 0.807    |\n",
            "|    std                | 0.583    |\n",
            "|    value_loss         | 0.0315   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 582/600: Total Reward = -0.28\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.42     |\n",
            "|    ep_rew_mean        | -0.373   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 86       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 485635   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.66    |\n",
            "|    explained_variance | 0.899    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 97126    |\n",
            "|    policy_loss        | 0.595    |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.0199   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 583/600: Total Reward = -0.18\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.16     |\n",
            "|    ep_rew_mean        | -0.324   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 117      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 486470   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.67    |\n",
            "|    explained_variance | 0.921    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 97293    |\n",
            "|    policy_loss        | -0.165   |\n",
            "|    std                | 0.586    |\n",
            "|    value_loss         | 0.00223  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 584/600: Total Reward = -0.21\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.21     |\n",
            "|    ep_rew_mean        | -0.415   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 73       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 487305   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.65    |\n",
            "|    explained_variance | 0.705    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 97460    |\n",
            "|    policy_loss        | 0.333    |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.00704  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 585/600: Total Reward = -0.22\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.43     |\n",
            "|    ep_rew_mean        | -0.354   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 116      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 488140   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.66    |\n",
            "|    explained_variance | -1.64    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 97627    |\n",
            "|    policy_loss        | 1.49     |\n",
            "|    std                | 0.587    |\n",
            "|    value_loss         | 0.0482   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 586/600: Total Reward = -0.75\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.98     |\n",
            "|    ep_rew_mean        | -0.401   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 100      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 488975   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.64    |\n",
            "|    explained_variance | 0.316    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 97794    |\n",
            "|    policy_loss        | -0.481   |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.0144   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 587/600: Total Reward = -0.59\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.76     |\n",
            "|    ep_rew_mean        | -0.404   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 97       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 489810   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.66    |\n",
            "|    explained_variance | 0.964    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 97961    |\n",
            "|    policy_loss        | -0.0906  |\n",
            "|    std                | 0.587    |\n",
            "|    value_loss         | 0.00213  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 588/600: Total Reward = -0.38\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.85     |\n",
            "|    ep_rew_mean        | -0.406   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 120      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 490645   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.64    |\n",
            "|    explained_variance | 0.263    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 98128    |\n",
            "|    policy_loss        | 0.262    |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.00946  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 589/600: Total Reward = -0.15\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.08     |\n",
            "|    ep_rew_mean        | -0.339   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 70       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 491480   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.66    |\n",
            "|    explained_variance | -0.24    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 98295    |\n",
            "|    policy_loss        | -0.135   |\n",
            "|    std                | 0.588    |\n",
            "|    value_loss         | 0.00285  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 590/600: Total Reward = -0.72\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.25     |\n",
            "|    ep_rew_mean        | -0.342   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 113      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 492315   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.64    |\n",
            "|    explained_variance | 0.98     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 98462    |\n",
            "|    policy_loss        | -0.12    |\n",
            "|    std                | 0.585    |\n",
            "|    value_loss         | 0.000953 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 591/600: Total Reward = -0.77\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.11     |\n",
            "|    ep_rew_mean        | -0.328   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 493150   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.62    |\n",
            "|    explained_variance | -0.494   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 98629    |\n",
            "|    policy_loss        | -0.64    |\n",
            "|    std                | 0.583    |\n",
            "|    value_loss         | 0.0174   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 592/600: Total Reward = -0.36\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.43     |\n",
            "|    ep_rew_mean        | -0.362   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 122      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 493985   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.66    |\n",
            "|    explained_variance | 0.0971   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 98796    |\n",
            "|    policy_loss        | -0.925   |\n",
            "|    std                | 0.587    |\n",
            "|    value_loss         | 0.0345   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 593/600: Total Reward = -0.13\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.98     |\n",
            "|    ep_rew_mean        | -0.336   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 108      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 494820   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.68    |\n",
            "|    explained_variance | 0.976    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 98963    |\n",
            "|    policy_loss        | 0.0786   |\n",
            "|    std                | 0.589    |\n",
            "|    value_loss         | 0.000305 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 594/600: Total Reward = -0.43\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.02     |\n",
            "|    ep_rew_mean        | -0.332   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 71       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 495655   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.65    |\n",
            "|    explained_variance | 0.0608   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99130    |\n",
            "|    policy_loss        | 0.0974   |\n",
            "|    std                | 0.586    |\n",
            "|    value_loss         | 0.00422  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 595/600: Total Reward = -0.23\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 5.29     |\n",
            "|    ep_rew_mean        | -0.418   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 113      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 496490   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.59    |\n",
            "|    explained_variance | 0.659    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99297    |\n",
            "|    policy_loss        | -0.117   |\n",
            "|    std                | 0.58     |\n",
            "|    value_loss         | 0.0167   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 596/600: Total Reward = -0.28\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.88     |\n",
            "|    ep_rew_mean        | -0.378   |\n",
            "|    success_rate       | 0.99     |\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 497325   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.59    |\n",
            "|    explained_variance | 0.994    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99464    |\n",
            "|    policy_loss        | 0.197    |\n",
            "|    std                | 0.581    |\n",
            "|    value_loss         | 0.00119  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 597/600: Total Reward = -0.69\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.4      |\n",
            "|    ep_rew_mean        | -0.339   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 83       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 498160   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.57    |\n",
            "|    explained_variance | 0.955    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99631    |\n",
            "|    policy_loss        | 0.111    |\n",
            "|    std                | 0.579    |\n",
            "|    value_loss         | 0.00115  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 598/600: Total Reward = -0.19\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.48     |\n",
            "|    ep_rew_mean        | -0.27    |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 112      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 498995   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.59    |\n",
            "|    explained_variance | 0.896    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99798    |\n",
            "|    policy_loss        | 0.119    |\n",
            "|    std                | 0.581    |\n",
            "|    value_loss         | 0.000871 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 599/600: Total Reward = -0.77\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 3.7      |\n",
            "|    ep_rew_mean        | -0.298   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 71       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 499830   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.58    |\n",
            "|    explained_variance | 0.968    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99965    |\n",
            "|    policy_loss        | 0.0586   |\n",
            "|    std                | 0.581    |\n",
            "|    value_loss         | 0.00044  |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 600/600: Total Reward = -0.37\n",
            "Logging to runs/aqrdlwti/A2C_0\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 4.75     |\n",
            "|    ep_rew_mean        | -0.388   |\n",
            "|    success_rate       | 1        |\n",
            "| time/                 |          |\n",
            "|    fps                | 108      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 500665   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -5.6     |\n",
            "|    explained_variance | 0.797    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 100132   |\n",
            "|    policy_loss        | -0.57    |\n",
            "|    std                | 0.583    |\n",
            "|    value_loss         | 0.0129   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation: mean_reward=-0.46 +/- 0.35\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1UAAAHWCAYAAACfRKOZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAA7G1JREFUeJzsnXec3MTZx3/S7t5eLz7fufeKu7HB2NjYgLHBlEAooXfyQiAQShLIGwgklBQCpBECeSlJCD0JJabYYLANrtjGBvfefbbvfHe+urvS+4d2pJnRSKu9wp3N882HeFerlUYjnXYe/Z7nN5ppmiYIgiAIgiAIgiCIJqG3dQMIgiAIgiAIgiCOZCioIgiCIAiCIAiCaAYUVBEEQRAEQRAEQTQDCqoIgiAIgiAIgiCaAQVVBEEQBEEQBEEQzYCCKoIgCIIgCIIgiGZAQRVBEARBEARBEEQzoKCKIAiCIAiCIAiiGVBQRRAEQRAEQRAE0QwoqCIIgviG8/HHH0PTNHz88cdt3ZR2gaZpuP/++9u6GW3C888/D03TsHXr1q91v9/kPicI4uiAgiqCIIg2QNO0QP8FCXQefvhh/Oc//2n1NrMBN/svHA6jW7duuPrqq7Fr165W3z8hwoJhr/9efvnltm4iQRDEN4ZwWzeAIAjim8jf//534f3f/vY3zJo1y7X8mGOOSbmthx9+GBdccAHOPffclmyiJz//+c/Rp08f1NfXY+HChXj++ecxf/58fPnll8jMzPxa2kA43HrrrTjuuONcy8ePH5/2tq644gpcfPHFiEajLdE0giCIbwwUVBEEQbQBl19+ufB+4cKFmDVrlmt5e+SMM87A2LFjAQDXX389OnbsiF/96ld46623cNFFF7Vx61JTU1ODnJyctm5GIIK0ddKkSbjgggtaZH+hUAihUKhFtkUQBPFNgtL/CIIg2ik1NTW488470aNHD0SjUQwaNAiPPvooTNO019E0DTU1NXjhhRfstK+rr74aALBt2zZ873vfw6BBg5CVlYXi4mJceOGFLV4vM2nSJADApk2bhOVr167FBRdcgA4dOiAzMxNjx47FW2+9ZX9+6NAhhEIh/P73v7eXHThwALquo7i4WDjOm266CZ07d7bfz5s3DxdeeCF69uyJaDSKHj164Pbbb0ddXZ3Qhquvvhq5ubnYtGkTZsyYgby8PFx22WUAgIaGBtx+++0oKSlBXl4ezjnnHOzcuTPQMbPUu1deeQU/+clP0LlzZ+Tk5OCcc87Bjh07XOsvWrQIp59+OgoKCpCdnY3Jkyfj008/Fda5//77oWkaVq9ejUsvvRRFRUWYOHFioPakQtM03HLLLXjxxRcxaNAgZGZmYsyYMZg7d66wnqqmaunSpZg+fTo6duyIrKws9OnTB9dee63wvSDXKpBen+/atQvXXnstOnXqhGg0iqFDh+LZZ59tkf4gCIJoaUipIgiCaIeYpolzzjkHc+bMwXXXXYdRo0bh/fffxw9/+EPs2rULjz/+OAArjfD666/H8ccfj+9+97sAgH79+gEAlixZgs8++wwXX3wxunfvjq1bt+LPf/4zpkyZgtWrVyM7O7tF2soG4EVFRfayr776CieeeCK6deuGu+++Gzk5OXj11Vdx7rnn4o033sB5552HwsJCDBs2DHPnzsWtt94KAJg/fz40TUN5eTlWr16NoUOHArCCKBa8AcBrr72G2tpa3HTTTSguLsbixYvxhz/8ATt37sRrr70mtC8ej2P69OmYOHEiHn30Ufu4r7/+evzjH//ApZdeigkTJuCjjz7CmWeemdaxP/TQQ9A0DT/+8Y9RVlaGJ554AlOnTsWKFSuQlZUFAPjoo49wxhlnYMyYMfjZz34GXdfx3HPP4ZRTTsG8efNw/PHHC9u88MILMWDAADz88MOuoERFdXU1Dhw44FpeXFwMTdPs95988gleeeUV3HrrrYhGo3jyySdx+umnY/HixRg2bJhy22VlZZg2bRpKSkpw9913o7CwEFu3bsW//vUve52g1yoQvM/37duHE044wQ4GS0pK8O677+K6665DVVUVfvCDH6TsF4IgiK8VkyAIgmhzbr75ZpO/Jf/nP/8xAZgPPvigsN4FF1xgappmbty40V6Wk5NjXnXVVa5t1tbWupYtWLDABGD+7W9/s5fNmTPHBGDOmTPHt43PPfecCcCcPXu2uX//fnPHjh3m66+/bpaUlJjRaNTcsWOHve6pp55qDh8+3Kyvr7eXGYZhTpgwwRwwYIBw3J06dbLf33HHHeZJJ51klpaWmn/+859N0zTNgwcPmpqmmb/73e98j+2RRx4xNU0zt23bZi+76qqrTADm3XffLay7YsUKE4D5ve99T1h+6aWXmgDMn/3sZ759wfqsW7duZlVVlb381VdfNQHYbTUMwxwwYIA5ffp00zAMof19+vQxTzvtNHvZz372MxOAeckll/juW26D13979uyx12XLli5dai/btm2bmZmZaZ533nn2MnaOt2zZYpqmaf773/82AZhLlizxbEfQazWdPr/uuuvMLl26mAcOHBDWvfjii82CggLl+ScIgmhLKP2PIAiiHTJz5kyEQiFbwWHceeedME0T7777bsptMKUEAGKxGA4ePIj+/fujsLAQy5Yta3Lbpk6dipKSEvTo0QMXXHABcnJy8NZbb6F79+4AgPLycnz00Ue46KKLbBXlwIEDOHjwIKZPn44NGzbYboGTJk3Cvn37sG7dOgCWInXSSSdh0qRJmDdvHgBLvTJNU1Cq+GOrqanBgQMHMGHCBJimieXLl7vafNNNNwnvZ86cCQCu/k1XAbnyyiuRl5dnv7/gggvQpUsXe/srVqzAhg0bcOmll+LgwYN2X9TU1ODUU0/F3LlzYRiGsM0bb7wxrTbcd999mDVrluu/Dh06COuNHz8eY8aMsd/37NkT3/rWt/D+++8jkUgot11YWAgAeOeddxCLxZTrBL1Wg/a5aZp44403cPbZZ8M0TbvPDhw4gOnTp6OysrJZ1y9BEERrQOl/BEEQ7ZBt27aha9euwoAdcNwAt23blnIbdXV1eOSRR/Dcc89h165dQipZZWVlk9v2pz/9CQMHDkRlZSWeffZZzJ07V3CL27hxI0zTxL333ot7771XuY2ysjJ069bNDpTmzZuH7t27Y/ny5XjwwQdRUlKCRx991P4sPz8fI0eOtL+/fft23HfffXjrrbdQUVEhbFs+tnA4bAd8jG3btkHXdTtVkjFo0KC0+mLAgAHCe03T0L9/fzslcsOGDQCAq666ynMblZWVQupknz590mrD8OHDMXXq1LTbCgADBw5EbW0t9u/fL9SsMSZPnozzzz8fDzzwAB5//HFMmTIF5557Li699FL7nAe9VoP2+f79+3Ho0CE8/fTTePrpp5XHUlZWlvJ4CYIgvk4oqCIIgjhK+f73v4/nnnsOP/jBDzB+/HgUFBRA0zRcfPHFLnUkHY4//njb/e/cc8/FxIkTcemll2LdunXIzc21t33XXXdh+vTpym30798fANC1a1f06dMHc+fORe/evWGaJsaPH4+SkhLcdttt2LZtG+bNm4cJEyZA163kikQigdNOOw3l5eX48Y9/jMGDByMnJwe7du3C1Vdf7Tq2aDRqf/frhrXlN7/5DUaNGqVcJzc3V3jPq3BtjaZpeP3117Fw4UK8/fbbeP/993Httdfit7/9LRYuXOhqe0vA+uzyyy/3DEZHjBjR4vslCIJoDhRUEQRBtEN69eqF2bNno7q6WlAA1q5da3/O4M0IeF5//XVcddVV+O1vf2svq6+vx6FDh1qsnaFQCI888ghOPvlk/PGPf8Tdd9+Nvn37AgAikUggBWXSpEmYO3cu+vTpg1GjRiEvLw8jR45EQUEB3nvvPSxbtgwPPPCAvf6qVauwfv16vPDCC7jyyivt5bNmzQrc7l69esEwDGzatElQSlgaYlCYEsUwTRMbN260B/1MlcnPzw/UF62J3FYAWL9+PbKzs1FSUuL73RNOOAEnnHACHnroIfzzn//EZZddhpdffhnXX3994Gs1aJ8zZ8BEItHmfUYQBBEUqqkiCIJoh8yYMQOJRAJ//OMfheWPP/44NE3DGWecYS/LyclRBkqhUMjlHveHP/zBs36mqUyZMgXHH388nnjiCdTX16O0tBRTpkzBX/7yF+zZs8e1/v79+4X3kyZNwtatW/HKK6/Y6YC6rmPChAl47LHHEIvFhHoqNo8Sf2ymaeJ3v/td4Daz/uPt3AHgiSeeCLwNwJq0ubq62n7/+uuvY8+ePfb2x4wZg379+uHRRx/F4cOHXd+X+6I1WbBggVCLtGPHDrz55puYNm2a59xUFRUVrmuIKW4NDQ0Agl+rQfs8FArh/PPPxxtvvIEvv/zS1aavs88IgiCCQkoVQRBEO+Tss8/GySefjP/93//F1q1bMXLkSHzwwQd488038YMf/ECoSxkzZgxmz56Nxx57zE6nGzduHM466yz8/e9/R0FBAYYMGYIFCxZg9uzZKC4ubvH2/vCHP8SFF16I559/HjfeeCP+9Kc/YeLEiRg+fDhuuOEG9O3bF/v27cOCBQuwc+dOfPHFF/Z3WcC0bt06PPzww/byk046Ce+++y6i0SiOO+44e/ngwYPRr18/3HXXXdi1axfy8/PxxhtvuGqr/Bg1ahQuueQSPPnkk6isrMSECRPw4YcfYuPGjWkdd4cOHTBx4kRcc8012LdvH5544gn0798fN9xwAwArOPzrX/+KM844A0OHDsU111yDbt26YdeuXZgzZw7y8/Px9ttvp7VPmXnz5qG+vt61fMSIEUKa3LBhwzB9+nTBUh2AoALKvPDCC3jyySdx3nnnoV+/fqiursYzzzyD/Px8zJgxA0DwazWdPv/lL3+JOXPmYNy4cbjhhhswZMgQlJeXY9myZZg9ezbKy8ub1WcEQRAtTltYDhIEQRAisqW6aZpmdXW1efvtt5tdu3Y1I5GIOWDAAPM3v/mNYM1tmqa5du1a86STTjKzsrJMALa9ekVFhXnNNdeYHTt2NHNzc83p06eba9euNXv16iVYsKdrqa6y104kEma/fv3Mfv36mfF43DRN09y0aZN55ZVXmp07dzYjkYjZrVs386yzzjJff/111/dLS0tNAOa+ffvsZfPnzzcBmJMmTXKtv3r1anPq1Klmbm6u2bFjR/OGG24wv/jiCxOA+dxzz9nrXXXVVWZOTo7yeOrq6sxbb73VLC4uNnNycsyzzz7b3LFjR1qW6i+99JJ5zz33mKWlpWZWVpZ55plnCpbujOXLl5vf/va3zeLiYjMajZq9evUyL7roIvPDDz+012GW6vv37/fdt9wGr//4YwBg3nzzzeY//vEPc8CAAWY0GjVHjx7tOueypfqyZcvMSy65xOzZs6cZjUbN0tJS86yzzhKs2U0z+LWaTp/v27fPvPnmm80ePXqYkUjE7Ny5s3nqqaeaTz/9dKD+IQiC+DrRTDPAzIIEQRAEQdh8/PHHOPnkk/Haa6/hggsuaOvmpETTNNx8882uFD2CIAiiZaCaKoIgCIIgCIIgiGZAQRVBEARBEARBEEQzoKCKIAiCIAiCIAiiGVBNFUEQBEEQBEEQRDMgpYogCIIgCIIgCKIZUFBFEARBEARBEATRDGjyXwnDMLB7927k5eVB07S2bg5BEARBEARBEG2EaZqorq5G165doeveehQFVRK7d+9Gjx492roZBEEQBEEQBEG0E3bs2IHu3bt7fk5BlUReXh4Aq+Py8/PbtC2xWAwffPABpk2bhkgk0qZtIVoGOqdHJ3Rej07ovB590Dk9OqHzevTRns5pVVUVevToYccIXlBQJcFS/vLz89tFUJWdnY38/Pw2v6CIloHO6dEJndejEzqvRx90To9O6LwefbTHc5qqLIiMKgiCIAiCIAiCIJoBBVUEQRAEQRAEQRDNgIIqgiAIgiAIgiCIZkBBFUEQBEEQBEEQRDOgoIogCIIgCIIgCKIZUFBFEARBEARBEATRDCioIgiCIAiCIAiCaAYUVBEEQRAEQRAEQTQDCqoIgiAIgiAIgiCaAQVVBEEQBEEQBEEQzeCoDKr+9Kc/oXfv3sjMzMS4ceOwePHitm4SQRAEQRAEQRBHKUddUPXKK6/gjjvuwM9+9jMsW7YMI0eOxPTp01FWVtbWTSMIgiAIgiAI4ijkqAuqHnvsMdxwww245pprMGTIEDz11FPIzs7Gs88+29ZNIwiCIAiCIAjiKCTc1g1oSRobG/H555/jnnvusZfpuo6pU6diwYIFyu80NDSgoaHBfl9VVQUAiMViiMVirdvgFLD9t3U7iPRpiCWweGsFju9dhGgkZC9viXP66tKd6F+ai2N7FvquVx9L4KvdVTi2ZyE0TWvy/r5ulu84hNlrynDLlH7IynD6bu3eamwsO4wzh3dud8dzNPyt7j5Uh/dXl+HCMd2QGz2qfhqaTKrzunhrOTrnZ6Jnh+yU26qPJfDSkp3YU1mPaUNKMbZXke/628tr8c7Kvbj2xF7I5O4hQahrTOAv87bg9KGdMLhzXuDvJQwTv/9oE2IJA9OHdsLI7gVp7bclME0TCzaXo39pLkrzovbyeMLAkm0VGNGtAF/urkJ2RgjDu6XfPnYua+ob8PaSnTh1cAlKuP2kw9JtFahrTGDSgI5N+n5zqGtM4Ef/+hKjexTg2hN7+65bUduIuesPYMbwzvhiZyV6F2ejY651zFV1MXyy4QCmHVMq/Faxffz3y704Y2gn5ETD+Pfy3ahtjOOycT2b1GbTNPHV7moc0yUPIT34PXxPZT3ufWs1LhnbHacMLsHfF+3AtoO1+MkZg+ztNOce/Mn6/dhQVoNrJvRKq13/XbUXH6zeh5+fMwQFWZG09wtYffLkJ1vQtSATE/sXY/OBGozr0yHQd1/7fBdiCQOXHt+jSftORTxh4PVlu3FszwIM7OS+j3y4pgz9S3PRqzj1/a8ptKff1aBt0EzTNFu5LV8bu3fvRrdu3fDZZ59h/Pjx9vIf/ehH+OSTT7Bo0SLXd+6//3488MADruX//Oc/kZ3dOhcKcWRhmgA/ht9bC9QngN7cPeZQA5AdBlgM8OZWHR/t0XFiJwMX9TWEbdXEgdym3X+xrw54eEUYnbJM/GRUwnfdmdt1vL9Lx7HFBq4aaPiuGwTDBA41Ah2aNv4IzFNrdKw5pOO6QQmM6ODcnm5bYA30fzAsjj4Bxomzd2nICQPjO319t7iYYZ2jbtniNZMu6ys16DDRvwlj2sYEUB0DijPVn9fGgQX7NIwrNYXr8Om1Or6q0NEjx8T07gZ65JgolM51wgAONACFGUA0vXE+9tUBUR2ubQLA4RigAchR/F0YJrCqXENNHBhfakLTrGWrD2nYWKkhogPjOxmu63LtIQ1764ApXdTn3zSBBgPI9DkO0wS+KNfQaAB980x05Pp0fx3w4IowOmeZuMfnb7EmBpTVA5urNLy13dpZUYaJnx1rfac27hz3sgMaEiYwtMjEPUus6/2cngmc2s05hooGYGeNhqFFJrzGf//cqGPRfh0FERP/O9raT5DztfaQhj+vCSXXN/HQ2AQiLZTPcqDeOs+986zXXxzUMLyDidIscb11hzQ8uSaEkGbi+BIT3XNMTOhk4pm1OlYf0jGmo4HPD1iN+vXx8bSvww93aVhZriMaMrGuUsfwIgPXDxbvj/I9f2s1sKfW+pthfV4XB+5OnqOfj4mjIMN/v3Vx61pT3RdME/iyQsPHe3Rkh01cPdBAKMX9Y+l+DX/faB38jcckcEyheJ2XNwCzduoIadbf7JpDOnrnmth6WEPfPBO3DUugNg788asQdtVqmNrVwNm9xH54Z7uOWbt0TO5s4JSuBu5fFoIJDT8cEUf3HP/2qXh3h4b3dobsa7q8AYgbcF0DgPU3//kBDSENKMgAPtxtnfPSTBNl9Vbn3Dg4gWOKrO00Jqzt1MWBw3Ggk2KbjEMNwH93WL/PvXKBHyy0zuN5vRP2/WJjJZCfARRFrft6tuI50y+WhXCgQcOMHglM757e70xjAli0X0NpJuzrvVcusLlaw61D4+iXL66/4qCGhWUaLupr3ev21gKPfGE16vZhcWE8IlPVCMzZreO4UgNdfYa1DQng31t1lNVpuGpgAntqnfvBdwcnUJBhYnOVhhM7mVh6QMM/N4UCjUVUGKZ1z29nz0c9qa2txaWXXorKykrk5+d7rveNfxx5zz334I477rDfV1VVoUePHpg2bZpvx30dxGIxzJo1C6eddhoikSaOwgmB1XuqcNOLK3D71P44d1TXlOs/++lWPP7hRrx47XEY0b0Ai7aU47ZnlyIS0jDvrpNQnBvFtvJaTH18PoZ0ycOb37OC+dvu/QAA8Ok+Hc/fcrq9vUffX4enF27F/10xGpMGlqbd/pU7K4EVi6BFMjFjxmTfdZ/580IAVVh2UMedQ47H8b2DPf3y4s+fbMZjszfi+yf3xa2n9MfqPVXIioTQp6P3r+vuQ3WYt/Egzh3ZxfUU1It/7FkCHKrA0BGjMGNEFwBAQ9wAFswGAPQbNganD+3ku42tB2tw2xOfAgB+cc20QPsFgOr6GDIjIURC6Y0k2d/qy3uKsXR7JX717aH49uhuKKtuQGZYR34aTzFrGuK47cGPAABf3ndq4H5j3PX6Kry9cg9e++44dMjJwB2vrcRJAzrilpP7AQCueHYJFm6vQKhDF/z6W8MBAIdqY7htwRwAwI4aDX9dF8LE/sV47qox9nZX7arElc99jsMNcQzpkofXvjsOYV1DRV0MxTneI8qDNY349fvr8a8Vu9GtMBNz7pgkKI11jQmc/Ng8JAwTL11/HPqX5tqfmaaJG/6xHJ+sPwAAmD7xWAzqnIern1+KDWU19nqf7Avj3zedgOyMEK59YRlO7F+Mv6/ZDgC4ZNrxGN2j0NWuP87ZhN99tAn9S3Lw8HlD7XUOHG7AhrLDOKFPB7yzcjeeW/gVACCsa/ifk/rgtlP6QdM0vPvlXmDFSuyt03Dy1OlYvLUczy/YjgfOPgY9irLw9LytAIBXP9+J7eV1wr4rGjX0GzMJr32+C3//fDteveF4HG5I4IUFn7s7sLA7ZswYbr+94tklWLilAgNKc1CQFcENk/rglEElWLmzEnsq6zF9aCf7/lMZ0/D7DXnYX92Av10zFv9avgv5mREs2lKOi4/rjgvHdBfbtXgHsGYNAKAhocHoNgr1MHHuyK7QFRHcodoYnl+wDZMHdMTopHJumibqYglkZzjDC8Mwccrj87CvqgF3nz4QD7+7DoYJLD4UxX++Nx6rdlVi1c4q3DylL3Z9thVYswEJU8OCMmufDXldsPrQHgCwAyoAyB8wFqcOLkVj3EBGOPXfbH0sgbsf+Rh1sQSsIR2wqkLHjBnOPfrNL/bgp29+hT9dMgrr9lWjX0kuXvj3lyiviaFr3/64aXJfez0sWQUAiHUehnc2l2Pptgr85IxBrt+WxVvLccWzS/HdSX1w52kDUB9LwDBNZGeEUdMQx62vfIG5Gw4m19awO28Qlu84hJ+cMQifbzuEZ+ZvQbfCLPzxklGIJo/zo9dXAbD65D+7svGDi0+yVZaNZYdx4dOLcbghLrRj62Hr883VGkaMPxm/n7MJu2p3AwBm79YRLuqCkwYU29cF+w1ZX5eN8aU9YWI9AOBAbj9894xBKfv6wZnrcFzvInxrZBdU1sVw28PWPeat7SHce9nJOO2J+aisj+HGSX3wg1P729dYQyyBHz8yB/UxK8jLjOgArNcsoAKA2sI+WJsRwp8XbAEADCwwYEbzsKGsBjO/PwEDuHvJsu2HUFHTiFMGl2Da7z7F1oO1OKTl46lpo4CF8wEAn+zPxANXnISVuypx27NL0bUgE0O75mP+xgN479YT0bXQidQq62I4kLxnrqjKwWOnT7L7/7nPtmH17ipcMKYbHn53Hf5nUh/89dOtGNOzEP87YzAA4IkPN+L1LZuRlxkGEEfC1LC52tp2RtdjMOOkPgCs+2MkpOG+X32Myro4fr82ikV3T8Ev/rsWwA4AwJeJrvjejFGIJQz8feF2nNC3A4Z0scav1fUxXPCXRdh8oBZ7zAK8+b0TXJkeNQ1xXPi0tU7CsILDD6s641ujugBrrGv89R2ZKM3LxNq91YiWdsecAwcA1GNfnYYZM2agIZbA1oO1GFCa67pXLN1WgX8u3oH7zjwGhdkRmKaJi/+6BAcON+Dtm8cL94rq+jjCuoasjFC7GgOzLLZUHFVBVceOHREKhbBv3z5h+b59+9C5c2fld6LRKKJR96PTSCTS5ieR0Z7acqRz04srsLuyHj9840tceFwv33VrG+N45D3rR+SFhTvwyLcL8b1/rgAAxBImdlQ2onNRLuZvLAcArN5TDU0PIRzS0SEnA+U1jQCAcDhs38QWbTsEExq2VdTjlCac01DY+pM1gZTXRN+SXHy527oRvLFsD04c4B+IpGLWmv0AgD/M2Yz9h2N4eckOlORFseR/p6K8phH/XbUH54zoioJsp13Tfz8b9TEDuysb8NHaMlx2Qi9ccYJ/vzN0PWQf45byant5cV5mymOv4ZT6oH87VfUxHP/Ix+jRIRtz7ppiL99+sBbdirKEtJAd5bV4cdF2XHtib5TmO/LF0u2VAIBXP9+NaUO7Yurj85ETDWHxT6YqB6UqYvXO0+JGU0dugPY3xBO48KkFKMzOwNKt5TBM4IM1+/GPhdtQ05jA8h2VuH3aYFTUNGLhlgoAwL9X7MHjFx8LAPho/R7XNr/aXSX03QdrDtiDtNV7qvHnuVtR25jAc59twX1nDcE1J/ZRbKMSlz6zCJV11gnZdageh2NAB06SWrGrGgeTfyvffXE5Zt0+2U53W727yg6oAGDh1kN4b3UZNpTVID8zjLNHdsWnGw9g68FafL69ErPWlGHzgRpsPuAEXOW1Cdc1YJomXl9mDSY37q/Bq5/vxvF9SwAAt7+2FAs3l+O80d3wzsrd9nfihok/fbwZY3p3wCmDO2Fbeb392Y7KBjw4cx22HqzF7z7ajAvHdsejsza4+kPTgBHdC/HFjkOYu7Ecf1toBX6//mCDZ/pQY8K022+apn3+WFC5oexLfHjnZJz/FysT45/Xj7O/q2vAzgoroLv+78tQXe8Msuvj23HpCeI521PVILz/0b++tPYLHeeP6Y47X/0CI7oX4PpJVmDx+Edr8c9F2/GnjzfjJzMG47sn9cOPXv8Cb3+xB/931VhM6G+lxa3eXYVdh6z++uV765Ect2FvVQPuf3st3vtqLwCge4cc7Kiw2lCaF0VZtfX6rZXu6xMA5m0sx4GaOH76ny8xumchThpQgrNHdhUCc5456w8mAyqHwuyI0L93vW4NIq/72zLX9x+bvRG6ruP6SX0xa41jfmUNcC3+sWiH/dvSGDdQVl2P//t0OwwTeGruFlTWx/GvZbuQMExcPaE38jIjmLvhIDLCOhrj1t8+u3Y+XLvf3u6Gshr85oMNeOBbw2AYJuZvPGh/treqAZsP1mNI13w0xg3c9caXroBKZvbaA9ZDOo73vtqH2WvK0KUoB7sP1eGrPdbvx57KevyWu57fXrkX/3vmEIR9Hj799dPteGXpTryydCemDumMh99db3+macBf5m3FoeR94c9zt6BPaR4uGmulsS3eVmkHVADs13mZYXx7dDdkZYTx1Ceb7L8fxvpKHYD1dzFn/UEM6Wal2NY1JnDd35bhcEMcN07uh60Ha631yw7j8+3OYLm8JoYP1h7A+8nrcXdlPXZXWtftb2ZtxJe7KnH3GYNx+rAuWLfN6bvdlfVYuPUQpgwqRSxh4NFZG9AYN/DWyj0wTOC2V1cCAFbtqsK9Zw9DSNfwcfK+xv9NMtaV1SASiWBfVT2+9cdPUZAVQWWdtV5FbQz//mIv/r3C+ZuYvbYMu6sa8dynW/H8Z1vRuzgbpw/rgh0VtciLhrH5gHW8a/ZW4ydvrsFd0wahc4Hzu7Vme5XwkAoAPtlwAPnZzsOy8poYypM/rP9cvFNYt8HQcM3flmHJ1gp0zs/Esb0K8b0p/TEsmZ77wDtrsXZvNUb17IDrJvbBih2HsGz7IQDAZ5sPwQQwaUBHhHUd0343HwVZEcy+w3lo3B7GwEH3f1QZVWRkZGDMmDH48MMP7WWGYeDDDz8U0gGJby7sBulFPGHg5n8uw7Pzt+Dfy3fZy2MJAxvKDqOKuwHuPmQNVvhB9ab91o2pA/fkng1qAGBr8ubW1KRbI/nFIN9nT5wAK6e+qcQSBupjCaG+4eUl1hOy/clBzw1/W4p7//Mlbn91hfQ968fwHwu3Ye3eary9whmkesGabXAHuXm/c8M3AmQy8lnNhhGss1ftrETcMLHlQA1iCWsn/16+Eyf9Zg7uffNLYd2bXvwcT32yCd/9u0JZgPUMfPOBGtTFEjhwuBHLtld47nfehv24518r7UEQH7zFE8HSNtfuqcbKnZWYu34/ahutQeNf5m5GTaMzgDxU24jXP3d+DHUN9j7ZtX7XtIFY/L+nArB+vKvrnej0ix2HAACTB1rBx9NzN+OFBVthmsADb6/Ge1+6B75//ngTKutiGNw5D4XJYHvrQfHHm20XAHaU1+GVJTtwydMLMfbBWTj3yU+Fdf++YJt9DM9fezweOm84pg+zHpi99vlOzF2/HzL7DzfYx/nKku1YsOkgNpQdxq5Dzt/lgcPWdby/ugELN5fbfRJLmMgJm1j2v6fg6gm9AQDPfboVALCFC9z+uWi7PVD776o9eGyWM4DkKc7JwEVjLRVg1mrn4d/aPdX4cK01SH/5uyegG/dEfOehWvs13+bbpw4EYD0xv/2VFfZyft/9Spzggg3emNKxaX+N6/pi96p+JaL6/NrnO7Fg00G89cVuPPjfNdhRXouGeAL/5YKdP3y4EfWxBF5duhN1sQQu/esirEoO2udvdM5LPPn3+OC5wwAAH611gpNFW8qxvdzq1x+dPhj3nz0Efryzcg8e/WAdAGD59kP43YcbcMX/LbKDE5n3vtzrWlZVF7P/3hdsPuj6XObRD9bjey8uw8fr3NcaAKzcVYlDyfvtzf9chom/mmP/VgDAS4t3oCFuIG6Y+Ov8LXh8tnW+fvGtoXjgnKHKbfboYF0PLyzYhre+2I1VuypxsKYRedEwTuhrZSB8nrzH/G3BVny1uwpF2REsvOdUnDSwBFmREO4/ewg65kbtOrn/rtqDPcnfw0uOd2qk4oaJa55bgv/995fC70wsYaU+5meGceBwA976wrmXf76tHBv2OQ++AOBd7n5w3EOz8S/u99Q0gb/Ot9QlVvP32w/WobbRukY/3XgAKl79n/F44FvD8L2k6s544JyhGNRJDKQXbDqI05+Yi9eW7sC8Dfvte8BTn2wS1vvrvC3C+5mr9uDjdW636HdW7sHWg7W48R/LUB9LYNUuMSB9abEV4G3af9i+/lQ/PXM37MeLi7bhq93eyseaPVUwTRM/fmMl9lbVY53Ut/e/tRqHG+LoXZyNif07wjSBN1fsxvOfbQUAbD1Yi6c+2YT/rtxj/1az+sPXP9+Jkx/9GK8t3YH3v9oL0zSxP3n/61WcjQ0PnYHTh1r31K0HxHu1F3e+ugJLtlrX396qesxctRe/Tf5dbiyrxtq9Vvu3J+/9765yro2bXlyG7724DFMf+wT/WbELBw43YtP+GlTUtn0dVVM4qoIqALjjjjvwzDPP4IUXXsCaNWtw0003oaamBtdcc01bN41oAWoa4sIPlB+maeL+t77Cs/O3uD7L8HjCtm5fNf67cg+enrsZb3AD0K0Ha7FH2u/KnZX424KtOHjYebq7eo91o2VP5tl6AFBR02g/mWtqlQ/7kQvy/TgXfaR6agkAK3cewitLtkMuszzjd/Mw4v4P7IHnsG756MsNukzTxOfbrBsqP0BawQ2W+yQHd4kA0SALBvkfpM0HDtuv4wGiKv67QfYJAEXcU7m9ycHGE7Otp7P/XCQ+Ef1yl/WDyB8jj65paIg7AQ0/AJG54v8W46XFO/CPhdus9nKNb/AYHMrIgYqKLQdq7CewgNVHK3ccwmcbD2Dh5nKEdQ3fGtUNpXmZ9kOBbclAwTBMexBx9xmD0TE3A40JQ2jrX+ZuxqRff4TrX1iCt77YjVv+uQzvJAfdv7lgpD14Yj/UO8prcf0LS/CHjzYK7fzVe2uxYPNBHDjcaA9O7jzNCiDqYgkYJjB9aCcc29N6Cj2g1Nqu/NSd8fTcTRj2s/dxz79W4sdvrMIlzyzEy4t3COuwa/vDNU6gc3zvDujVIRvn9TaQlxnGdRP7QNeAeRsOYPC97wqDxBe56yNhmFiefAr79i0TsfYXp+O7J1nKzo9PH4yTB1lpv/y1U90Qh2kCJ/Yvxgl9i/HO9yfiie+MAiA+lNmwz/o7GNgpF7dNHYBXvnsCAKtNjKXbnAC+UQqawrqGFfdNQzSsI2GY9rbf+Hwnht//vh0knS+lBX6+rQLzNjhBxP/N34KP1+1HZV0MJXlRdC3IRHVDHK8uFfv17D/Ox7+X7xRUFQDIjYZx0dgeyIzoQhtX7jxkX3O9i7MxZZCTIj1jeGfkSQYqlXUxHKqNITcaxn1nDUHH3AzsqazHW1/sxsxVe3DVs4uxp7IO8YSB336wzv47nNLFwMCkmmWYzt/7a0vFJ/A8H981BY9/ZyQiIQ0frS1z/W1Gwzp6F2fDNIFPk8fLAmc2qGScOrgUj39npLDsrBFdMb5fsWu/3YuyMOv2ybg5GUjc/cZKvJLs5wn9i3F8H+s7y7dVoLYxbgcNPzp9MDoXZOLZq8ZiyU+n4uoT+2DpT6fiz5dbKb0rdhyyH8D8ZMZgPHbRSNx3ljuI5RXUm6b0w41TrHY8PHMtKuti+Oei7Tj/zwtw+f9ZSumrS3eg993/Ff4eYwkTWZEQnr16rGBy0b80F//+3ono0SEL+6oacOM/lmHSrz/Ckx9bx3Apt66mwU41z8+MYEKyr84c0QVXTejtMneYv/EA1u6txg9fX+l6+JWTEcJ5o7sBgB2wTBlkPSz6aG0ZYgn/34wXPttq3w+/ndzO7DVlKKuqt38bvGABqx+b9x/GL99d6xm4M7X1vNHdcXryoZLXgxwA6FqQiX9cNw6nDemE7kVZqIsl8MPXV+J//v45Xlq8w344OrxbASIh3U6llVVdADi2ZyF+d/Eo/E/yngYA739lXee/u3gUvn9KfwDOA+a3v3ACqO3ltTBN00qdlthX1YCfvfmV/f5vC7binZV7UNn058FtwlEXVH3nO9/Bo48+ivvuuw+jRo3CihUr8N5776FTp+alPn0TiSUMvLJkO7YfrE298tfEVc8uxuTfzLFvAn6s3FmJ5z/bip+/sxoAhO94udWwm2ncMIQnJVsOiE+2AWtgcd+bX+HB/66xl321qwqGYdqpfwCwctchABBSkpruD8OUqtTfj3M/DKoUA5lz/vgpfvzGKnwsPe3fWHYYjQkDXyR/JO84bSD+ddME+3MvIWg+N9BjT8Tjhok7X/0Clzy90FNBYsfGK1VbOKUqEUh5ctYJtj5gct95e+VuPPnxRiHQ4slMUb2v60BNg/OD9N+Ve5SqE38e2QCHP+5UQVVDPIFXlmz3DO4A2C5fG/YdtgcCw7pZ+fafb6vAr963niheNq4neiRd7Jib3fZy629/84HDONwQR1YkhAGluRjc2V1vunz7Iewor8PsNWW49aXldkDVqzgbw7rl2wOie//zJWb8bh6+85cFmL2mzH4AwYKu2kb3D/nF3JN0ALiXG/wNlJ5QM0WJsSNZz/QSF0g9+6n1oOXbx1oDooOHG7FqZ6V9r7hr2kC8euN4zL59Io4rsc5Hjw7Z+NYoa30+NYnnV+cPR8dc65oZ1aMQw7sXIDMSwt2nD8aHd07GBWO6o2thlqBE8Zw1wqrFKcrJwNQh1m/WodoYbvjbUrz/1V6sTw4ABySduMb27pCsyVBTJ/XlgE55yMoIoW/yIcem/VaQ9rcFW4V7xEkDSuxroHfyXvkM90T/5SXb8XhyEHfe6G64IJm29ct3rTS4sK7h1MFWQPTiwu1YvEUMqo7tVYSMsG4HxIwNZYftQK9ncTZ6d8yxU/nOGtEVPbn79tRjSpGddAZ68NxhuHZiH1w70UpnvOu1L/C9F5fhk/X78fsPN+K7f/8cf/hoI+KGiTOHdca3ehn47/cn2A+HdlTUwjBMpUIxonsB/nzZsejdMQfnje6OH59u1cT06JCFf1znpFqO7F6IUwZb52z+xv2Cyitz+rDOOG90d5yWPMcXH9cDOdEwBpTm2tfP/0zuizOHd8HvLh6NzEgId5w2CKN7FqK2MWE/5BnXp9h2gf18ewVeXrwDBw43okeHLFyQDIzDIV1w8+xSkIkczlW1MDuCvMwIvn1sd1w5vhemDemE04Z0soOWJ74zCn+8dDTevW0Sfjh9MK6f2Bd9S3Jw4HADfvnuWvzk31a65L6qBmw/WIufv71aecxnjeiCUwZ3soOAAaW5eOHa45GVEcLD5w1HSNcwd/1+++8VgOBq2LUgS3DBfOTbw/HgucPw2wut4PSEAI55rJTowrE9cPbILsJnV43vLbyfoAhwGb95fx3mJgOebx/bHWN6FSFhmHh5yQ58KSlYugbM+9HJOGtEF9d2mHpfnJMhGDYYpvWQSmZE9wKM4Bw5zxnV1b6G/Dh3dDcUZEfwzJVjMfO2STimi3P//vMnG7G30upz5oIZTrqk1CuCqmHdCvCtUd1wz4xjcFxvx8E0rGuYMbwLLk+m9++sqEVj3BBSqLeX12LT/hpsL69VuizyD1iemL0Bt7+2CqsrjhAniyRHXVAFALfccgu2bduGhoYGLFq0COPGjUv9JcLFc59uwY/fWIXJj85p66bYbD1Yg1jCDKRW1UjqzJo9zhMkL8eZRFIFSRimoIjUxwz76XM294MEiAPfr3ZXoaK2URjIf5V8csWnCzU1pGKbDRKTxbk2BFGqGHwahyp4y84IC4WuhkdjPtvkBFV2OoRh4j8rdmHB5oPYW6VOxXSOkQuqDqiDqjdX7MLiLeWe2/Brnwy/2q/fW4dfv7dOCFb49pTmeVjrJdE1zU5lASyzhleW7sADb3+FSi5Y5wP97kXWQDsuKFXuH7VXl+yw1dcn52zCj99YZaekqWA/uu9+uQcNcQP5mWGcf6w14Jq9tsxOv7vllAH2d9hDBxZUrdjhBGPhkI5jujiD4eHdCtAp39sS8vxju0PTNPQqtgawNY0JrN5T5UrFPUcq7v/HdeMwonsBLj+hJ0ryorj11AHQNOC3F45E9yJncM2nuAHAtSf2wXUT+6Bzvv85Ks2L4srkQGpPZT3Oe/JTO6CbNlRdg/ur80fgmSvHKj8b2CkXF43tgXk/OgVPXzEGf7nCMfnQdQ39SnLtv5sRHlblpx7jKDO50TCKkoOuWav34cH/rsZ6plQlg5GQruE4hQENC5rlJ83Dk8tZMLF5fw0qahqxUhoI9ijKxj+uG4f/3HyiK0gFrPvh2r3VyMsM48rxvXB+Mjhl/Te+XzF+kExPXLqtAvUxAx1yMuw0tuOTg7FBHnbv2RkhlCQfBvzp0mPx6/NH4IxhnYWHYbedOhAf/3AKXr9xPM5NqgWXjetlByWMlxZvx0dry5AZ0fH7S0bj8YuG2w5+7DraWVGHNXurUFEbcxle3DS5H84Y7gyIr5/UF2/efCJm3jpJUJY6F2Ri0kCrhuyjtWV2AKzi1GOsv8knvjMKv/z2cPzkzGMAAJqm4adnDsF5o7vh1lMG4E+XHYsxSev9kK7Z6grjuN4dMDqp2G47WIs/zbFU3+9O6utptqNpGnpz5kL830k4pOPpK8fimSvH4rlrjsPMWyfh5MGlOGtEV3sgnhHW7fvHK0tEBf/eN61arg45GfjDJaPxclJJBZwHI5MGlOCD20/C29+faD9cmDSgBA+fNwzZSQVpcOc8nDmiC/qX5tnXTF8pJbVXcQ4uP8GZbuD4PkXQNfe9/jtje0DTrGDyf2ccg9E9C3Hj5H6YMrDUDjyzIiGXSnivQrUDrGA+bpioboijKDuCkT0K7DrhP3+8SUh7BKwHVD06ZAuBDACcObwLXrjmeAzunIcbJ/fDHVMH4tJxPe10TsDKCrj1VOe+3KNDNs5OPngZ2b0AfTrmoFN+pt03vYuz7d8RRt+OObiMq2POz4zgzZtPxOc/nYrinAzsKK/D3xZYWRIsqIro1rXDHh7xRkT8A7VO3LXTqzgbkZCO0rwosiIhGKal/G/aX2OPt3ZU1OGr3ZV2+xl+ddbdcr4+996W4KgyqiBaFpay0Z5M93klibF+XzWKczJQnCsN7KTAaTUXVKlkbcBRd+KG6ardmZ/M8x7Tq0hIt+H5anelnafO2Jx8GryFS2Frap+y7wUJFBIBg6oP1+wTBis6FzCpVJ6cjLBg5ezVFr4f2BOohGHa2/RSkAxbqXKWbVYEVV/trsRtL68AAGz95ZnCNvgmBVWqVMeREXLSkyrrYihMKlcleVE74Kiuj7lsuXVNc/U5S/mIhHT8ZIY1iNrEKXChZL8bQlDlVkR++uaXaIwbOHlwqatG5JTBpTimSx7+sXA7Kuti6FaYZdfHzEk+WR3VswgjuhcCcOqZenTIEubqYSrFtoNW7QyrFxiZ/B7/wzqgUy4Gdc6za510DciJhvGXK8Zg9e4qXDbO+sHsrVCHexdnY+vBWgzunIdRyW0DyWChTxHeumWivewHpw7ANRN6o0hyGsyRUsJ6dMjCvWcNweSBJbjy2cXCZ5oG3HrKAJimiWsn9hGefLNg9tELRyrnZAGsAaXXk+FvjeoGTbNcq7yCMsbIHoXKFBg5WO9WlGUr5jvK61BVZ6XZ8OrcuD4d7LTb318yGqV5URimiUufWeR60szqKlgg+tDMNXho5hrI5GeFUZAdQc/ibNffz+PfGYnHZq3Hroo6IcAd2CnXDvr6l+ZiQKdc6JrzdzyyewEmDijBiwu32YofP4dWn4459sOTboVZdgA6qHOeHXz17OAMrHsWZ6MgKyL0WUFWBG/dMhEvLd6OA4cb7esWAH59wUicM7KrMN8MG9TvrKiz66BO7FeM9fuczIQeijnIRnJukuy4LxrbA8f1KUJeZhj7qhoEZZTn4uN62Om1OdGwS4U9d3Q3O0iUYfWMgJXCdkyXPIRDOkZ2L8AXO606q4yQjrNH+jvb9u6YY9f0dPVQTaPhEIZ0VTsgM6dM+dY6N5ki+stvD8e0oZ1hmiauOMGa+4mfV1H19/Wd43rigjE9XArGoE752FFe53p4IlOQFcF1gwwMGzHaNoYAgF9dMALXTeqD3GgYXQuzbJMVwPpbP3N4F2RnhJAZCWFsryIs3VaBrgWZOKZLPq6f2Ad7q+pt1b00L4q/XDEWf5m7CSFNwwVjuiMvM4JzRnbFS4u3Y9GWctfYgimtvBPh96b0w4+Siud7PzhJWP+v8zZj4eZy3D51IG6c3A9vc6njPTtk48oJvdAQT2A6d4/59fkj8PKSHbhz2kDc/soKW+29/ISeePDc4ZDJCOsozo3igrHd8ZdPNtu/M+xBhqxUDetWgE+SGSyDuQdqfFDFzo/1AC0ba/dW44/JIP/UwaX4eN1+NMYNO6XxmC75uGlKf8xdvx8/mXEMPlpb5soGCukaOvtY47dHKKgiPAla4P91wlKoGuNW29btrcb0J+aiU34Ui34y1fN7pmnaufoAUNeoTt9h9TcGN/jvWpCJ3ZX1dpqSX1BVVR+3c5tL8qLYX92A3ZX1qG2MC2YLTYWpJUHOTIyT0g/Xx2Gapj1Q2VtZj1eX7sAxXfJxw9+Wem4jrrgGsqMhIfDiYxH+95DfP1Oq+GDYO6hi/1ov6mMJIZ2StYmvNXFvgzeq8FxNQNWeguyIrSbtrKizg6qw4ARYhwEl4p1f1zVbKc2M6EK6GK+YCgqc6Q42G6Q0M8Mw7b5csrUcXQozhSLme84YjAGd8nDK4E549P11+Pm3htrBH2NUj0IM7pwHTXPO3SBpkOOk/9Xgof+uwefbKpAXDds1DvwPa//SXAxOBlXThnTCL88fgbhhoDQvExP6OZOi8k/HJw8swTkju+LMEV0wf8MB9CnJQRYX4PTpmINoWIxUdV1zBVQq2DXeSaFUDe9WgNuT9VmM3GjYDoAnDehoP73246Yp/fDnjzehX0mOHRifk2IgyzOSCyBH9yzE8u2HXDU2ABDSRbWB3YMGcsHIWE6pGt+3GCV5USzdaqm3fG2IrsGuv5GNKGR4JXpIl3whOBrdowgf/GAyDhxuEAKOkweXCkFVZnK6BdY/o3oU4bqJlorI4JWqn555DK57wboXeRnrsOuyICvi6ZbYtTALd06z7L4PN8Tx9he70Tk/E2cr0q/YU/2dFbU4eDgZVPXviNrGhD3A65liYtN/XDcO28tr7fMwbUhnvLFsp2AKw5j7w5NTbs+PXsU56FWcjW0Ha3FsryLbfe/uM47BJc8sBACc0K/Yvk95wT/g4F3ggjK8e4Fw/2Cw90yV1jQNv0gakgRBlRJ23uhuWLXrkJ026MewIhMzhne2gyqWVeL1kASwrlvGoxeOxO8+3IDbkurQT5Nq1bwNH6CyLoYBnXIR0jV8b0p/YRu6ruHXF4zAZX9dhJ0VdVbdUmMCB2sa0Y8FVVwbTujrnVp4/aS+uHBMD9tFdwD3AKVnh2xEwyEhqwCw7gHs+uODZF7RV3GMlMbdkSlVIbGmqjQvihnDO2NvZT2GcoE2r3L25YLe3sU5WLu32g7czxnVDRvKDmPbwVr7QeCQrvk4LZlqyt7LQVXfjtnICKlrZdsrFFQRApv3H8aOijpMHlgSyBDg60ZWql7/3HoauK/KXWOlCylqopNag4dSZasopmkPcvt3yhNSlcb2Uudud8zNwIHDjfZT4/4luUgk66s2768R0/+aKFXZAUeAgJcfnMcNE/UxA1nJH5lrnl8iDO55+H5TBVWWUqVO/+N/FPkBHQsEeFcuLwMJU1Kq5Daw4/LLtBaUqoB9rerSw5LbI7OIreeOY0dFrTuo0pyaqjOGdRGcJPmUP6ZiAs455dsrp//xny3dWi4Em4AzABzTqwgvJVNv5IHK6B6FyImG0ac4x1YA5UEHGxSt3FGJpUlXp99fOtr+4exfmouwriFumBhQagVx/7n5RPQryUFepnqw25MbgJ82pJNthsBqhwzDtANQOchLxa/OH467/7UKz159nL2MT0nMywzj8hN6YcYw98C6ODfDDqpSDUIYd00bhO5FWZjUvwT7D9cjljCVioYXw7nUl+sm9sEpg0uFuVoYUUUK13G9i9CXC1BH9SjEmcO7ID8rzNVEuL/31i0T7SCGf+qfFQl5KvcAkJURQn5WBIeSilm3oixEQrrreE8d3Al/+cSqA+nb0dr+4C75dlA1soc75ZEPqoZ3K8DPvzUU9735FW45ub9rXcBJaxzSRa2gyNx75jEoyY3i6gm9XXPzAE5QtbHssG0CMqFfR6zdW41FW8pRlB1Bvsf1zCjNzxQcYM8a0QVvLFMbXnTITf1QIBWnD+uMv3yyWVCtxvcrxiXH98QrS7bje1P6+Xzbonexc/10SZEmqyIvM4IBpZZClxHWcVzvItucA0DK1Nt0OHNEF5ypCIj96F+ai41lhwM9IOHp3TEHjycNYnh6FWdj5c5KVw2guE4OPvnhydhyoAYluVHc8tIyy9TGVlmz0bckB41xQ5myy8NPS9KnY479UKNngHtM1wI+qPKXeWT1jylV7DeD/daGQzqevGwMZDoV8EqVc03xD9ByMkI4dXApXlu6A9sO1tr3Gjkd8pgu+YIjKsD+zimoIo5gTvntJwCA/9x8YuAn/DyxhJH2xKlpbT/ZKKaC+Dnt8D+hccMQBs1egwjbec5wXo/vWyxYNXvVAVx+Qi+89cVuW5EqyYsibhgor2nExrLDQlDF2HKgBrnRsJB65QczUwgSJsjBSHVDzA6qvAIqQFSbVOYK2dGQq6iWwQ9cYnG3UsUHVV6BIet3lWEF4ByXapDktKkJRhWK4Iu/Tvg6Pj4o31FeC0B88qhrjlJVmhfFFSf0wt+T7n6bk1bW4ZAupjVyKilDNkTgj2Xp1gpUSymGsroDWD/Ex3TJx6aywzihX7FdO3BMl3zPoGpAqfVElm3/mC75mMIN4qLhEGYM74LFW8rtYuVRigl2ebIzwpg8sASbDxx21U8B1tNe9oTT78myClXqEK9kdMyN2gYDMh1zo7aKHWTQAliDDpbW2BTlITcaxhnDOmPlzkqcNLBEGVABwP3nDMVdr32Bs0Z2wa/fW2cv46/9kK7hT5cdK3wvLAXSnfMz7QcCADC0az6uPbEPOhdE8a1R3bBubzX6dMzB3f9a6XoKD1h1GCyo8rq/H9uz0HKFjBt22tgxnfNsR0FenWOU5mXi1lP6I2GaKM3PxJXje2PakM7C9A08I7oX4uXvnuCqr/GiND8T9/nYsg/tavUJc6rrnJ+JY7rk2YPRoNcDz4n9O2J4twKX5XY0rAsGEU3ljtMGYkK/jpjYv6Ow/OHzhuGeGYNTBoGAOOjt4pH+l4pRPQqxft9hjOxegC7cQD4a1pGf1bZDy+evOQ7vfbkXV4z3rtVJh6FdC7ByZ6XywQBPSNfsdL/7zhqC2WvKMCNZjxfSNbzz/YkwTNi/w0GIhkOYMqgUX+w4hGFd/fcPpKdUyX9HpZJRBUO+nzA6cX+n/Up5pcrZ72Un9EJONOx6CDNYGkcNS94z8jPD9tQ1AzvlAt6lie0SCqoIJSt3Hgr8hJ/xm/fX4q/ztuAvV4wRrHBbioRh2goEU0FY0aMKTaoN4gfaccNUBoBs0Bo3HLvoKYNK8Kv3nMkdiz1SkHKjYXxrZDd73pGOuVbB5pKtFZi/8YBQH2MCKKuqx8mPfgzAXRPkiSn964OsNB6uj8PnQZsNP0mtMv0vWYTKEJQqrs95J58GlrbJqVde15chBRdy8MXMRPzm0o1JNs1f7qrC/0zuK9TQyKQKvvjUBP5cyul1rG01SaOKnGgY98w4Bg+cMxRDf/Y+6mIJbC+vRd+SXNt9DXCO08+ogm8jH5B1K8xSGgoA1lPGmbdORNwwhet9SNd8/Dc5X4gcxBTlZOB7U/rZducXH9fDFcT+/pLRyv358cK1x8MwTM+JkCf274h1+6oxcUBH5ed+yIoc394sn/PO/z2zovivA2Zt7ceQrvmYedskmKaJjJCO0vxMOxDwQ76vyYMkTdOEYIOlSr54/QlQMWN4Fzz1ySZh/j2ZcEjHez84CbGEYQe0rK19OuZ4pm7ekUzVY6RKR/NLnUqX/qW5GNQpz06hPXlwKTRNs80hju1V5Pd1JRlhHS999wTc/9ZX2FtZb9fiWg5vzXcyi4ZDgkrF0DQtUEAFSEpVE9L/AMvO+80Vu3Hh2B7CfaxzQWaLHGdz6F6ULdRONZd7ZgzG9KGdXIGsHwM65QkpfwA8H56k4v+uGotYwnSZqKjoUuicTy+XUUZONIxISLPHU+zvO6L73z8YxZzy2q8jl6bIBVUs3fekAR1t18puhVmuvjh5cCm+e1JfjO9XjGueWwLAKr2goIo4KognzMBP+AHgxUXb8Kc51twSCzeXt0pQxQ+UY8k5cqp8rML5+7ocVAGWCiEPPtiA1jCdQS6rDWBKk65ruP/sIbhfso7NjFg/diyoikZ0dC6wfrz4+W8AKz1tzd707xaqiXG9iEtzbQR1AORvn/I1EA3rCId0QcEyudhNTP9zK1X8Mrl99vbsYxT/ddqUbKfGf8d0BdGMX7+3Duv2VWNo13w71UxFqst99yEnBZQ3ANirmFBa0zQ7/Y/l9evJp5irdlVi/b7DqKiNCXV+KgMP2ahCFYhmhHTM+9HJnoEKa09E+mFkKVQhXVM++f/+KQOwaEs59lbWexbONwW/dv7vmcfgllP6p6wJSRevKRQACAY3TVEmvg40TUtrkCgPgpqbPXDntIEozskQ3AlVdJTMgiYPLMGPTh+UMt2pLTlrRBesm2Xdi09J1tdMGlCCeT862dPEIRW50TAeTVp9H/uLWSivaXQbKbUhHXMzUJQdQUVtrMnX/Ph+xVj34BkAgGc4++9OKZxRj0TyMyOtMqYJiqZpyAgHC1R7JNWp7IyQywlTRX5mBAeTaeQsbTjo/aNvx1ycNLAExTkZQsriCX2K8T+T+2Jo1wL7gc3pw7rgj5eOxmOz1uNSyZyF7YMZOF1+Qk+s2lWFUweXYo731HHtEgqqCCVWulzwoOo/XM1INMDTlKYgD8h5Nz3VXC1ycCAHCPWxhOvJHq+KMKUlpGl46LxhuPSZRbal7dUn9sHgLvm4+OmF9vpZkZDwZKooO2LnLMuzg5swfWuCvEgn/U8+3sMB5qoCpBQ+Kf2POa151VSx8bIVxLq3zW/P6/oypLQ/+TiYUiUHUfwPAV/PVZWcL6amUTz+37y/FvM3HMAzV41FaV5myjq33ZWOUsUHVXIfAaymytofP0fMgE5WULVhX7Wr7iKhCJjloEqVMlmaH/UNVLwY27sI/UpyMLxbgVLBywjr9uSyX9eTZ03TWjSg+u2FI/H8Z1vtgnMV/L2jR8CaqvaOnK7jlb4TlEhIxw0npf/kX1cU9bc3zh7ZFY/PXo+sSAgn9ndUsHRq5PwozYuivKbRV+X7utE0DU9dPgZ7q+pb5Dj5Y+vUROWLaBn6leTgjtMGokeHrED37bzMsB1UMeQgSmUgAlh/33+79njl8nvOOMa1/KwRXe25+PxgjoW8U+eRAgVVhJJYmkoVP4ht+sS2/vDKRmPCwJo9jtKT6tYRVyhV9QoHwLgqqAppmNCvI+b96GThSWyOJF+zPOk3bpqAt7/YjSvH97brEGRM03uuLD+8LNUb4waenrsJkweW2kXw7pqqYEGVn6U6U13Emiq3UYUq0GDt9Nq2sz1xu/L1ZNdUScv4ciJ+2zHOzp2HKau3vLgcr9443laBBnfOw+iehS5LZH4iVT7YUaVIhnTNdmrjLb+ZwcCqXZV2Ue6I7la+vqFSqmLe6X+Mpqbv5GVG8OGdU3zXaes0nuZy/pjutiGGF/x5LcwOlj7V3pGNKlTGFYRF7445+Mf145CdEW5yepYfJXlRrN1bLaRKtQfGtWAaJX9snQLWBxOtg6ZpwtxWqTi2ZxG2HhRT2OUgKtLMhzLfJOhOSyhRKTu/m70B0x7/xB4s8vAD39ZyYo8ZYvofbyKg2qVQ96OYd0plVsEHCOwlqxPq0SFbKDCVi01Z3caYXkW4/5yhyIyE0LkgUyjgZ/cm0wS0JmhVTqAhLv+/+Vvw6AfrcfYf59vLWE0Vq2+oDqhUibbo4o5YIKlpmh1Y8f3MbsaNHkEVH4CkVqqs93LKmyqwkJfx9WQskPMK4hZvLcfGssP2/kK6hgzFIJS13TTNlEoVn/6XE3WuE6YIMcvozIhuO0olJIUOCJb+17ngCJvIo53B1/Ac6UEkQx4EyamfhMiEfh1TGq00FTaPllct7tEA/7CxKRbtRNvx07OG4JyRXfHP68fZy1xKNz2UCQz1FKEknnCn/z0+ez3W7zuM5z7d4lqfH6+agZLT0ocf4Ms1X6rxuWwpLg9IVUGVqs5H9/gr4QfLADxNEGYMd+bX4AtHm6RUSf8yVG5+ieSxsKfvh+uDSemaBlTUNOLyvy5ypahlc8fMFC1TSP9LKlWKSWtd7fNYxTaoUEwCDDjBjaCoyWoWdx7ZdcNfD41S++au32/vT9c0ZUEwqyOLJcTURrYvfhnv/scrmizoZMFSWNfBfq+cmipnO2y98ppGXPPcYsxMOqmFdc2+lpqqVBEW15zYG+cf2x1/vXJsWzelxXApVfSkuc04Y1hndC/KwtRjvOs5j3R4paq0Be3UidanQ04Gfn/JaEzgTDiCpv8Rbij9j1ASVyhVDNWT+YSgQLRSmySjCr6ORJVyKNtqy+vMW78fpmlidM8iYT2ZsEdUJaeKZHvYpJ4xrAsenmm5B/btmIMdFXVJYwXl6v4kmycfi6rLY8ljKcyKYBuCG1UYJvDE7PWYv/GA7VzF4AMEXQMSUCtVssKlwmseNMM+xuR7r3mqeCMSaX9xSdUExMCrSgow91TW2WYGugZ1UJXcb73kyBczVEGV6P7HYINbNqlvSNfsPnPc/9zzqT34zmrMWbcfc5Kz0eu6hpMGdsRLi3ekPacTIZKdEcZvLxrZ1s1oUVyWyPSkuc2YOqSTr0HO0QBfU9WSc1QRbYPbqIKCqqBQUEUoiXsYDQBqVcgQ0v9aX6mKJUyEdd70wL9NqnTG385aj9/OWo9ND89wJrtTtD3kEf3IQZTX3BM9OmTjl98ejphh4ovtFfZyXmmR3eu8sI0qAnQxO15W+B+0piphmMoUT0A8Zqu9Yq2arVR5yVAcXvOguSzVA6T/yXVNgqqpqFWqko5vd2W9fQ3puqZ0O2KKVIM0d1TcDtqcZbqQ/scrVdZ2mVV6WNfsPnPmqXK2w5Qq3rIYsK7Jn8w4BqcO7oSTB7edKxXRPpEtkWlQRLQm0XAIXQoysa+q3tdpkzgykO8fIa90HcIFBVWEEmZZrkJdv2T6r9BCbeJf8wMFVcqhnP7nFSQebojbdUcq0wGv+0kkpCMjpNv1Q35z4VyctBBlQZUJ0WghqHEFG3DLgYZKqWODfSf9L6hSZQoBHw8fIDChUGVU4VVTxeM9T5X4r7teyh0kuR0C/a8H2Yp/z6G61Ol/TKmS0kZZsMVnFGrglSrnumBKFUs/1BVKFd8vLPg6JAWBIV1DXmbkqH8CTjQN9+SdNCgiWpfnrjkO5YcbbQtt4sjFZVRBD2UCQ0EVoUSl7DDUShX/unWiqrhQU2XAMJ2BQhClyqtdfFCVUAQDfvnEWRkhNNZZ3/GbWJbBYhUriBJtyfUAxhVeNVUqWBBQmDy2oOl/8YS3asYrVU5NlfN5Kvc/HpU9uLU9/5oqZqkuTuYs7i9ViqqsVO2prLf3q2vwMKqwtilPyMsMVHilqiFu2P2SG3XXVLGgU61UcUFVUhWTlUNKcSf8kGuoaFBEtDaDO+e3dROIFoIeyjQd6ilCicqCnKFShcT0v9ZpE+/+15gwBVVJWVPFjat9gypOtVCVAvkFVTk+boAq2JZMyLbkKb9qfc/D/U/1dTuoYul/aSlV6s9EpUqz12ewY5KNIFR4W6qzY1Sn/9kTNEvnN9W2RaXKClKYxfm+qno0JhylSjXXGqvbqnel/7mDP7Z9TRMVTPZjpaqpYnGgavJfOaiiwmHCD03ThGuEBkUEQQRFTn8no5vgkFJFKIn7pP+pRvCGEOC0VptEpSqR8N9nQlKq2PHomjgA5hWchKLQx6umCgCyuSDDL/2P4ShV4uS/QdU9wWUxRR0WS/8rSjP9L254p/+JNVXuNoXSqKlSpVoCTlAhz1dlf87c/ASlSh14Cd/jjSrqrL7oW5KDHRW1iCVM7E1O7qtr6pqqmIdSxfo5LgRVjvMff45Yvzruf87gt6yqHrf8c5ltwcz2VR9LuK5vCqqIVIR1zf5bkp88EwRBeOG2VKf7R1AoqCKUxBN+SpWbryP9T66pSjXnER/oxQ3DbmNONCyoNm9/sRt/+WQTHvn2cKXNt98AlgUZGWE94EA3mTIHUakK3mViIKlprsUAkvNyJZc1xahC9zgW0f3PrVTZ6W3x1AfkeX1JwZRXTZUpBc3COgrJkQ/CmZJUkJWBTvmZ2FlRh10VyaBK93D/81CqmPsfv8vqejbxrxhoh6X0vxCX/vf+V3tR05gQVMLZa8ow7Gfvu9riFfQSBCMS0u3gXfWQgCAIQoVLqaL7R2AoqCKU+Fmqp7IvV33eEghBldS+IIEeC7JyMsSg6vnPtgKwZr6X5/zRNf8JQVlQFUSlAuQgSKypCoIpHZNXHRavyrBar3gA9QhIBlUehyzOU5VsB9fR6bj/pUr/k63V5c8TPul/Krt2Uamygp78rDC6FmRZQdUhR6nyMqowTdNWqrIzQqhtTCjd/9j2cyTbfTnw5uepqk0aYHjNy+W3HYKQ4Z8uU/oOQRBBcf9O0f0jKBR+Ekriho/7X6r0v9ZqE2+pHjekmir3+kJ6WMKZ/Dc7qg6ADtXFXAPYVINXNldV4KCKtRemVFPVhPQ/8K+9lRpWH+TltieT8En/UylVvH15WkYVKdz/zBRKlZzeqVqHR1VTlZ8ZQZdCK5DeWcEFVR5P5hKGaStVzICC9TV/yCy9kK9BA9xpFCFds1Mm03kWQUoVkQq+joqeNBMEERS3UQX93gSF7rSEknjC9BzktYf0P0tJEwfuskLGB3oJLh1OVg8Y+ZlhlyNdqsGrrVQFMKkAxJQ/saYq0NeF4Mmvn3mlhgVVXm57Mn5KVZZrnirRPp19r2WUKvFf+3sJd/qfq6YqpfufFfTkZ0XQOalO7raVKiCiUKrYfpilOguqVO5/ts2+dF3I832EQ5pnqqUfpFQRqeAd/8j9jyCIoMjpf5Q+HBzqKUJJwjA9lY1Uk/+2llFFjBsUN0o1VVYbvNsUN7j0Pw+lKi8z4tpmqic0LEALYqfOI1uqB02ZFKYD83gNiAFERrpKlYcBRt+OORjTq8h+z7qGd/rT7Zqh1PvyMqpwaqrYvx5KlRA0G8p1eNRKVRjRsHXuWP1JSNcQ9fgRiRumvV5upqRUKQ5HdhGUrydeqUoHCqqIVIjpf/RTTxBEMFS/U0Qw6E5L2PADe7lmSVivjSzVefUhnjBcyoscmAiDbtMx3vBSqvKiYVfgkUpFYEpEdlClijeq4JYH7bOgKiCfkseeMiUCBDqA1W/yTfSUwaX46K4p6JgbtZc5TnaOG57t/hfAUt1LOXMrVXL7DNdy2ZhCaVTBfaHSrqmKuNQ1zaOmCrD6UFaqWK1VwnRfK3I/qnLVm6JU0W8ckQo+kCKliiCIoLiNKuj+ERQKqggbUxikGp7mE6km/20towqhpkqap0pug/WeC6oSTpDolaoXjeiuwCPVExqmeqVrVOFlvpAOfuqgbaXMz4OUVk2VuEzVDyqlSpMCFN/9eLSHLbcVK496KTm9U7WO1zLbqCIzYgeC7GNdE93/+EOPGYZdU8XXS8UNU6lUyQqB/ARQl+YTCgo9OSRSwV9rdL0QBBEUlaESEQzqKcJGTpeL+wxaZQQnvlZSqholS3W5Ta7aG25cb6kJ/ttPGO7BeKr0v+w00/94owp+T0HrnfxS/nhYTVU45J5cFhBru2RURhWqfrBrqrigih0GC6q8DB8A9TGbpnOe2PmVgy/b/S/Nmir++mDzSOVnhV1KUUgX56nKCOv28ccTjvtfHh9UJbyCqhRKVahp6X9kVEGkgjenIKMKgiCCIivbpFQFh+60hA0/Lk1IQUjCQ7VyvhvMQKE5xH3mqVIht4kdgzzPECNhGK62pxq8dsy15oAqzsnwXc/GlqrEfmyuUYWX+59l2e2eT8rvqBKGu6ZKNShjD6/4YJcFQqymKjPifYtRBeqyZby8DHCOTVAipW2ptu2pVEmBjpz+Fwk5fRjnlCpWU8WWK+c4U7j9ie91MqogWgXBqIKuF4IgAiIrUxFSqgJD81QRNoJSJY0QeR8A1fhfHAy3cMNYm/jJfBPumi85IHIZVdiDdHUDZXUOSD14PXtkV9THDEwd0in1AYBXqsR+DGypnuI8MNhxhEPO5LJ8f2ma5il1xRXpfyqlyq6p4oJU1rdMqcqMhGxVyKuNPKraPK+ASZzcWVwnptp2cllDPGGbTfDpf/xx8QpbNKzDNC0jizhXU8Wn/8WaqlTpGlI9BCzNiyIS0u15tFTbIQgZ/tojpYogiKCopv4ggkF3WkJJTBohJlIoUeJEvK0TVcnpf/JA2s8BL2E4xhYXH98T3QqzMLhznrB+PGE2wVI9jKsm9Ea3wqxAx8BvTqXKpIJfy+QDLJ+aqrDuDqr87pEGZz/P8A2qEor0v7jaUlzYj1LxdF6zAM3L/U9WVoV1fCzVG7h0xcwMt1Kka6Jrn6hUOel/WZGQ3Y9eNVWpctNDeuqaquN6d8A/bxgntZF+5Ah/+ECKjCoIggiK21Kd7h9BoaCKsOEHr7yjG5C6ZurrsFSXjSpkG223UuW8ThjO+w45GZj/45PxyLeHi9tXKFUtnUtsK1UmwIdIQftMMAzxCV6ZUsQP2l1KlQe8qsdQ9QPbBF9TxfZhK1Vh76BKlS6nSiN118qZwr/ya3YM7v1Zy/jrKKLrblMOzV1TxX5U4oZhK3OZEd0euMYThjKoktMmmuL+l50RcgVR9OSQSEVEsFSn64UgiGC4a38pVAgK9RRhw49D6xrFoCqVkUJTVJd0cdVUSaNYea+GpFSxQXVI16BpGvIyxexXfh1GU0wEgmDCbJpSZXq8ltZzlCpHieHVRr+jMkx3aqXa/U9lVCHVVKWtVLnT/6TY2TbhENM7pXmqVEqVlJoYSgY0QWqqmMIUT5ioTz5wyIyE7FqVmJdSlWJm+iDzVOVEw+5aLFKqiBTwE03ToIggiKDIDwPpoUxw6E5L2PAqSF1MUqoEhcRN4mtQqhoFpcodAJnSOFp2h2ODcDYgzY1GhPXjirm5mmIi4AdTiNyW6sG+72VUIcPXVNmW4UL6n79SJfeDylJVZaluSIFLpsd8T4B6Lil+tyqXP8AJsvyMKvws1Vnb2A+F3Beypbqc/seMKqJhXqkylcpbkJqqVNdYTjTktmKnOzeRAt6cgtJ3CIIIipyZQu5/waGfZsJGUKpi3kpVqvS/r0epMl2DbTkdTmgTF1SxMXSupFSpzC9a+glNc40q/NQpnrigxiSXCel/3t81lEGVT00VlyoqW6r71VSp5qlSpZHKxiJMlZIt84V1VAGbHVRZ/zIzCtUEvWFds/tISP9LGPbxZkZCwvJANVWuAmA9kFKlsn0nCD/CQvof/dQTBBEMV1BF94/AUE8RNvzgVbYd97NU5+cWst63Tvv4gbN6nipxfdkdjg3C2YA0W5pbyqqpEo+7pQ0BnMl/5T4L1mkqJUcF65uIrgs3RNYn/kqV4Qp4VOlD6nmqgtdUKeep4rrfVqpkBdI2qvBWqvws1VnAyX445KBG06z0UFZXlcHN9RU3TMTiyb7l0wI90v/kgl+l+1+KAGlw5zylQyFB+CHOU0XXC0EQwaD0v6ZDluqEjd+43s+oQh6/tpb7X4wbXccN06VG+E3+a827JQYU8tP/hGKuodZUBJo7T5VfN7MAQq7ZSZgmdGgp5qlyBzxqpcr6l3dlZN9rTAYezVGq7JoqL/c/X0t1xeS/9hxa1mcs4FG5/wFANKSjMW4klSonzc+eWFnX7MFqLKBS5QqOfNL/jumSjwvGdMfJg0pR3SDa0pNSRaRCTP+j56cEQQRDT2ZqsJ9eeigTHLrTEjZ+yodijOr5Pb91mwMfVMXiipoqV7AnKhlsEO81vrDULLHxLT145WuqWjL9zzVBruGoMfxDJ7vPfA5LZdihuqmq5qliX2OBi9/kvyqlKi33P/78StGwv1LlKE2A+3pg55zVVcmT//KGJ3awZZhIGO4+koNROY0i7GNUMbF/Ma6b2Aea5l6HjCqIVAhKFQXhBEGkAa9WUfpfcKinCBs/tUQ0qvBPtWq9miou/c8wXKl6cgqda/Jfg9VUOQOMRT85Fd8e3Q0AC7zEfbZ4UCW0l2trwEDUVAQdKlhfyellhqTWqUiY7nPqp1SJNVXJ9L+4M/mvZxtVtueKNFO2zQwugLGWi23mkedZE9pmK1VeRhXuoEowpDCdoIr1S9xj8l+XUqWYVNEryOcVLHk7LW2gQhx98OYUpFQRBJEOQk0mKVWBoTstYeOXtsebRLjS/Vzpf61DTKipcpspyPuV5zFib/mn/J3yMzGyRyEAZlQhKVWtVVOF4E5+PN7qlDrQDeu6EDTE7cDSex8JRU1VSPGkyq6pUqT/2TVVPkGVSk1SBZps82yQyPYhW+bLx+C1PxZwsUBJDqp4gwr2b8RWqkwuYHWCrZjhMU9VyD83PaxrngEuf+2RpTqRLmGdaqoIgmga/G8VKd3BoaCKsPEb1/NP/v3S7KzPW6mmSppktjFFTZU4+a/pqdLwqV1ynVZrqd6mlP/XlPQ/v+/EuBQ1/oYYxKgioXD/U1kyqy3Vk8uY+59PUJV6nipRqYqEZaXKu6ZK5f4nW6pHvNz/kn3jGFWo0/90HZz7X0ClSqFceamh/HJX+h/9yBEpCAmDIvqpJwgiOPzvo0YP8QJDd1rCxn/eI2fg7Er/8wlmWhI53a9Bsn1PWVPFDYZ52MCYD7wYLT0YYRYRJuSaqmDfN4X0OChfA45SE5YG7awP/G6RhuG+Fvwm/23wc//zqalSKVWiuyFrj5j+p66pkoIq1bZZTZWRIv2P1VRxQVVEmI+KU6pSpP+55qmS9uXn/se3y2WmQUEVkQIx/Y+uF4IggsN+l0ilSg8KqgiboEqV63tSplWrKVVSG+rlubQ8DA0AcfJft1LlKCDyYLzlJ/+1/jXN4KoTT9DgK8bVVFkW4dZyFoj4PXmKK40qFJP/6n5BlfVv2kqV4DIp1k45phCGa123UuVO/2PrNHKW6IA7YJTT/yJh0VJdqKni2hREqdJ1DfyikK4HUqoA8ceNxshEKkRLdfqpJwgiOOz3keox04N6i7AJMu8RAFfxkl/aXUsiK1X1cdmoQlxfTiWza6o8BqsJzsyC0dKDV7Y5uaYqaCAqqlumcjngnC8WMDKFJIghhmVUIS7ztVRXpP8xpSrqZ1ShiEJUgSYLYliQ48xTxbVZDqp8nAV5S3RA4f6nMKrgJ/ll7bbc/1hdmenqM0A9mBVqXXzc//zMKUipIlLBW6rT02aCINLBnseR7h1pQUEVYeM3rheNKlKl/7VWTZW/UuUKqnglg0vb8qqpiiUM12BcZdDQLOyoypQCiGBf90r/k2HHYae4cTVB1v78AmgjkLU860fV5L9smZ9SpZqnSkjpS75kx2wHNiz9z0+pUlmqJzcoW6rLqp3t/sfS/8K6qFTZ6X+aM/mvxzxVymCUu6RCPvNU+ZlTkFEFkQo+oKenzQRBpAP77aLU4fSgOy1h45v+x6dlSZ+1VhDlboM40K9Llf4nGBk435XHsHxNlax4tPRYxLOmKmBU5ZUyKCtdLAiW86JZN/gHVW6LcrVRhdv9z3HYC2BUkWKeKnZMbJuyUsUfsxwEqtL/7IBPslR3Tcgru/8JluqGkP7HB3pB0v8AhVLlFVQp6q/8tksQPGSJTBBEU2EPYsjkJj2otwgb/3mPOKMKlyIUfDvNQU4XS2Xlzo+r+YmD3Y5s/ASuqQ0amgM/ThbnnAr2fSFl0Gc9Xk0BnAF6QgpU1N813GmQSkt1619eqWKHZNdUZfgpVe5lqnm45JoqpVGFdA0qlSpp8t+wR02V0qhCoVSFmqhUhaTgyMuJ0c+cgtL/iFTwk3dGaGBEEEQasN8peoCXHnSnJWz83f+CK1VBJ7JNl5iqaMWnHfwAvZFLHZTTvfiaKndQ1dLuf6xt8pxT6StVQiqgtB47X/ZcTNwxytuRUVqq+7r/OYqhrFT5uf+plSr+c3E9efJf/nJwK1WKbUttY9tLOflvWBfNTDgVkCkAMQ+lSl1TJQZV3kqV9N7HYp0gZARLdVKqCIJIg7BtVEH3jnSgoIqw8VNL+EGqHAC4gplWmv43VVDlthXngipfpYrVVJnuSW9b6X5iQoyqgipVgl9IgBq4sPS0yVZ5fJUqRT8ENqqQgyofowpF9O03T5Vf+p+7pkox+a/UNq9CXPZ24oCOKMiK4LjeRYJRBdtVWNdEq/UmKFXpGFXIChdB+BGh9D+CIJpIhJSqJhFu6wYQ7Qk/pcrwXMud/teCTRLa4L9hOdjjAwN+4mD5HuEoVarJf1vRUh3uACIVXul/8tfjXIoa/6/jnOcTVJmqyX8VluoKowq2WbbML6hSxcj8tcS2xc4jn/5nSm3kXxuGqbwG2bmNSUYV8qGxc37R2B64cEx3aJqGfy3bZW3DMO2/BV3TuHmqDCQM/wCKISpVuucE07JKygdffpM3EwQgGVVQ+h9BEGnAHsSQyU16UG8RNn4xSywdpeprqqmSkT/lm8GrXPKANBzyrqlqaStiwahCUKrST/8LYoFvBw7MUt0MkP6XCFZbpqmMKqR5qjJCuiuI9Wu/Sqlii/gn7wkpcOIDbq/g27ZUl4wqvNL/AOcYlZP/hpx5qjzT/1RKFa8g+KX/yVbvQjCm/ApB2PDXHilVBEGkg21UQfeOtKCfZsLGb5AeUzi8eX2vtcwAG9OsqfJK//OyVA+a9tYseKUqYCofj5eluvz1GDeXEv+vyuRBJmGarr70m6eKD7jl9D/ejty1nxTuf/Y8Vbb7n6N6yW0U7dXV1wkLtmJ2UOVVU+X+rq1ISUYVTlpg09z/Qj7pf17XKUBGFURqImSpThBEE3HGDnTvSAfqrW84+6rqcdM/Psdnmw4EmvcIcCta7sl/W0upEm3CZVw1VXz6n09NlZPC5VZoWjrNytma6TmRrx/BlSqxbojdF1mfpFK5XIqdT/qf3D7DMLl5snTPPlQrVe7XbD1ZqfKap8pTqWJBle2M6OH+p2gvU5diQk2V7rj/GQbiit2qBrOygUDgearIqIJIg7CkiBIEQQSF/bapTKoIbyio+oYze80+vPvlXry4cHtgS3XZtc0dZLVoE7k2WBvOlup02GDT3/3Pu6bKmdjVcM1v1PKW6sn0PzkADDpPFf9aULrE9Ezb/U+2VE/WI6Xr/qc0qvC4ezRwfR0OaZ4DOqVDn2KeKna9RcPODuOGrFQ5+/RKE7WVqmT7IuHU6X8MVpPCOx2GNFGpUp1CVb8Jk/imYVTBv6XiYSIVsiJKEAQRFPbbRul/6UFB1TccFmw0JgzlQLs4JwOAOFCVU8fkAXgrxVR2Cp889xEbtPsFKixFTdMUlurc5L/ywLjFgyrudZPmqQqwnmE65yskqTGqY5RR1ZapbFXlfmRU18fs1zkZYU8lRpWCqOoTeZ4qwKr7Sjf9jwVntormqVS5v8vWaYhximfIcf+LGabSeCOQ+59H/7hq/7hBMhlVEKlg114kpHn+rRIEQahg2Sk0+W96UG99w+EttlUD9kGd8wAAMSOdmqpWSv9L7jdbCqrYfEPuoMp5zdL/VKpAmJ+DSBqQt3Sale3+h6bNU6WqOZLhlSrZFtVQBEyufQS2VFf3TWWdFVRlZ4SSE+R6pP+lmqeK1VSZYroekFSqhHmquKAqhVLVKNVU+RlCMFhQWc+rcNw8VfGEOv1PWVPFBaiW+5+6f+R+49cj5YFIBbvOaFBEEES6sLEDKVXpQXfbbzgJ7um9PEh/4jujHIVDYUbAkMf2rVFTxQcDsk13JJkW5pv+l3BssGXC3DHKIkdrDV5lo4rASpW0DRWG6aTDhSSHO5UJhYwVsMhKlaqmSv19FlTlRq0ZGzyNKhTtEKzRpZoqXZMmavaYp8oraGTrx6V5quRrQvVUnyl+DTEn/U/XuHmqPNz/UtVUhXTvwF0OtvhNUVBFpILcuwiCaCrsN4YeyqQHzVP1DSduK1WGPXgtzYvijZsmoEeHbPx7uTU/T4wf7EqBhyv9rxWEKl4py4mKl62d/id9hx90szRH1f3BqalSKFWtlP5nSlpV4EDUQ6kSnQBNW62RJ/+NeyiSPIbZPKWqKpn+l5eZIqhK4f63r6oe17+wBDvK6+zthHQtGcCYQtAspnqmSP/j7N5Vx6GsqUoOTBtkpYqbpyqu2G2z5qlyuf9R+h8RHCf9jwZFBEGkh5P+R7816UBB1TccfqDJhqXRiI4eHbIBcINxxVxE9jZc71u+nXxKFxusM9igwc9SPeanVCmc3RitaVTRlHmqDCF4UmOa4IwqxLohVWqfjJxaZ21HVVOl/r6tVGVGrH17rKgKqvimldc0YvaaMm5/VhDTAPdcWkLNn8cFKKf/sfPudtlzf5cdPzOq0DRLSbLnqfKwVA9UUxXQqIIXHGicTKSCBkUEQTQVMqpoGvTTfJSydGs55q7fn3I93mLbtNOsnD8i9lqwVE/h/pduTdXn2yow/pEP8e6qPZ7r8IPmXE6p0jRn8CnvVpz8N2nckKKmSqa1FAF3TVXQ7/HqlOmx3Aks5MAhoUjzdO3DdKs9QS3VAaCyNqlUsfQ/j5tyKqVKJqSLTo18EKMyJVFhGJyKx5QqadCpTP8LMfc/sTbPdv8zzOA1VfI8VV5GFT6W6qRUEanolB8FAHQuyGzjlhAEcaTBfqfooUx6kFJ1lHLt80tQF0tg+X3ThCBERqypspbxf0JsLB1LQ6lKN/1v/oYD2FNZj4/WluGM4V3U7TTVQVVI0+zaHjmYEwbaycGwaizqd9No6RuKvX/J1rwp81R511SZjjGHZKlumO56KRWuoMpn8l+Zqvo4AC79r4nzVLn35yhDzBqeEfcxUuGJG07fZITEvuH3I8OKdutjYr+yHx5L5VSlDaaYp0r3mafKZ/JfqqkiUtG9KBtv3DQBXSioIggiTRylirSXdKCg6ijENE17YFvbGA8UVPHuf/ygklc4GC6lKoUbYCrYINdr0lZ5/7ylekh37IJ9a6p8Jg72UlIAt1rQXPhxsinUVAX7vlf6nyktZ/3FbMN1+zyq9/XEd0ahPpbA3f9aBUCc1wvwCqr83f9SGlWkqVTpmiYop/z3hQDaw1KdbV+e/FeuaVL9htiW6sn0P9YfTAmsa0wI67L2KK83KTgKnP5HQRWRJmN6FbV1EwiCOAJhvzGq6VQIbygEPQoRbKm9x5cAOKWKm/eHH+OxQWws4R0AuN83LajyMhjgtxnSNcH9L6xrdnvl4C5d9z8VLW9U0byaKiEQ84jEDM5SXVaq4pwhCc+ZI7rgW6O62e/lFDqVA5DX3DdOTVUTgiqf6FLXNMH9T5inysO0QiZumNzkv8l6s0BGFcz9jxmeiD84NVxQlSVdnzKiUqV79o87qCKjCoIgCKL16ZCco7QwO6ONW3JkQUrVUUiQuYwYbABqmHxQ5X4iLhhVpJqnKs32NqYTVGmaMGgN6ZqdriiPpfl22ipcikGuTGul/7lrqgIXValeutICWTqcXFPllf4X0jQYujsItT9XPK3yTP+rY+5/SaMKD3s7lWGGn2LH11QlJDMNvubO7zpKcA6P8hxeDLWluodSlTw2XqmKhnUcbhC/xxOWFCevAMk1f5ZgVEFBFUEQBNE6XHx8T+RlhjFtSOe2bsoRBQVVRyFGwKf2gJNyFzdMe5TOj9dCXLqVavuq9+nWVNnpfz4GA+w4NA3IjDijzXBItwelphTOqTanGotGfOZhaDWjClMMpIKn/6UOmE2Tt1QX3f9U6X+2k52PcN2U9D/bqMJjsyoV1e8hgKZxk+1KLoZBJv9l6zUmP2fqkxxEqdLxbEt1u6ZKF5bXJuevCnHKKaDORxeUqpCPUYVfTRUpVQRBEEQrkRsN4zvH9WzrZhxxUPpfOyZhmPjjVzp+/K8v0/peEDMDBhvEJjijCsH9T3cHVXKglkq5SgWr34n5RBZsAB7S3UqVHVRJX1epP6rBqC4NhIX1W3WeKoemGFWIqpWoyrnS/3ws1VnA5Heo6RhVuNP/PJQqpaW6dz/wTnly+t++qnos2VoOwF0PJu9TnvxXPseq42LBqe3+p4vLaxutGsaMkCacI1W/uZUqdVv9aqpautaPIAiCIIjmQUFVO2bVrkpsqNLxr+W70/qeUMAfYE4i619Dnf7HlCof9z8/K/MgsPqdmN9gmEv/i3rUVMn7VQ3aveqAvNL8Wt6owqOmKqBU5RFTCfA1VU7AlAxGFOl/bLCuad6qiWq5V19WJ01SbKMKjy5MN/1P15zjiRuGcBxV9XFc+NQCfLbxgDBBr3v7vPufuqZKbaluLbPnuGJ2s5JRRSSkC+dFbVTBWaprltGKqtv9jSrc6xMEQRAE0XbQT3M7xm++HT/SSf9jA9MEb1TBfc6CCr4t8lg4VTpgKhpt97/UNVWaBndNFWcXzqM69nSCBqD15miwaqpaLv3P7f6XVFRsNcb6LK6YpyosDfJlwlwf86RM/0sqVSqTC6B57n+8ssrzyfr9qI8l3B8kiSvnqZL34/6enCLqOCMla6qSaYGRkC6obUGUKv5f1T6cdmnK1wRBEARBtD0UVLVj0g1OnO85r1MZIDBFI2E6Q3x+/OgMxr2NKmT76LSVKpb+l2LSVraPTA+jCvnbqv7zDp7UfwotXbuicY1tyXmq5G0xYTEsDdoNRTCSyqrba0Z1r3jzcIM4T5VXyVrCMFFZG8Oj76/D5v2H7WVe6HJNlWLdjLBuK1WqU2cYph3ERzzmqQoS4DjzVInLM8IBlCquP9nxqIIkuV2qYIwgCIIgiPYBBVXtGFGJCB6p8OumSv+zlSpuMlVdkf7nNSeQ1c7kunZQ1TSlyte1TbBU55QVXbMH7W7FzL0drxjJM3BopZoqQA6E3Ou+8NlWvLJku+e2PE0rTE6p0lhQ5Uya61aqUgRVHlFRqr7JjUZ8v28YJn74+hf445yNuPjphVbTfS4dq6ZKt7+rCkQjId126MvJcPvw8EoVU5n8FCFnu+qgitmy8+vxzVIpfEGVKrl/+fdkVEEQBEEQ7Qty/2vH8APthGF6Dvz9vpdqnire/Y+tq07/czbkdvtLDlJ1DY0InsrGCOL+x9qmS5bqYV2z536SpSov63AVXml+LW+pngw8JasKORBdvbsKP3vrKwDARWN7cLVYXKDNrS8GWAqjCs1Zz6umSn4NAMU5GTiudwePY1EutnGUKvWKCdPE7DX7AABl1Q2u45ARa6rUQZWuAfXJVLysjJCtmtn75C3VPdz/VMcl9wtrR2Y4JCyX0//Ux8EpVbq6rku1jH9PRhUEQRAE0b44qpSq3r17Q0sWfrP/fvnLX7Z1s5qM1+Sm6Xwv5TxVzP0v4Qzy1UYV3koV2wYb6KU9+W88aVQRYJ4qXZPT/3Q7Dc1VU6UcdKdXU9VaSpXbUl1s6/yN++3XXoqWlyW7CSdwstPLhGBEbJNfUPXxD6fgz5cfqzyWVHU9uXZNlUdQpWiLr1GF5P6nSv+raUzYSlV2Rsj1ecIwbXdA/iFFqhTISEhdU8WrpoBlfpHq6lcpVUHmTxPaS0oVQRAEQbQrjjql6uc//zluuOEG+31eXl4btqZ58IpCOnFKWkFVglOq7MDF+ZwN7Hi7c6+BMBssplsJZqf/+chqfN1WpqRUMWnB3S5FUNXGNVUME7LSJH6+dGsF95kJHY7CZW/DJ8BiShULfPg0TjkY8QsoIiHd0+UvVbzJ0u+8gq+mGFXwSpVq1ZqGONhtLVuR/mcpVUxZFQ06EnCnvzJkldgJqiSlKqyl/FsVaqqaaFRBNVUEQRAE0b446oKqvLw8dO58dMwAzWfDpXLx4zHT+J6tVJlOTZWmSDOK+6T/OSYSenL/aSpVQSb/tdUwuGqqHEt1uV3u7QSdEyjV8qbi2Vbp/dJtTlAlpgmqX8sKlq1USZP/qmqRBOVE8x7Iy/h9lhsNe5o5MHglkdmv+85TpfFKlaFUIg83xO11vJQqdr1Fwvx1DiBpGqg6LPkYvIKqjADpf0qlSpX+R/NUEQRBEMQRw1EXVP3yl7/EL37xC/Ts2ROXXnopbr/9doTD3ofZ0NCAhoYG+31VVRUAIBaLIRaLtXp7/Wjk9t/QGEOGHixYaWh0vheLxX2PI5ZMlUoYpv1ag+l8x2QBD+/+ZwjbjMWtuhWWIZUwTNc+TdP0VDwakhbYjXHDs62xWDzZNiCsOf2gwbRrqmJx8VhVFu26BuU+wl6JsEaiRa8DI9mPhmEiHnesv+NxZz/7qxtQXtNof9bQGLMbyJ8H/ngT3LE2xmK2GmMY1jpaMjSLxRPCdQVYA3q2HXn+IzMRR8xUnzfTR1nMyQjZ29Q8tEs+9ijKjiAWi6HRxw7dMBJ2vnJDYxwJRbpodV0MGUklKCviPqkNsZjjMsmdWz6YNFXnXDrWUPI6CkFsrxx8qa4dja+LS8QRg6Gcy8tIiNcz34/KNhItDutj6uujBzqnRyd0Xo8+2tM5DdqGoyqouvXWW3HssceiQ4cO+Oyzz3DPPfdgz549eOyxxzy/88gjj+CBBx5wLf/ggw+QnZ3dms1NyRcHNQDWk/D3P/gAWSGgKgYUZPh/r7wBYKd2/mefYc+X3uvuK9MB6EgYJj7/fBmAECrKKzBz5kwAwOYd1ueHqqrBKoIaGmP25wCwosxqZ6yhHoCGxsZG4fMPd2mYvVvHDYMS6JvvbsOh6hAADXX1DcL3eDZVWcdUX1uLuR/Nto/vYPmhZCCg4fPPlyG+1Rl41tWFINpuAFWVlcp91Na41wWAZcs+R8OWdBMavVm71+qrfWX7sLJxL9j5XbtuHWbWrAUAbKh0zjsAvPfee2Dxwfbt1vkAgKWff47GZNsqK532z5nzMWqTx/7Zp/OxNRvYmfzeuvUbEN6/Dvyffl3NYbtP6qU+e++9dz2PZeMOsZ08icZ6e5v79jpt9kKP1WLmzJlYudd7m1+uWomDBzUAOlZ8sRI1tTrkc7Zt915UZgCAjqry/a79fjL/U7Bj//ijD5Gd7AYj4Rz3ooULcWC1uO+D9QDfZ4cqrL8RK3Z1lldWHEQsrtnbUl1rm3dyf9fvvQdNAxoa3NffRx9+iNwId2xbuXO/eDEq17XcdUn4M2vWrLZuAtHC0Dk9OqHzevTRHs5pbW1toPXafVB1991341e/+pXvOmvWrMHgwYNxxx132MtGjBiBjIwM/M///A8eeeQRRKNR5Xfvuece4XtVVVXo0aMHpk2bhvx8RQTwNWJ8sQtYbznAnTp1Kt5euRe/+O9aPHbhcJw9oovn93ZW1OGBZfMAAONOOAHHe7i3AcArZUuBQ+UAgGEjRwEbVqG4uANmzDgOALBpzia8v3MTolnZQF0dAEAPhTFjxnR7GzWf7wI2fYXcnGyUN9QhHIkIn9927wcAgN99Fcaa+6fak64yfrV6LlBfD0jb5Vm0pRz4ainy8nJxzpkT8KPF1h9Zdl4+cqMhbKk+hFGjR+OMYU7q589XfgzEGoXtdCgqxIwZ41zb//OWBdhbV+1aPu7443DSgI7KNjWFgwu2AlvWo6SkFMMHl+Llzdbovf+AgZhxcj8AwPyNB4HVn9vfmTZtOrKSqWyf/ucrLCjbBQAYPfpYTB/aCQDw5ObPgFprrqfJk6fgD2sXAfEYTp48Gf1KcvD5f9di3r7t6NOvH04YXAJ8udjefmFBPmbMGA8AeGL9fBxssG4eIV3DjBkzPI9l85xNeG/nJvt9JKTZKlBBfi5mzDgRAPBR7SosO7jHt1+6lRZjxoyxqFi0Ha9tWatcZ9SoUShbvQ9fVpRh8NBhmHNgM9DYIKyTlVeEjoWZwP596NOjG1aWi/sdPeZ44KtlAIAzpk9DTjLt8Gcr5qAuOWnxiRMm4NiehcL39lbV4+fL59rvSzta7QWAHy2ZZR93l06l2FJTbitbqv7b/slmzNyxESFdw5lnWp//Zs1cHGqsF9abPu00FGQ5UdWq99fj4z1bAQDjx4/z/bsmWoZYLIZZs2bhtNNOQyQSSf0Fot1D5/TohM7r0Ud7Oqcsiy0V7T6ouvPOO3H11Vf7rtO3b1/l8nHjxiEej2Pr1q0YNGiQcp1oNKoMuCKRSJufRE13ntjroTA27rcGu1sO1vm2LRTiUob0kO+6JpfaZYIVzev2dzKSltF8ppVhmsI29WTdDguWDBPC5yV5UexPWma//WUZLhrbQ2gDM8GIJ0zPturJvgjrOjKjjlQXN0x7/6FQWPi+evJfXbkP2d2NEW3h6yCc7E9d16GHnPOraU67+OUAEI6EEYmE2Yr28lDIObf8kYbCYbuWLpphtT+S3K+paXZfMiJhZ98hrh9CmuZ77BGFnXgsYaXDZYSdtoVDauWJx4S1L033XjcjEkZmsh8SptoQorYxgcZkRl5OprvtfCpjdmbUnmeKr1HKiIRdx52TKdWhcceXGQkhlojbr/l2qfovI3kMfP+GFNcfO3f297j+bunrkvCnPfweEC0LndOjEzqvRx/t4ZwG3X+7D6pKSkpQUlLSpO+uWLECuq6jtLS0hVv19SCbQ8TtSXL9034E978U81Txxf62Yxw3vnOsuLm2SNtkJgm2m5rUPH6QuXq3O9pnFtcxw/CsvUrYJhri8ljC8LRUV3l0eLr/eU7+q1zcZFj9l2maktEE7+rnfRzSHL/KdQzTtPsrLJlFGAobc3HeJMm8we9YpJNhBaaJ5Gv1Nr1g7U01T1VGMghqjBvKdWsa4o6lesQdoNVzNVt8G/k+UJlGRKWiO/5yyYyEUF0fT24ztaW6asJflcuk7EhJRhUEQRAE0X5p90FVUBYsWIBFixbh5JNPRl5eHhYsWIDbb78dl19+OYqKitq6eU1CsDE3uIl6feZzAtK0VOf2wVzRNLgHe8I8VR7zQanmqTJNE4dqOdOFuLvtbL+m6T3JMW+pzhNPOEYV8pE2dfJfPo2tpS3Vbfc/iPboYp+J3wk24a/4fSdAFudBShhuR0ghkFLMUeaFHHzwah//OkgAwNrkZ1YZ0jQhqFI5Wx5uiKMhOfmvyv2PfRbWNXE+Nv5BguK4M+Sgigt4eDfKjLCeck4BlSuiqo/koDadc0MQBEEQxNfLURNURaNRvPzyy7j//vvR0NCAPn364PbbbxfqpY405EDGth7nBpM7ymux+1AdxvUttpfxY81UkwaLQZVbDWIDwEbB/U/cpimpIvyn1Q1xob0Ncbe7Gz/pb9wwEVZkgLGgQQ6qGhOGPfiUFR7l5L8e6gu/3Qwujc1LwWou1uS/zntZaeLx+szLXt00nbmo7HmQNCfglfvJa56qVHby8sde6hQ/F5OXxb8dVPlEVZqmISMZ/TQmEsoArKYxgXqmVEXdtzf2mWveKWEaAfd2w7oGXXPPyQYAmdwFGwlpKR9k2P2RYjJfeZnKip0gCIIgiPbBURNUHXvssVi4cGFbN6NFEVPunIEyv3zSr+cAAN6+ZSKGdy8AICkbTVCqVKlQ8hxShmE6yhQbwIfcStWhGtGGUlaqTNMU0hkbE4Zr7h9rH2J7GPGEYS9zByOKoMpTqRLVhppkYY7fXExNgW3NFHQqWXWSvmSqX3spVYbpVvb4NE452OQDjPSCKm+lild22HYioQBBld88Vbpmp+E1xg1lAJYwTFQlDSdUShVL/5Nr6HQPtY6hJVWy+qTSxfcNf7161eaJx5GsQUzR167Jf1O0kSAIgiCItqOFK0aIloQPNgwu+FBNkrty1yFuXWd5ikxBYZDL0gr58RobcMtzPvEDc9YcRw1x1quoFd33GqWgqlFqoNcEwHaKoTSW5NeXx+PqyX/Vg1FBqVIEBC2FM/kvhAZ71VfJ771CDn4d/lyxc8L+TRjuoI1PZUsnqJK7kleq+OCCbSfDJ+AIkv4XpKYKAA4m5/jKUgTnLP1PDn5CAQKWKKdIiUEVF0wGqKnilTvV9gCrb+WatXTODUEQBEEQXy8UVLVjBKXKdN6rjCr4gWDTa6pY4KJQqgyfgb6cmsetWi4FVbJSJR+LV72YISkvjEZBqRK/o0r/8xqM8gFBawZV4Oq/BKXK8A4OBaHKS53iuo0PNFmKma0iGqbrmoh6HG8qNcRPqVKpMBmqvE7W/iBGFTqf/ucobrPvOAmr7p9mK1PMNCLHJ/0vIqX/CfVKHndF/rrgjy8aFpWqVOqwU1PlXXemNq5I3UaCIAiCINqGoyb972hEqKkyTPu9rBoBooIjDrZTBFUmH1Sx9D/nczYA9FOBWGAWsS3VufQ/OaiKiTVVsRTKlb2/5CblgXwsYXDqT5D0P+XmhWDCS5FoCezm+9RU+R2HpxNgCqWK9VvCNO1roldxNsb3Lcb5Y7q71geaUlPFGVUoAjXZQY+HBe1+AYnOGVU0xA37GszOCCMvM4KcaBi1jc71laVM/2NGFVL6H3csKvdJuf26h1IVCWmplaqQQqmSdqnq+1QOhQRBEARBtB30vLMdI6a2cUYVCqWKHwh6DdZVqGqqoHD/c31PMdBXuf9VJGuqWCqWW6lKN/1PbI9hOsvkIEM1Pg9SU9WtMMt+3eLuf9xrT9VJVqr44/JYzn+HV/8c+27rfYKzVC/KzsAvzx+B47hJZL3qq1TwgYWmuc0+7O1oTKnyvt0YAdL/ZPc/2bwkV1KmVJbqLOhyWaQHUOg8lSpuPxlhXXndqfblV1OVqsaK0v8IgiAIon1BQVU7JsYpDgnO0U0ORADv9L+muP/x4zUvO2z+e2x/Kvc/VlPVuSATgDuokpUp1bEB3ul/gGj+oGofb1gQpKaqf2mucnlL4Fiqm4HS+uTPvAMxvjbOec3Oia1UcYYnqdSQ1DVVYvDNr84HDGN6FSEzouN4LniT0+/YdeplZGG1Taypkucuy4mKQZQq/a+6PhnkSypWELtyz5qqcHpGFaqaKvm6VLoBklEFQRAEQbRbKKhqx/CDY8Nw5q1SDTzF9D/udar0vxTuf15jRH67tvsflyrIBv8sqOqUHwXgtlSXjSu8JjZm7VQFeWxwL1qPO695wwKvQCH8dQVV4PvIWe5nqe6lTgk1WbxSxaf/SQP4BGeprjo0QT1JWVPFvdY1oa/49L+TB5fiy/un47xjuzltdNXSpU7/Ey3VDbsvWDtzMsQgSpX+d7jBqreSnQH5tnsdtletnWhUkfp6YX9ffsqT6jonpYogCIIg2i9UU9WOiUtqEDNxiCmDKrVSlY5RBRvY8uUmXk/EVelqfOrY919ajskDS1BRaykDXQqslDrmvsZwDa5Vln3c/lRjVsFRT9E+3vLaa8DMD1L7lThBVWspAi6jCp/zJLr/qVUrU6FU6ZoTcLJgyeDS/1S1Q4JtdxqW6vJkurLTXzik+wYCjlGF9/5CupP+V8/V5rF2yOl/Kvc/ZmKRJQVgoQDH7WXokSml/6WCBZwqh0RNs65jZfpfGioiQRAEQRBfL6RUtWN4JzwrqLJGnI3xBH713lp8uGaf/Tk/PuYH2H7pVIAYuDGlSkPqwVtCEbjx1tzvrNyDH76+EhU1TKlSp//J6X6e6X9STdXPzh4CALj/7CG2YmJ4HDevSngdz6E6Zz6tPh1zUq7fVPgA0FQEptZrOf0v9Wv+O6wPVYFCwjDtc6dSovgAIR2lyi/9z1nfe3tB5qnSNSewqeOCc3ZsuZlSTZXivB9OBlVyvVWw9D91TZVoVJH6lnp87w44bUgnXDuxt2v/bB+qvqL0P4IgCIJov5BS1Y7hFamEYdppXQs3l2Ph5nJhXVGpcpanKpoXBuOGWKMCeA8weUFJrqniYUpVZ6/0P1dQ5ZX+Z/3LBtDXnNgH543uhsLsDCzaYvWFEExyr/k0MK/j2VFea7/mB+OqY2oOqvovQAqwpLjSS3n0TP9TBFXOPFVc+p9i/J/HBSbp1FT5pf8xnPouhf19kHmqeKWKc/lj+y3OidrLMsKiMsYmHvZK/xNSGT0OW1SqnNfp1lTlRMN45sqxwjLHITGE+pihvO4o/Y8gCIIg2i+kVLVj4tLkv/5F/FxQZaiDC/U+nBE8szfXpcGyCrVS5V63vKYBANCZpf/JRhUplCt5f3xQVJidAYA3f3Awuc2I6X/q49lZUWe/DpIK1mS4xvKnRmX8wQiiTqmMKlTzIPGGJyq1Iz8zYr9ObakuDvL596rgQq7v4mHnN6Wlesg6l/VxPv3P+rdzgRNURV1BldUeL6MKsaZKfdxiTZWzXEj/a+IEUrJSpTQRSaPejSAIgiCIrxcKqtoxYvqft904IA7y/FLJZPh1WT1TMKWKV9Gsf1VP18uqWVBlpf81xg1h4BzUUt1PXbGNKjyCSTENTLl59CrOBgAUZUcQ0jW7D4IoD+ngNRT2UxeDWKqbivMop+cBoqW6KqjilarUNVXc9qWaqohP+p8yqEp4m7DY++As1esa3TVVLMUUsAId/vhYsMKUKrneKojroej+xylVfPpfuGnBDrvM2PGprvOwEOw3aTcEQRAEQbQSlP7XjnGl/3moOBbOgEtMJUtVU8UpVQm3guE1wBTS0HyUKrZaZ27A2xA37Kf7qpqqxriBWMIQLLH91BUnpQ6u9QExPcurFuX3l4zGn+ZsxM0n90ckpOP2qQNR25hAQVZEuX5T4VU1T9MJOTUwgDmFWFOVVKq4gJCZiBjc5L+qU5vPHW8qIzu5DolfX5X+ZytV3PeKsiOoqI3ZQbDf5app8DWq4K8xWanKsCemtt77uf95xZK8CuU1T1VTg3A7hTE3ip0VdcrrLh27e4IgCIIgvl4oqGrHuIwqUszh46yrfq2Cr9+xjSr4+pImzFMlEwlp6JCTYb/ng6rGuNjAWMLExU8vwNaDtZj/45ORnXRpCzK3kqj2OOtHI+40OJl+Jbl47KJR9vtbTx2gXK+52AGgNDmx3+S/XiqWl3tgXGGNz17HE6ZvumZ+WjVVzusg6X9sbior2LOCoqKcDCuoCmBUwe+jnjOqYO1kDpNAMqji3QilIM/P/c8r/Y+/jjzd/0I6BnfOw9q91SjJiyIo7LiGdMnHlSf0wqDOea51yKiCIAiCINovlETSjhEs1Q3veiPAZ/LftJQqhftfAEt11qyQR05SYXYGIiHHHY43q3Cl/xkGvtpdhfKaRuytrLeXy3MS8TiOeu70P94xjr1vD5jwNprwnfxXWK7+PrtuhDmnmKW66W+p3pyaKiH9TyFz9S7OwbdHd8NNU/rZyzok6+LYdZqypopN/stdN6yZpflOEFMfM4QAWg7y3EYVqVWgDIUFOgBkctdXJKThmSvH4rJxPfHKd0/wPBYZtr1ISMP5Y7pjWLcC1zqq80kQBEEQRPuAlKp2TFpGFUJNlbfpAY/JDbABPv1PvV2ehMr9zyNfrCg7Yk3cGtZRHzOEuapkowqW+geIQSULkpRzKyWX8YfKjCf4gTjQ9gX+GtfWpilVHk6AivQ/lbKRylI9Hfc/ORDh4xaVUqXrGh77zigAwC/fXQsA6JSstQuS/hfS3UYQmub0Ka8YHUpOOh3SLdc/t1KVvvtfhqelupj+16NDNh46b7j3gShg58JPgSKjCoIgCIJov5BS1Y7hVZwEN0+VCj7Y8Bqsy8gDWMfgIPXgjQ/w/GqqAKAoqUawQn/eAVBWqhoTht0u/nid9D/39p2aKmudt7/YjQufWmC3iTcY8Ert+rrg67/EWilwr+Vzpg64PJUqlaW67f7nb/rB11SlSjGTA5FU6X88d58xGIM65eH2qQPtY7EmJva/xuXgyOv6rEkaWbDPeQUOSFVTldqogl8n3cl/VbCAyc/CXzSqoKCKIAiCINoTpFS1Y2JS4BKTJzDi4IdYqtQ8FXFpe7E4U4OcZUGMKpjK4DUgdIIqa8Dpl/7Hu7rx7TN8aqps979kk77aXWV/pmuaNL9QWytV1r9+NVVyXCEEUsJyD6MKRfofe20YjuKpCjCbOk9VWNeldDv/7944uR9unNwPlbXOpMsJ0z+oCimCqpSBX7J8qzg3Q1ju5/7ntU1BqQrxQZWzvKmW6iz4C/n0m597IkEQBEEQbQsFVe0YYQ6phOkabPMErc/hkWO0mG2pnvqJuCpdzVOpyrFUAlbozytVjZL6VtvIB1zufajT/6x/31qxG5v3HxYCSV0TB8PtdTzql7Lpr2K5AzTbqEKhbMQ5S3WVysMrOnJqpoyYJpraqEK5DW61hGG6rklxf4qgKsVu2DF2zBVNI/zmqQo2+a9X+l/TLjB2fvzS+lTuiQRBEARBtA8oqGrH8DVF8qS5Lrzqc3yKVFxKle0a5yxLJ/0vtVKVTP/zqamq46yy41L6o1d72KLVe6qwek+V8Jmc/tfWaVNimqY6rc9dU6VWsdhyOc5SGlVwc3n5WarzaXE1XICrQqypErfnl8bGw09QnEiR/qcraqrk66F/aS42lh12tbGjpFRlS+5/QgAaZPJfPv0v3Pz0P9EZUQ0LqmiOKoIgCIJof9DPczuGV2pSqQZecxn5Ff7LqgCrYUo7/Y9LJ1ONR5ue/ucODv0s1VW40v/aS02V6a1AyWqUaKPuDrDkQIRdK4L6kuwCPsVOFWDyQV9tcqJcL/jBvTVPFadUBQwuBKVKMk5xratpLiVIPvdPXT4GY3oV4YVrjwfgBDmleZnCeq6aKm47XpeIl1LFpwKGmxjxnDWiK47rXYTpQzt5rkNKFUEQBEG0X0ipasfwSk2qoIoPkPiBacLnyb9bqWIKRuqn9gnF/nTNSgGT91mYnUz/C7vT/+SgqrbRGcgLQZXpbhvDb4yp65qU/tfWSpX1r4ngKZteSpVpfy7ug51XYeCfHOxvLDuMR5LOe6n6ojaFUqUJSpVoqR60togPQgzD9LVUZ/vICOv234McGPYvzcUbN02w3/9g6gCs21eN0T0LhfXkmipbBdK8zUy8aqpaombv+D4d8NqNE3zXsR0C22sOK0EQBEF8g6Ggqh0jpv/5D3C9DAz8Bqly8BNTTBrrZZNumNYAWNM0TkUSDTMYbOJflobXKNRUyUGVf/qfajyZytFPmKeqnQxI05n8l0dVeyUHYXGFpboqxkmleBxOpVRJQVVT0v/41eIp3f+sf6MhLqhKsZsrxvcGABw43CAsl5Uqtm2/QNPL/a84N4rrTuyFLVu2CEYfLY2tVLWTa5ggCIIgCAcKqtox6ShVXil/fnNbyZ+pJhf2GsDtqqjD2Bdn46LjeggqkjXYlJWqZFClMKpgjoOMOi+jCj/3P2ULLQ7Xx9uVUQWbWFm2VBdr1MTveCpVpnp9e56qFIpjqkw1XjVUIVqqa8K5CZr+p2lWMGYkLdV9Zg2wjycjrAPJGClogFGYJVqqu4wqAswTFRXmqRKP7+7TB2HmzE2B2tJUcqPW7Tong27bBEEQBNHeoF/ndkwsDaMKfiwatKbKK6gSlCqPQevyHRU4WNOIj9aUYVDnPAB+NVVy+p8TODUmRAVOMKrg0hNZvKdSmvwGwnWxhKAwtHU9imOprg6QgBTuf8JyD6VKkf7nZ0XvRcwvwoFb0WxK+h9gBSiNCSOlpbrOB1WKNvjuQ2oPby4BBDOBaGtr/p7F2bj/7CHoU5L7te+bIAiCIAh/KKhqx8TTMarwTCVLR6lyp9h5DVoP11sqRkVtI+fMp65vktP/ePc/plRFQhpiCVNI/0soa6rc2081vo1G2k/6n21UIehU/imbXp95GVWw64ZP3VSdx+YGmJp0nQjpf2lYi7O5pOIJ/5oqdu5aokZOvg7Ye7/tCTVVbXQdXX1inzbZL0EQBEEQ/pD7XzuGV2rk2iM3fKqcszSd9D8GP+D0GhyzeptDdTHHoluaqwgA+nbMsec+8jOqYBbXnul/vpbqKWqqQu3HqIKLqoRI2K+mSlSn3Mvl9YPWxjU3LpBrqoT0vzSUKtvu3Uw1T5X1L6+CpaMYRX1SEoOl/3GKZ1vnkRIEQRAE0a6goKod05pKlWGYKKtuUH7GDxe9Bo/VSaWqMW7Y6pKmiUHVWSO6YOZtk+wgzamp4tP/WFBlDVhrY5z7H29UwQVurvamo1S1dUzFz1PFLfdz/xPUKbjXk9Udv3mqeLxUu5MGlgAAhnbNV35uf19KE9WbmP7HrrFURhUhhVKVTozsG1Rx7n9eZLRx+h9BEARBEO0XSv9rx8TScP/jB+VCgOWhRv3k36vw8pIdys80YbCsHojWcCYG5TWNAKyBOz/UzMkII5OzrrbT/7gAkbWVDXgFpcpwqzdKpcrXqqJ9KQweQpUyrU/1Xp3+J67PlCpxnqrgtWi/+84ovLJ0B84d1U19EPb3xW3xm0sn/Y+10zBSz1MFND24iUZCQL3afMN2//PZXrQdpP8RBEEQBNE+oaCqHcMrNamNKoKlkjG+2l3luS1+vOhVd3O43h1U6VJNlTxAtdP/YgZ++8E6VNfH7baygbJQU8Udv+GjVKUa34rKRjsyqoD6PLlrqtSvPY0qVJbqKqXKoyuKcjJw4+R+nsfAkOep4oO0tNL/kg0JbFTBp/+lcT4zI81L/8toh9b8BEEQBEG0DyioaqfIT+3TS/9zXntN/utnl82PK0MpaqoA4GCNlUao65ow2JTH1UwxqqqP4dlPtwAARvYoFD4T5qniDsSZp6oJ6X+8stFOxsImgs9T5ZX+59RUqV0ceZVRpeg0NzDQpQCab0dTgqp4IlVQZf3b1PQ/v5REJ/0vmFLV5rV5BEEQBEG0K6imqp0Skyr2UwZV3Osgk//ywYtMEEv1ak6pqo85xghCPZY08GS1Tfu5Wi62Roai3kU9T5V/e1UIk7a2l/Q/11xU/GtvpUplbuGap0qh6imDqmYGBvJ1wqeaRtJJ/+ONKvzmqWK1eU1M/+telO35meP+5/19/hr1C/4IgiAIgvjmQUFVOyUuzRGUMv3PI5DycvirafBTqvwH417t0TVxoO2V/scbZNjpf4poiU9/NHyUqhQlVcqAra1gfWul/zn4zS3mnSbIlsnpf0ypcjpG1W3NtVQX3P80TVAW01KqkgFYwvC3VGd911RL9YfOG4bjehfhqcvHuNuQpvufn6smQRAEQRDfPCj9r53iDqr8jSp4VDU4pmkKwRI/ya6Mn9rkR0gXJ4B1KVXJQen+6np7GVOjoop6FzH9z/pXNehVLRvcOQ9r91Yn9+tsO9WEtq2Nl1GFoC5CbKNoo+5OBZTH9/GEOwBVBa3NFe3k+jn+GNIxcmDXSSKF+x8jo4kW+d2LsvHajROUn7EHAH7KF6++xSmoIgiCIAiCo/08wicE0k7/86rPMUws3VqO4x76EG99sdvell9wIatNQcetmuQAJw9QWXBz4HCjvSyRPE6V3TU/T5eT/pfacOGS43vgpRtOwIPnDsOs208Sth1POd9XK8Pl/5kec4v5u/85r9l5lh0e2bXDBzbFuVH87uJROG1IJ3tZ82uqxPQ/Xr1JxxCEtSNh+M9TxWgNa3MW2Pk1mz+mRJCGEgRBEATxjYGCqnZK2ul/HiliCdPEFf+3GAcON+DWl5YD8DepANxBSlDVwUr/495L3yvIiri+w57489br9meKyX+V81RJ+X/3zDgGRTkZuPyEXhjQKQ9hTtloa4VBaKtPIMzjaWJhq5DiPmylSuqrb43qhrNGdLHfN7umSudfa03uW3Z9JUzT01iFR0z/a9IuXbDtBO0T1fVKEARBEMQ3F0r/a6fEEukpVaLSIQ7C5VQ/P5MKwP20PqRrgdLmQtLkv3L6X8e8qOs7TN1gk//y8Pu0J/9VjHnlZX4pi3K/ft3YlurwNhdx11RxrxVGFUFqqhh8MNDcgEQ+115zogXdTqqaKkZGqOWNR4Kk/wHAvWcNwfq91Rjft7hF9ksQBEEQxNEBBVXtFPmpf2OKYMBzgK4Y6KZSquTULcuaO3Uwoknuf/KAt2Nuhus7TFXJirgvRSH9L3lMyoBJWuY3MJYVwK8b3v3Py5zC7f6nbrOXUUXMJ1WSD15b0lI9pGtoateG+PS/ANtoqlFFkDak2tx1E/u0yP4IgiAIgji6oPS/dopc+5O6pir1AD0nOaCuafBXquSBatCxtzX5r49SletWqljgpFKqBKOKNCb/9Rtot7VSxfCbp0qxsnI9b6MK6xhTBlXNDEhkl8im1hmFhaAqdVQ1oDTXfr3tYE2T9ikTxP2PIAiCIAjCCwqq2imyMpW6psqBH5jy5gHFyaAm3fS/cEB77JCuCXU28tcyIyHkRkVFirUvSxVUCZbqyW2qJv9FcKWqzd3/WPqfy1LdeS0HFoLjn2I9OWWOqXGq9D9eEWxRS3XJqCKt7aSpVJ03uhsmDywBABzXu0OT9unVhub2CUEQBEEQ30wo/a+dIqeppVKq+BE6P8bmlZkOOVb6XbpGFUEd1qzJf73nqQKA4twMHObmyIr71FSpjSpSt9evufE2dm1j/eNnqe5K/+Pr5bjlTvqfuA8WkKv6n+/n5sYPrvS/JnYtP/lvkJoqXdfw7NXH4eN1ZRjevaBpO3W1wfqXYiqCIAiCIJoCKVXtFHnwnzL9T7Dndl7zE+3mJ933alIoVXIKFK94ZPm4num6Jg60FSNUOQWQBU5KowpV+p9qnipdVEz87Lzbl1KlDqT8jCqE9D8vowrDR6lqwfQ/l1FFgIBIBQva44YZWO0K6RpOPaYTSvMym7RPGXYNUfofQRAEQRBNgYKqdoo8+E9pVCGoHs7rvZX13DrWB7UN/kqVDD/Q7JTvBEWaJk/E6k4Jk5HNKpiSlpXhFk35Gp2Ej/kCT6r0rRP6tky6WEsgnDMP90ZACpoUL+Vgxq+v+KCquaqdPPlvU9P/0jWqaA3YddtS814RBEEQBPHNgtL/2inputR5mVMcrHEm2mXbTFVT5VKqQs77zgWZ2HqwFgCQHQkhJxq21TBd08CXN6me+hdLSpVtqa5QwPjAkh2SUqkSJitWHhI+vfsUrNpZiWnc5LdtgdNUqW7KdB+r6r1KtfISiFQBJt/PDbHmBVWyUtXcoCpo+l9rELKVqjbZPUEQBEEQRzgUVLVTYmmqCF6pZDxsYtXm1FR1znfSrbIywijKzhCCqtRKlZT+x1SVkIaMkC4ocrxRBWu7KqjiF3kpVd0Ks9CtMEv52deJXVOVhqW6qUj5Y9tQrc8Ihdx9wZuOpDI/SQV/LsKh5gdV8UQw97/WgF03fqmjBEEQBEEQXlD6XztGVWfkRRB7bjboTVlTJQVDfG1OpwInqArpQEF2xPmeJgZkKqOEwqyIa5n1XQ3RiHg5qizVVYFaqn22J5o7+a+hUK28YplUqZD1Mf/rIBVCv2uaHfimC29U0WbpfwEn/yUIgiAIglBBQVU75eRBpfji3lNxevdgaoLXwJuHBSl1UlAljyPlYSWvSBRmOTVRh+vjKOKDKl10/1MN6vmJW+U2RMNiEBlPuBUalbu7sM8jZFBsKVXO+6CT/4r26mqjCkaqvmiuUiXOU4XmK1Ue81T984ZxmPejk5vWyMBtsP49Qi4fgiAIgiDaGRRUtXM0BByo+lhyMxKGgTlry/DpxgPCcnksLKdA8TVV/KCzpjEhBFm6pompeIqrK6JISWPfzXQpVe70P1V6VpD0v/YCa52Z/B8jcE2V4rVXHZLK/Y+npZWqe88aAgC49ZT+aW3HrqkyTMG5kjGhX0f06JDd9IYGQKf0P4IgCIIgmgHVVLVzgj45V81fJLOvqgHXPL8kwD7lyXR1z88Kc8T0P35Qqqp/mj60Mx787xpU14t1XZpmTQ7MwxtVsPIq5eS/glFF+x4Us7a6lSqfeao8Ai7DVqrU+2ptpUqXzvWoHoVY/+AZnmqk53bagftfcU40+W9GijUJgiAIgiDcBAqq7rjjjsAbfOyxx5rcGMJN0Afnoj23emRaWRdr0j55xUP+TFaq5AlhZQqzM7D4J1Mx4/fzsOVAjbNuCqXKCFhTdeQoVWIgzKfO+ZUmKY0qPM53yMsKMUlDvLlKlfu6SDegApzryyv97+tgfL9iPHX5GIzuWdgm+ycIgiAI4sgmUFC1fPly4f2yZcsQj8cxaNAgAMD69esRCoUwZsyYlm/hN5ygQ1QvJzmeVBMI2/uU3f+EwbOkVHE1VSE9tfsfYM2VJH+m6xoyPWqqyqrqufQ/VXuPoJoqrnleaX3+NVVwvfZWqtTLzxrRBe+s3IMbJvVN3V4fNG77zZk0lzeqaKOYCiFdw+nDOrfNzgmCIAiCOOIJFFTNmTPHfv3YY48hLy8PL7zwAoqKigAAFRUVuOaaazBp0qTWaeU3mKBjVT+jg/T3Kaf/iTVVV43vhRcWbMPkgSWCUYWmSRPC+jReVpR0DUr3v3dX7cFNLy7z/B7br72ddl4l6ExTFSzFT36vShP0qqnyUqr+cMlo/Pxbw9ChmaluKqWqKTiT/zb/2iUIgiAIgmgL0q6p+u1vf4sPPvjADqgAoKioCA8++CCmTZuGO++8s0Ub+E1HHqtmRnTUKyZtFWuqmhlUSe9FowoN98w4BuP6FuPE/h2xeneV/VlI1yRHOO+RtjwI1zSVUmXgR2+sFJaptinss72n/7GaKu7/gVTuf85rUyFVeSlVXkYVmqY1O6ACREWzOb3uBFUGBVUEQRAEQRyRpB1UVVVVYf/+/a7l+/fvR3V1dYs0inCQY4SsSEgdVAVI/wuK26hCVKoyIyHMGN4FAFAkGFVoLke4oPuw3P/cRhWyoYXKiEJL8Xl7wq6pSsOowvRI/3OMKtQnvLX7QjiHzQhmdU6pSjTPO4MgCIIgCKJNSDtZ6rzzzsM111yDf/3rX9i5cyd27tyJN954A9dddx2+/e1vt0Ybv9HIJygrknpC4OY+7ZezxkI+g2fRqEIMcPyUKnkf6vQ/9whbFajpR5BSxTCR2ipd/Zk7wPI636ks1ZuLmOrZ9O2wdiZMs9kqK0EQBEEQRFuQdlD11FNP4YwzzsCll16KXr16oVevXrj00ktx+umn48knn2yNNn6jkWMEWc1heE0k68XtUwd67xP+ShUPb1RhKVXihLBeBFGqahvd7nSpaqrau1EFa6tpivNUNSYMXP/CElTXx1znT5zPylnO1vOKQ5pjHhEEoaaqGQmAbDsJw7AnqCYIgiAIgjiSSCuoSiQSWLp0KR566CEcPHgQy5cvx/Lly1FeXo4nn3wSOTk5rdXObyxyjBD1Cqo8JpJVMbBTLm6bOsDzc5elulRTxZMZCSE3GrbbJs9d5IX8mabBVVMlp/4BaiOKoCmH7QEWfMhKFQDMXlOG5z/d6jp/Qk0Vt9xMkf7X2kpVaxhVBHWoJAiCIAiCaE+kVVMVCoUwbdo0rFmzBn369MGIESNaq11EEnf6nzoO9rPklgmnsMjzn/zXvf7PvzUU2w7WolthlpD/55v+J9u265or/U+F0qgCmu/n7Qm7a00xQGI0xN1mDanT/9T7CoVaO6hSv06XMGdU0UhFVQRBEARBHIGkbVQxbNgwbN68GX369GmN9hASsgKQlxlRrmekkf4XSTHY9p/81/3dbx/b3X4ddCJeZfpfOHW9mEqJEi3V23dQxaOKffMyw67zZ3iYkKRSqlq7vkxrqfS/5DmLJUxhEmSCIAiCIIgjhbRrqh588EHcddddeOedd7Bnzx5UVVUJ/xEti3yCzhrRBZeN64nj+3QQlpuCPbf/wJSpOX+9ciy6F2Xh/64aK+5TEfAwUg2dhfQ/X6XKPU9VZgClKrVRRcpNtCl2TRXEc8bIz4q4lnrZ5bOXXumerZ3+J9Cc9L9kp9Q2utM9CYIgCIIgjgTSVqpmzJgBADjnnHOEJ9WmaULTNCQSbnMBounIMUSn/Ew8dN5w/PLdtVi8pdxe7uceJxNOOkhMHdIJU4d0cg1m5bF4WDCqCK5ypT1PVQBnQ/U8VcH22R6wa6pMdf5fdkbIFSSltlRX7+vrVO2aU8vGzpnKmIQgCIIgCOJIIO2gas6cOa3RDsIDeaiaEbYCIj8VInVNlfjdiMumT6qp4o0qUohJTTWqsNz/gihVTd9ne0BUqtR41VRV1sWUwXNbGVXwNGdPLKiqjyXs95QGSBAEQRDEkUTaQdXkyZNbox2EB/K4mAVVsgqRzuS/YSmIkgffzVOqgplGyJ/pGhBtgZqq9q5UMazJf90nKmGYkKfnMkwTz3+6Bfe/vVrchv25eh9fZ1+0hPsfU6oyQjrqDFKtCIIgCII4ckg7qGLU1tZi+/btaGxsFJaTI2DLIg9WM0JqpSo99z/ZzlxDJKQhlrC+51dTlbK93Gs/owT5I13T7IDRD3X63xHk/pf811RWVCWDKpOdBytgMk3ggXdWu9ZlQZlXTdWRGlRFIzp+OH0Qfv7Oavzq/OEt0TyCIAiCIIhWJe2gav/+/bjmmmvw7rvvKj+nmqqWxSv9Tx4we5kZqFClhYV1HbHkuZNT/NJRqgSb7XQm/9W1QMGb2lLd//P2hDP5r7r2zTCdYCus62hMuC3WGanS/77OvmhWTVXyu3WcUnXtxD64cGx3T7dLgiAIgiCI9kTa7n8/+MEPcOjQISxatAhZWVl477338MILL2DAgAF46623WqON32hc6X8hj6CKV6pSTPXjrqESbdZle+yQz+S/MnpA1Uj+SNeC1QCpdi+6/7XzoIrrW7VS5QTFqerXbKMKj/Pd3gNMhq1UxSzDFDZfGQVUBEEQBEEcKaStVH300Ud48803MXbsWOi6jl69euG0005Dfn4+HnnkEZx55pmt0c5vLJ5KlRQ8iHMZicN1TRODLtVgm0+985unKtU4XahvStOowisICOsa4snCIdU2RXWsnQcSXPNUiqJhmnaNlDVJs2GnZcqY3HdUfK1GFS3g/scrVQRBEARBEEcSaY9eampqUFpaCgAoKirC/v37AQDDhw/HsmXLWrZ1HA899BAmTJiA7OxsFBYWKtfZvn07zjzzTGRnZ6O0tBQ//OEPEY8f2XPfyOPiiJdSxb2WjQuiYV0IdsKKyZzCnCwiBzx8IJNq8Mx/7hfgyNvRNO/1szir9ZSW6u1eqbLwcFRPBlVOTRUA7K2sU27LmadKva9QKqmrBWlO/MbOu11TFcCwhCAIgiAIoj2R9qhr0KBBWLduHQBg5MiR+Mtf/oJdu3bhqaeeQpcuXVq8gYzGxkZceOGFuOmmm5SfJxIJnHnmmWhsbMRnn32GF154Ac8//zzuu+++VmvT14F8grxqqviRtayAREK6oFqoFIxImA+cxM/4wXmqmEUPGODIYoSuaZ7KCh8EqoK6I8qoItlWE+qoyjKqsF6zY9lZoQ6qnHmqPGqqvsYAs1thVpO/y857XdJSPYhhCUEQBEEQRHsi7fS/2267DXv27AEA/OxnP8Ppp5+OF198ERkZGXj++edbun02DzzwAAB47uODDz7A6tWrMXv2bHTq1AmjRo3CL37xC/z4xz/G/fffj4yMjFZrW2sij4ujAYwq5EF2RkhHLOGkkcmW6gAQ8VGqwmnUVPE1Q/41Ve70v+N6d0Dfkhz0Kc7Bh2vL7G3w7U1lVNHe0/9EpUptqc4CZHasOypqfbfpPflvk5sZmBevH4ctB2owumdRk7fBgj922UYpqCIIgiAI4ggj7aDq8ssvt1+PGTMG27Ztw9q1a9GzZ0907NixRRuXDgsWLMDw4cPRqVMne9n06dNx00034auvvsLo0aOV32toaEBDQ4P9vqqqCgAQi8UQi8Vat9EpiMVibmXISCAWMwBTdCeIJxJ2exOSc0E4JNYr6TBdx8arRAa3LQDCvgwjkaJfuNquRNx7XSnwS8Tj0DI0vHvLBGgaMPC+WQCA7IyQ2LZ4HDFd/K7BzWmkme5ja0+wdFTTBAxFNBRPJOyJb1mw4aVUJRKGdZ16pbimPFfN5/heBTi+V0Hz9iNdy5GQ1q7PoQrW3iOt3YQ/dF6PPuicHp3QeT36aE/nNGgb0g6qNm/ejL59+9rvs7Ozceyxx6a7mRZn7969QkAFwH6/d+9ez+898sgjtgrG88EHHyA7O7tlG9kEdIjB0PvvWVb2X5VpAJzak40bN2Fm4wYAQFmZDj5xMNZQDzMOMJ1kx/ZtmDlzi7Cf2pqQ/fmiRYtQvtYZ8K/f7ezr86VLUb/J27J9315n3x/PmYPCqHq9vXvFNs6ePQvZwtVovdGNGGL1Mbttsz54H7KQ8WWF0749e3Zh5swdnu1ra8rqACCMWDyWVHzFg1m9eg0OVeoANDQ01APQ7Fojmf0HDmDmzJlYtVe8FhifzPkIuUeAgd6q/WL7Dx3cj5kzZ7Zdg5rBrFmz2roJRCtA5/Xog87p0Qmd16OP9nBOa2v9M4YYaQdV/fv3R/fu3TF58mRMmTIFkydPRv/+/dNuIADcfffd+NWvfuW7zpo1azB48OAmbT8I99xzD+644w77fVVVFXr06IFp06YhPz+/1fYbhFgsho1vOBdTNBLCjBnTAQANy3fjpU1f2p/169cPM04bAAB4pWwpUFluf5aXkwOzPobaWivSHtCvL2ZMHyjs69kdi7CzphIAMH78OBzfu4P9WdmCbXhzm1VHd/xxYzF5YIlnmz+oXonlB60gdurUU1Gap46qZh121gOA06dPQ27UuRxvW/ABAKA4PxcAcKChBgBwxhmnuyzhs9fvxzNrlwMAevbojhkzhnm2r63ZsLcSWLEIoVAYnToXA+VlwucDBg7C+i/3ATXVyM3OwqHGes9tdSguxowZx+Hgwu3AlrWuz0+fdhrys9p/VGWs3IO/b1xlv+/RtQtmzBjZhi1Kn1gshlmzZuG0005DJNL++5wIBp3Xow86p0cndF6PPtrTOWVZbKlIO6jasWMHPv74Y3zyySf49a9/jRtuuAFdu3bF5MmTcfLJJ+P6668PvK0777wTV199te86vCrmR+fOnbF48WJh2b59++zPvIhGo4hG3QP/SCTS5icREOuFMsIhu03RDOnUaTrXXvc8U3xdEr8dBu+4liEdezTi7CtVv+jcfqIZ3utGJIc3a1335ZibGUZj3EkPy8zIcNVNhcNc+0LuY2tPZLC2aY5pxbg+HbBoSzII1rj6sZTW4hoikQg0j+KprMwMZZ+2N6IZ4vnKzAi363PoR3u5bxAtC53Xow86p0cndF6PPtrDOQ26/7RHXN26dcNll12Gyy67DACwYcMGPPTQQ3jxxRfx8ssvpxVUlZSUoKTEW/VIh/Hjx+Ohhx5CWVmZbfk+a9Ys5OfnY8iQIS2yj7aAjx94hUY2euBND2SjirAuOuupjCoEhz3pM6EeK4UPBO886Oc+J3/kZYCRnRESjkdlRKEHtHFvF9hOFU5Z2TmjuqJ/aS5eXLQdnE9FSidDZ54q9efhr9FSvTnI556MKgiCIAiCONJIO6iqra3F/Pnz8fHHH+Pjjz/G8uXLMXjwYNxyyy2YMmVKKzTRYvv27SgvL8f27duRSCSwYsUKAFY6Ym5uLqZNm4YhQ4bgiiuuwK9//Wvs3bsXP/3pT3HzzTcrlagjBX64yQ82Xfbj3MBaHmTLE+sqLdW5QEu2LeeDo1Tuf/yu/QIceTtem83JCKMhbqg/tLflvD5i5qmC01caNLs/Etw8VamOhQWwqkmEga938t/mIAePZKlOEARBEMSRRtpBVWFhIYqKinDZZZfh7rvvxqRJk1BU1HQ75aDcd999eOGFF+z3zM1vzpw5mDJlCkKhEN555x3cdNNNGD9+PHJycnDVVVfh5z//eau3rTXhx5v8YFMOWPhhtTzIDodkpco/qJLH4vygN2XMwu3a31Jdfu+hVEXDqK73n8A5qI17e4AdpmmatiKlaU67DYMLqlIpVcnvq+ap0n0mU25vyMEfKVUEQRAEQRxppD16mTFjBhKJBF5++WW8/PLLeO2117B+/frWaJvA888/nxyIiv/x6livXr0wc+ZM1NbWYv/+/Xj00UeFepsjEaGmKuStVPGBlKxUhTRNGGCrlSrvCXbF1MBUSlWw9D/VPFU8103sg0hIww+mDlAGgeJ3vbfT3mD9Z3L/rwGCUhU0/W/ptgo8Pms94or8P1WKZ3tFDv5IqSIIgiAI4kgj7dHLf/7zHxw4cADvvfcexo8fjw8++ACTJk2ya62IlkWoqQp71w6ZQvqfOMgOyTVVilobf6XK+zMZftd+JT1y4CZv996zhuDLB6ajX0muy+3PvTG+rf6rthdMrnbKUqqs14YZXKkCgN99uAEvLtzuWh45QlQqAMjJkExLwm57eIIgCIIgiPZMk2Wc4cOHIx6Po7GxEfX19Xj//ffxyiuv4MUXX2zJ9n3j4WMPX6WKe+1SqnRNCIwiCuWHV4NktSeUhhGEEdCoQg5+5CALcAbXqvbyHElGFXb6H9Q1VVb6n7U8qOq265B7cuAjSakqkGzfSakiCIIgCOJII+3Ry2OPPYZzzjkHxcXFGDduHF566SUMHDgQb7zxBvbv398abfxGw58gfrApByy8QiTXVMlKVUghIWX4DMLTc/9Tf0+GDxhSKTKpXOz4bx8xRhXJ9FW2kAWDCcNJoWyO0USqQLQ94QqqjqCAkCAIgiAIAmiCUvXSSy9h8uTJ+O53v4tJkyahoKCgNdpFJOFjBD4NTg5EDKGmyh1UCTVVKY0qpJoqYV/B3f9U6pNqH6lih5Q1VXrwAK2t4fvEUaqcYNAwTRhJs8PmqG7tvR945AmKoxEKqgiCIAiCOLJIO6hasmRJa7SD8MDTUt0n0DAkB/KQriOsOwtVCoiQ/ieNaUOh4AGQl723DB9v+QVfQGrl4kgyquBxaqo0TqlyFKx0VbfC7AgO1cYAHDlzVAFAZiSEjLBuT/JMShVBEARBEEcaTRq9zJs3D5dffjnGjx+PXbt2AQD+/ve/Y/78+S3aOMLHUt2V/uejVGmicqGqt8kIqFSlnKcqWEzVokoVjkhLdVGpYs22jCqs1+kcSzSs4/qJfez3R1L6HyCmAEYjZFRBEARBEMSRRdpB1RtvvIHp06cjKysLy5cvR0NDAwCgsrISDz/8cIs38JuOt6W6eOrEearEbbjd//yVKvnTpk7+60c66lIq0wVh8t/2HlQl/zXhBMKaJqX/peH+BwCTBnTE7DsmIy/TCUyOJKMKQAyqSKkiCIIgCOJII+3Ry4MPPoinnnoKzzzzDCIRZyB04oknYtmyZS3aOEKyVOfVJOnMpbJUD6UIqvhty+l46Uz+q5qIVoWehvqVapCtpRH0tTWsrbyyqAlGFc5MX0GDqj9cMho9OmQL56Y5JhdtgahUUVBFEARBEMSRRdqjl3Xr1uGkk05yLS8oKMChQ4daok0Eh6BUhf2UKn+jCn6Arpr3yW+eKkHFSsP9zw8++Em1zVQBgqhUBdt/W2MpVdZrDc75SRhOwBU0qGLnjg8uU87t1c7Iz3TKO6NHWNsJgiAIgiDSHr107twZGzdudC2fP38++vbt2yKNIhy8aqrkcadoqS5+ZhlV+NcdRYTASVaqvOutZJqS/pfSUj2VUoUjSKlK/mvVVLnT/0y+pirgsdhBFbesvadBypBSRRAEQRDEkUzao5cbbrgBt912GxYtWgRN07B79268+OKLuOuuu3DTTTe1Rhu/0QhBlWCpLp46wy/9z2VUkcpSXfwsrZqqoOl/aWwzlenCkZT2xreV7yq2PNGEmirWP7qgVLXvfpARa6rIqIIgCIIgiCOLtC3V7777bhiGgVNPPRW1tbU46aSTEI1Gcdddd+H73///9u48Pqry7P/490zWCZCEJSFBIwaJLGIQCSKIgoAQ9KfFKr/aB1twoyBWiqAV+xNcHgxY5dG6ALYKWmlp9XnoooimKlioLKIoClKpID4KgmUJEMg25/cHZjJnlmSyztyTz/v1yqsz55yZ3DMX2HNx3fd1/7Q5xtiq+d4a+yZDgVUM3+l/zjMul+WYLhis3XZ8Ld3/Grr5b22c66Bqv3ZI90564q3A6mjNe9U8jvYKje/ofFuqx/msqfJ8F8Bw9qlKiLO836UzuTSr2kOlCgAAmKzeSZVlWfrFL36hO++8Uzt37tSxY8fUu3dvtW3bVidOnJDb7W6OcbZazoTBp1LlV4motVGFZdVZqUqspbJRrzVVYU4AjHOsqar9TQd266g/TLpQXTu2CXreUfWK8qTK9wv0/a6q4+Oxa46GU3ULVWGsuw19dEml+x8AADBYg+9eEhMT1bt3b11wwQVKSEjQggULlJubW/cLUS++AXKsiwrYpyr4Y+nUDXZ9uv/5JybO7n+136z7bzwcirOlet3XD+zWUVlpySHeq7YKXnQJWqlSzWfweGqOh7M+zNG10efdjWtU4ZtUxZs1dgAAgLDvXsrKyjRr1iwVFBRo8ODB+tOf/iRJWrJkiXJzc/Vf//Vfmj59enONs9UKNbXNf5pbbd3/XP6Vqjqn/znP1W+fqqZvqV4X35dHe6Uq2Joqy6r5DnzXVNW3UmXS2jJ/ju5/JFUAAMAwYU//mz17thYvXqyRI0fqH//4h8aNG6cbbrhB69ev14IFCzRu3DjFscC8yfneGvs2HwhIqurYpyq+HtP/LL/tf5tnTVXN48YmVY5OglFfqaoZX3WcTrVU/+6YpyapCidB9I2bs1GFWYlJckLNfzuoVAEAANOEnVS99NJLeuGFF3TVVVfp448/Vn5+viorK/Xhhx/WOSUMDedsPe7b/c+/UlXDv1FFOJv/xrtCV6ria0m4/DXHPlV1q71dfLTyJlUBlapT58P5KAnxwStVJn0PkuT2SaqS4vnHGQAAYJaw/0n4f//3f9W/f39JUp8+fZSUlKTp06eTUDWzUFO6UpPjNaJnpve5c01VYKMK39cG3fzXcXNe25qq2scb9vS/JkwAHOuzojyZ8P3+PD5rqmoaVcibIde/UUXt1cho1r5Novexae3gAQAAwk6qqqqqlJhYc+MTHx+vtm3bNsugUMM3QP4NI56dOECzxvSU5EykAipVcZYj2Qi6+W8tiVN9ptQ1pFLV+DVVpjaqCKxU1Xf6X6g1VQmGtVTPy2yrGy/K1Z2je/APNQAAwDhhT/+zbVsTJ05UUlKSJOnkyZOaPHmy2rRxtrn+n//5n6YdYSvnuFEO8i/41eed0/+cmU3v7FR9/NUR7/NgVQznuinn+frseeT/u0Npyul/zqpX496ruTkaVdQc9SZQVZ76NqoI3pnRtEqVZVmafWXvSA8DAACgQcJOqiZMmOB4fv311zf5YFC7YBWd6jVOjkrVd6Wqx687T4eOl+vK/C7avveo93zw7n+hm1H47olVV84UZqHKr6V6IytVCp0QRp8gjSqsmgqbY01VfStVIY4DAACgeYWdVC1ZsqQ5x4EwBKs+BKtUVSc+fU9P15mdTlUS6+r+56gcyb9SVfO8qo6sKuzpf/XoKFgXkxo0ONZUfben16k1VdXHfDYEDmufquAJpWkt1QEAAEwWdlKFyAtWYaqe8hWspbpjU9x6dP+z/H6N7/vUNb3Pv0lGKFYTrqlyJGhRnkz4jq6mUlWTxlb6JlWNWFMVZ9j0PwAAAJMxR8ggwZKh6iPBWqqHquDUPf0vdKWqrgpIQ6b/NbYxge+ro75Rhe+aKt/uf9+dqKwuXym8pCoxxKbNpjWqAAAAMBmVKoMEu8n2Tv9zdP8L7B5XV6Wqtg1+XS5LPxnaTSUnKtS1YxvVJtxGFXGOKlpYLwkpVEUu2gXbp6qyqr7T/3y/PHMbVQAAAJiMpMogvbukBhzzVqqCTv+rOVadSLms4FPkHO3ag2zwO2tMr7DGGJmW6sHfNxpZIRpVVMekoqqmUhVWo4r4EJUqGlUAAAC0GJIqA7wz8xIdK7d1evuUgHPVU+cOHCvTE29+pv87IKeme1yQCk58iJvtpmpsEG5S5Zv7NHr6n6GNKmqm/1k13f/qvaYqREv1KP8eAAAAYklYSdVf/vKXsN/wqquuavBgEFx2WrISEhKCnqu+j96466A27jqo/37/fx0VkGrepCrEzXbHtknex42ZOtaQfaoa3f1Pvslj496rufl+VNvnYPV34NuoIpzEKNSaqlDJMwAAAJpeWEnV2LFjw3ozy7JUVVXVmPGgnvxvu3f/u9T7OFiL7VA36m2T4vXq7UMU57JaZOqYbx+FRnf/M2j6n2+m601+VTPVz3dNVTifJVT3PypVAAAALSespMrj05EM0aW2qXPO6X+nbr5rq2Cc0yWt0eNp2Jqqxv1Oxx5bUZ5UhWqpXl1J9O3+F07F0JlU0agCAAAgEpgjZLjacohgjSqau4LRkOl/TbmmKtoLNKE2//V2//PUs1IV79tgxOc4LdUBAABaTIMaVRw/flxr1qzRnj17VF5e7jh3++23N8nAEJ5gnfq854I0qmjuqX23XNJNd738kUb26lzrdU26pso3Qavl+4g2tqOl+qljjpbqfm3uPUHyVeeaKipVAAAAkVDvpOqDDz7Q5ZdfrtLSUh0/flwdOnTQt99+q5SUFGVmZpJUtbBwK1XVN+jN3R1vXP/Tdf4Z7XVmx8BOhb6Cja2hnJ0EG/VWzc45/a/mcbDpf3GOxNMKWgUMuaaKRhUAAAAtpt53XtOnT9eVV16pQ4cOye12a/369friiy/Uv39/PfLII80xRtSithwieEv15s06LMtS98y2dd7UW34JQ2M4pxI26q2ane/ntlXdqMIKuvmv7z5Vofas8o2n7/eQEO3zIAEAAGJIvZOqLVu2aMaMGXK5XIqLi1NZWZlycnL08MMP65577mmOMaIWtVeqwu/+19JcjupSIytVjveNjs8XSrBKlWX5VqpqNm52fq7g7+c7/c/3EipVAAAALafed14JCQlyfbcIPjMzU3v27JEkpaWl6csvv2za0aFOta+pqnlcs09VdNxs+68XagxXE1a9mlvwzX8Dx21ZlqPtfFyIzxWy+1+UJM8AAACtQb3XVPXr10+bNm1SXl6ehg4dqtmzZ+vbb7/Vb3/7W/Xp06c5xohahFup6tAm0fG/kdaUiZBZ3f98pv/5ZFX+haVTlaq6v6PQa6qi/IsAAACIIfUuWzz00EPKzs6WJM2dO1ft27fXlClTdODAAS1evLjJB4ja1TZ1zrca1L9rez3xw36ae3V0JL5NmQiZ1KjCV83mv1bQSpXjOwrxJSWEWFMVLRVJAACA1qDelaqCggLv48zMTK1atapJB4T6qb1Rhc91lqUr+3Zp9vGEqyn3qXImJNGfVVmyZcsKuqaqmsvyb+YR/L0S44NXqhKoVAEAALSYev9z9vDhw3X48OGA4yUlJRo+fHhTjAn1UFs+0thkpTk5OhM24Tijffqfr5pKVeD0PpdlhdV2PsGxT1XNcRpVAAAAtJx633mtXr06YMNfSTp58qT+/ve/N8mgEL4ozptq5XJMbWvce/kmZVlpyY17sxbkXVJlWQHT+1yW5VhTFSpBdm7mTKMKAACASAh7+t9HH33kfbxt2zbt27fP+7yqqkqrVq3Saaed1rSjQ51q6/4XzXyTiEZP/3NZeu//jVSVx1ZKYr1ntLY4S5Itn0qVFVitO1W9qnkeqprn3Kcq+HEAAAA0r7DvQM8777zvFs9bQaf5ud1uPfHEE006ONTN3EpV07ZB79Q2qdHv0WK+y6oc0//8qnWWFdgS32XV7G1VLcEVqqU60/8AAABaSthJ1a5du2Tbtrp166aNGzcqIyPDey4xMVGZmZmKi4trlkEi9jim/xmaGDZU9ce1fRpVBKypclmOJKn6mupErFqo/b5oVAEAANBywk6qunbtKknyeDzNNhjUX7RvdhuK1cSVKhPV5EdWwPS+U2uqapyqVFVPHKzhmzz5voJGFQAAAC2nQQtQ/vWvf+mxxx7T9u3bJUm9e/fWtGnTdNZZZzXp4FA3U/MRZ7v3yI0jEqo/ru+aqsBGFYFTJF0uSVXO94pzOatZ1RJaW/kPAAAggur9z9mvv/66evfurY0bNyo/P1/5+fnasGGDzjnnHBUXFzfHGFELUxtVOKetmfkZGiogqVKwlulWwAbJwZpVhFo7RaUKAACg5dS7UnX33Xdr+vTpmjdvXsDxn//857rsssuabHCom/99tjshTicqqoJfHEWaa58qk3h8WqoHTv8LUqkK8j35JmO+661C7WsFAACAplfvf87evn27brrppoDjN954o7Zt29Ykg0L4/G+d09wJERlHfTmqMK2tqGIFPvXPl1yW5bguzmUFnSbpu6aqyqc1II0qAAAAWk69b2czMjK0ZcuWgONbtmxRZmZmU4wJ9eB/o52eYkZS5XJ0tmtdCUDARD8rsLLkX6myLCto9cl3mp9vUkVLdQAAgJYT9vS/Bx54QDNnztQtt9yiSZMm6fPPP9fgwYMlSevWrdP8+fN1xx13NNtAEYrzRjsrLVmf7jsaobGEzzm1LYIDiQJWkO5/VkD3v+Brz+JdVKoAAAAiLeyk6v7779fkyZN17733ql27dnr00Uc1a9YsSVKXLl1033336fbbb2+2gSI4/4Rk9DlZapMYr3NPT4vMgMLk3KeqdSUAwSpV/t3//PeucllW0IpeRruaTY99k6rWVv0DAACIpLCTKtvb/tnS9OnTNX36dB09eqoi0q5du+YZHerkf/Mc77L01PjzIzSa8Llacfe/UA0bXVZN84pTSZTvOcuRiH44e5Q8tq3khJoNt6v8NgYGAABAy6hX9z//G3iSqcjzvz83JUFxrheK4EAiINTHjXNZ8lSdSoxclgJbqvtkVWlB1s4l0EYdAAAgIuqVVJ199tl1Tis6ePBgowaE+gnoGmfIfbVv1aW1tVQPNv1Pqk40be9j31VVca7gLdV9XXBmB/2f/GzlZfKPHQAAAC2pXknV/fffr7S06F6r09oEbcVtAMd6oVbeqaI6efKtRJ1aU1Vzjf90wGBcLktP/kf0T/0EAACINfVKqq677jrapkcZy6/uYUqDAt9hGjLkZuOsVFUfczamCLX5LwAAACIv7MliptystzoBlarIDKO+/DvbtSahp//VHHP5VapOTf9r9qEBAACgAcJOqmw6i0Ul/4TElAQlztH9L4IDiQTL/2ng9D//6X7B2q4DAAAgOoQ9/c/j8TTnONBAAVWPiIyi/vzbhbcmoSpVzjVVzul/4TSqAAAAQGQY0isOofjfZ5syTdN//VBrVv3pnWuonMmX/z5VAAAAiB4kVYbzb1Rhyo23y2q90/9CVqr89u7yX3dGpQoAACA6kVQZztyW6jWPW9s+VYFzNOteU+WyzIktAABAa0NSZTj/22xTNv91THVrbaUqP97ufy7fY87KVJzLciRdAAAAiB6G3IIjJEPXVPlvdNuahGouElfLlEjWVAEAAEQvkirDmdpS3bknkxljbiqBa6pOHaltDZXLZRmTMAMAALQ2JFWGC5j+Z8h9d2tuVOGv+uO7/PbuClxT1bLjAgAAQHiMSarmzp2rwYMHKyUlRenp6UGvqd7bx/dn+fLlLTvQFuZfvfDvBhit2KfK53mw7n/yW1NF9z8AAICoZUxSVV5ernHjxmnKlCm1XrdkyRLt3bvX+zN27NiWGWCEBHb/i8w46qtV71Plvw7uuwMuv3VmjsTTZemy3p0lSZ3aJjb7EAEAABC++EgPIFz333+/JGnp0qW1Xpeenq6srKwWGFF0CLU+J9rV1pQh1oWqVPmvM3P5Tf+7aUiuTm+fogG57Zt9jAAAAAifMUlVuKZOnaqbb75Z3bp10+TJk3XDDTfUmmiUlZWprKzM+7ykpESSVFFRoYqKimYfb22qf39t46iqqnI893gqIz7ucNi27fPEY8SYm0Kwz1lZeSpmvkmUJVuVlVWO57anSqN6dQr5PoiccP6uwjzENfYQ09hEXGNPNMU03DHEVFL1wAMPaPjw4UpJSdEbb7yhW2+9VceOHdPtt98e8jVFRUXeKpivN954QykpKc053LAVFxeHPLfrqOQbxg3r1+vbbc0/pqZgKU62LG375BOt/PfHkR5OC4pzPHv77bfVMVkqORKn6jrWv//9rf7+zhpVx/bLL7/UypVftPA4UV+1/V2FuYhr7CGmsYm4xp5oiGlpaWlY10U0qbr77rs1f/78Wq/Zvn27evbsGdb73Xvvvd7H/fr10/Hjx/XLX/6y1qRq1qxZuuOOO7zPS0pKlJOTo1GjRik1NTWs39tcKioqVFxcrMsuu0wJCQlBr/ngy8N67OON3ucXDR6s889Ib6ERNs4dG4pV5bF17rl9dPmAnEgPp0VUVFTovs1vOY4NH36pTkt36/mvNuqLY4clSRkZGRo2rKfmblknScrt2lWXX96rpYeLMIXzdxXmIa6xh5jGJuIae6IpptWz2OoS0aRqxowZmjhxYq3XdOvWrcHvP3DgQD344IMqKytTUlJS0GuSkpKCnktISIh4EKvVNpZEv+MJCfFRM+66uCypSlJCvDljbgr+s1Gr4+u7IXKcy+WIbXycq1V9R6aKpv9uoOkQ19hDTGMTcY090RDTcH9/RJOqjIwMZWRkNNv7b9myRe3btw+ZUMWCgKYHERlFw5xa62a3ukYV/rz7VPk17/Btj+9q7V8SAABAFDNmTdWePXt08OBB7dmzR1VVVdqyZYskqXv37mrbtq3++te/6ptvvtGFF16o5ORkFRcX66GHHtLMmTMjO/BmFthS3Zyb7+oOgKZ0LGwqIfepcmz+a7XqvbwAAABMYkxSNXv2bD3//PPe5/369ZN0apH/sGHDlJCQoKeeekrTp0+Xbdvq3r27FixYoFtuuSVSQ24R/pv9mnTzXZ1DmDTm5lAdwzjHPlXOpCqOShUAAEDUMiapWrp0aa17VBUWFqqwsLDlBhQl/PMRk/KT6mQqzpgtqJtGqEqV5dgQ2X+D5BYYGAAAABqkld3Oxj6Tqj5Wa61U+SfC3/1vnN9mv45KVWv7jgAAAAxCUmW4gDVVBkW0uvlCa1tTFSDEmirfZJPpfwAAANHLoFtwBONf5TGp6lM91taWLwR2bKz+HvwaVfheY1BcAQAAWhuSKsMFdv+LzDgaoiapMmjQTSDUmir/NVS+iRTT/wAAAKIXSZXh/Lv/mbRTVU33v8iOI9K8a6pq6f7X2r8jAACAaEZSZbhYqFS1tqltgR0bv6vY+QSvc7sk53RAkwILAADQypBUGc7/VtukqXTsU3VK9af3zZuG9sgwqOYIAADQupFUGS6wUmXOrXh1hYZ9qk797459R73HLsjtwD5VAAAAhmhlt7OxyHm3bdLNdxwt1SXVrIv71CepSoqPc4Q2cO0cAAAAogVJleH8l9qYtPaG6X/f+e7j33N5T0nS/GvOleSMbWv/igAAAKJZfKQHgMbxr/IYlFOxT1X18+8O3HJxN4097zRltEv67rgV8jUAAACIHiRVhjO5UUWw/ZlaBf/uf9X/a1nKTE32HqdSBQAAYAam/xkuoD13ZIbRICmJp3J6d2JchEfSsgIrVcGj5ruOijVVAAAA0YtKleH8b7ZNavpw7//prU27D+q809MjPZQWFW6ELCpVAAAARiCpMpzJm/9ekNtBF+R2iPQwIi5UyEikAAAAzMD0vxjT6tYnGShgymaIkDn3qSKuAAAA0YqkynAmb/6LU0Ktl7JCPAYAAEB0IakynH8SZRFR44RXqWqhwQAAAKDeuAU3HJUq8zSoUUWzjAQAAABNgaTKcP5Tx0xqVIFTQuXBFmuqAAAAjEBSZbjAfaq4+Y52AftUhREzcioAAIDoRVJluMCNZCMyDNRDuN3/HNc0z1AAAADQBEiqTMeaKuOFFTHiCgAAELVIqgzHmirzBFYXw5j+1zxDAQAAQBMgqTKcfxJFpco84USMsAIAAEQvkirD+Vc5uPk2T3hrqggsAABAtCKpMlxDppIhsgIbVdQdM6Z1AgAARC+SKsORQ7UOxBkAACB6kVQZjmlh5vGNWLjJEnEGAACIXiRVpuNe2zhWiMdhvwgAAABRhaTKcEwLM1u4a+AIMwAAQPQiqTKcbwt1Eiwz+MYp3JDRgAQAACB6kVQZrkFTyRBhtvdR+GuqAAAAEK1IqgznqHpQzYhZhBYAACB6kVQZzrcrHPfdZnBWF8NcU0VwAQAAohZJleGclarIjQMNFGbMCrp2aN5xAAAAoMHiIz0AoLWpT6OKLbMv06HSCuV0SGnWMQEAAKDhSKoMR3XKbHXFLz0lUekpiS0zGAAAADQI0/8M52ipzqoqIzRkTRUAAACiF0mV4ayQTxCtHEkVMQMAADAeSZXhLIvufyYjZgAAAOYjqTIcVQ+zsbcYAACA+UiqDOfsJMcNugnq0/0PAAAA0Y+kynCO6X/coZuHmAEAABiPpApoYVaIxwAAADATSRUQQaypAgAAMB9JVQzh9twMjjVVBA0AAMB4JFUxhKqHGZj+BwAAEFtIqmIIN+jmIREGAAAwH0lVLOH+3DiEDAAAwHwkVTGEG3QzsGEzAABAbCGpAiKKrAoAAMB0JFVAC6M6BQAAEFtIqmIITQ/MQ8gAAADMR1IVQ7hBNwMt1QEAAGILSVUM4QbdDDSqAAAAiC0kVTGE6X/msUiFAQAAjEdSFUO4PTeET6DIgwEAAMxHUhVDuEE3A2uqAAAAYgtJFRBBTNkEAAAwH0kV0MJIowAAAGILSVVM4XbdNBSqAAAAzEdSFUO4QTeDRaMKAACAmEJSFUO4PzcPLdUBAADMR1IVQ6h6mIeYAQAAmI+kKoZQ9TADLdUBAABiC0lVDKHqYQZHUkXQAAAAjGdEUrV7927ddNNNys3Nldvt1llnnaU5c+aovLzccd1HH32kiy++WMnJycrJydHDDz8coREDtbCCPgQAAICh4iM9gHB8+umn8ng8Wrx4sbp3766PP/5Yt9xyi44fP65HHnlEklRSUqJRo0Zp5MiRWrRokbZu3aobb7xR6enpmjRpUoQ/AVDDCvkEAAAAJjIiqSosLFRhYaH3ebdu3bRjxw4tXLjQm1QtW7ZM5eXleu6555SYmKhzzjlHW7Zs0YIFC1pNUsX9uXmIGQAAgPmMSKqCOXLkiDp06OB9/u677+qSSy5RYmKi99jo0aM1f/58HTp0SO3btw/6PmVlZSorK/M+LykpkSRVVFSooqKimUYfnurfX59xRHrMqF1FRUVAIkXMzNeQv6uIfsQ19hDT2ERcY080xTTcMRiZVO3cuVNPPPGEt0olSfv27VNubq7jus6dO3vPhUqqioqKdP/99wccf+ONN5SSktKEo2644uLiOq44FcaTJ09o5cqVzT8gNFLNUsbjx44RsxhS999VmIi4xh5iGpuIa+yJhpiWlpaGdV1Ek6q7775b8+fPr/Wa7du3q2fPnt7nX331lQoLCzVu3DjdcsstjR7DrFmzdMcdd3ifl5SUKCcnR6NGjVJqamqj378xKioqVFxcrMsuu0wJCQkhr5v27huSpBS3W5dffklLDQ8NUFFRod/tfNP7vG3btrr88osiOCI0hXD/rsIsxDX2ENPYRFxjTzTFtHoWW10imlTNmDFDEydOrPWabt26eR9//fXXuvTSSzV48GA988wzjuuysrL0zTffOI5VP8/Kygr5/klJSUpKSgo4npCQEPEgVgt3LJbLipoxIzTfLuouYhZToum/G2g6xDX2ENPYRFxjTzTENNzfH9GkKiMjQxkZGWFd+9VXX+nSSy9V//79tWTJErlczm7wgwYN0i9+8QtVVFR4P3xxcbF69OgRcupfrGHzXzM4N/8lZgAAAKYzYp+qr776SsOGDdMZZ5yhRx55RAcOHNC+ffu0b98+7zX/8R//ocTERN1000365JNP9Ic//EGPP/64Y2ofEG3Y+xcAAMB8RjSqKC4u1s6dO7Vz506dfvrpjnO2bUuS0tLS9MYbb2jq1Knq37+/OnXqpNmzZ7eaduowB3kUAABAbDEiqZo4cWKda68kKT8/X3//+9+bf0BRiqqHIXziZBE0AAAA4xkx/Q/h4fbcDFaIxwAAADATSVUMoephHkIGAABgPpKqGML9uXlIqgAAAMxHUhVLuEE3Ai3VAQAAYgtJFdDCHEkVORUAAIDxSKpiCPfnhrCCPgQAAIChSKqAFuZIpChVAQAAGI+kKobQ/c88RAwAAMB8JFUxhBt0M7CmCgAAILaQVMUQbtANwZoqAACAmEJSFUNoz20epmwCAACYj6QqhnB/bgbfMLkT4iI2DgAAADQNkiogglLd8ZEeAgAAABqJpApoYb6VqtTkhIiNAwAAAE2DpApoYb5JVZqbpAoAAMB0JFUxhKYHhvAJUypJFQAAgPFIqmIIKZUZnNP/WFMFAABgOu7oYgiFKvNQqQIA4BTbtlVZWamqqqp6va6iokLx8fE6efJkvV+L6NSSMY2Li1N8fHyjZ3yRVMUQkirz0KgCAACpvLxce/fuVWlpab1fa9u2srKy9OWXX7IUIka0dExTUlKUnZ2txMTEBr8HSRXQwhzT/2ipDgBo5Twej3bt2qW4uDh16dJFiYmJ9bqR9ng8OnbsmNq2bSuXi5UtsaClYmrbtsrLy3XgwAHt2rVLeXl5Df593NHFEItVVWbwCRPd/wAArV15ebk8Ho9ycnKUkpJS79d7PB6Vl5crOTmZpCpGtGRM3W63EhIS9MUXX3h/Z0PwJw+IIKb/AQBwCgkRIqUp/uzxpzeGMI3YDOU+6y1pVAEAAGA+kqoYQk5lhpM+SVVSPH8FAQAATMcdXSyhVGWEE5U1j+lSBABA67V7925ZlqUtW7Y02++YOHGixo4d22zvb4IzzzxTjz32WLP+DpKqGMLtuRlOsIUGAADGmzhxoizLCvgpLCwM+z1ycnK0d+9e9enTpxlH2njDhg3zfr7k5GSdffbZKioqkm3bkR5a1KD7Xwyh6GGGE5UECgCAWFBYWKglS5Y4jiUlJYX9+ri4OGVlZTX1sJrFLbfcogceeEBlZWV66623NGnSJKWnp2vKlCmRHpokqaqqSpZlRazhCZUqoIWdpFIFAEBItm2rtLyyXj8nyqvq/ZpgP/WtvCQlJSkrK8vx0759e+95y7K0cOFCjRkzRm63W926ddPLL7/sPe8//e/QoUMaP368MjIy5Ha7lZeX50jatm7dquHDh8vtdqtjx46aNGmSjh075j1fVVWlO+64Q+np6erYsaPuuuuugM/k8XhUVFSk3Nxcud1u9e3b1zGmUFJSUpSVlaWuXbvqhhtuUH5+voqLi73ny8rKNHPmTJ122mlq06aNBg4cqNWrV3tjmpGR4fg95513nrKzs73P165dq6SkJO8G0E899ZT69u2rNm3aKCcnR7feeqvjsy5dulTp6en6y1/+ot69eyspKUl79uzR/v37deWVV8rtdis3N1fLli2r87M1BSpVMYT6hxmY/gcAQGgnKqrUe/brEfnd2x4YrZTEpr09vvfeezVv3jw9/vjj+u1vf6vrrrtOW7duVa9evYJeu23bNr322mvq1KmTdu7cqRMnTkiSjh8/rtGjR2vQoEHatGmT9u/fr5tvvlm33Xabli5dKkl69NFHtXTpUj333HPq1auXHn30Ua1YsULDhw/3/o6ioiK9+OKLWrRokfLy8vTOO+/o+uuvV0ZGhoYOHVrn57FtW2vXrtWnn36qvLw87/HbbrtN27Zt0/Lly9WlSxetWLFChYWF2rp1q/Ly8nTJJZdo9erVuvbaa3Xo0CFt375dbrdbn376qXr27Kk1a9ZowIABSklJkcfjkcvl0mOPPaazzjpLn3/+uW699Vbdddddevrpp72/s7S0VPPnz9dvfvMbdezYUZmZmbr22mv19ddf6+2331ZCQoJuv/127d+/v6HhCxtJFdDCeqTZ+uDfls7sWP8NDgEAQPR45ZVX1LZtW8exe+65R/fcc4/3+bhx43TzzTdLkh588EEVFxfriSeecCQH1fbs2aN+/fqpoKBA0qkGC9V+97vf6eTJk3rhhRfUpk0bSdKTTz6pK6+8UvPnz1fnzp312GOPadasWfr+978vSVq0aJFef70mQS0rK9NDDz2kv/3tbxo0aJAkqVu3blq7dq0WL15ca1L19NNP6ze/+Y3Ky8tVUVGh5ORk3X777d5xL1myRHv27FGXLl0kSTNnztSqVau0ZMkSPfTQQxo2bJgWL14sSXrnnXfUr18/ZWVlafXq1erZs6dWr17t+P1TpkxRamqqXC6XzjzzTP3nf/6nJk+e7PjeKioq9PTTT6tv376SpH/+85967bXXtHHjRg0YMECS9OyzzwZNYJsaSVUMoZOcGcblejSqoKeuPj8n0kMBACDquBPitO2B0WFf7/F4dLTkqNqltmv0ehp3Qly9rr/00ku1cOFCx7EOHTo4nlcnL77PQ3X7mzJliq655hq9//77GjVqlMaOHavBgwdLkrZv3+6dDlftoosuksfj0Y4dO5ScnKy9e/dq4MCB3vPx8fEqKCjwTgHcuXOnSktLddlllzl+b3l5ufr161frZx0/frx+8Ytf6NChQ5ozZ44GDx7sHdvWrVtVVVWls88+2/GasrIydezYUZI0dOhQTZs2TQcOHNCaNWs0bNgwb1J100036R//+Ifuuusu72tXr16tJ554Qp9++qlKSkpUWVmpkydPqrS0VCkpp/5hOjExUfn5+d7XbN++XfHx8erfv7/3WM+ePZWenl7rZ2sKJFUxhJTKDG0SpHFDzlRCAhv/AgDgz7Ksek3B83g8qkyMU0pifIs3KWjTpo26d+/eZO83ZswYffHFF1q5cqWKi4s1YsQITZ06VY888kiTvH/1mqRXX31Vp512muNcXQ020tLSvJ/1j3/8o7p3764LL7xQI0eO1LFjxxQXF6fNmzcrLs6ZmFZX8s4991x16NBBa9as0Zo1azR37lxlZWVp/vz52rRpkyoqKrxJ2u7du3Xddddp8uTJmjt3rjp06KC1a9fqpptuUnl5uTepcrvdUVNUoFFFDLg4r5MkacLgMyM7EAAAADisX78+4Hlt09EyMjI0YcIEvfjii3rsscf0zDPPSJJ69eqlDz/8UMePH/deu27dOrlcLvXo0UNpaWnKzs7Whg0bvOcrKyu1efNm73Pfhg7du3d3/OTkhD+Dpm3btpo2bZpmzpwp27bVr18/VVVVaf/+/QHvW93d0LIsXXzxxfrzn/+sTz75REOGDFF+fr7Kysq0ePFiFRQUeKtwmzdvlsfj0SOPPKILL7xQZ599tr7++us6x9WzZ8+Az7xjxw4dPnw47M/WUFSqYsBzEwdoz8FSnZXRtu6LAQAA0CTKysq0b98+x7H4+Hh16tTJ+/yll15SQUGBhgwZomXLlmnjxo169tlng77f7Nmz1b9/f51zzjkqKyvTK6+84k3Axo8frzlz5mjChAm67777dODAAf30pz/Vj370I3Xu3FmSNG3aNM2bN095eXnq2bOnFixY4Ego2rVrp5kzZ2r69OnyeDwaMmSIjhw5onXr1ik1NVUTJkwI+7P/5Cc/0YMPPqj//u//1rXXXqvx48frxz/+sR599FH169dPBw4c0Jtvvqn8/HxdccUVkk7tdzVjxgwVFBR4K1iXXHKJli1bpjvvvNP73t27d1dFRYWefPJJXXXVVVq3bp0WLVpU55h69OihwsJC/eQnP9HChQsVHx+vn/3sZ3K73WF/roaiUhUDEuJcJFQAAAAtbNWqVcrOznb8DBkyxHHN/fffr+XLlys/P18vvPCCfv/736t3795B3y8xMVGzZs1Sfn6+LrnkEsXFxWn58uWSTrU0f/3113Xw4EENGDBA1157rUaMGKEnn3zS+/oZM2boRz/6kSZMmKBBgwapXbt2uvrqqx2/48EHH9S9996roqIi9erVS4WFhXr11VeVm5tbr8/eoUMH/fjHP9Z9990nj8ejJUuW6Mc//rFmzJihHj16aOzYsdq0aZPOOOMM72uGDh2qqqoqDRs2zHts2LBhAcf69u2ruXPn6uGHH1afPn20bNkyFRUVhTWuJUuWqEuXLho6dKi+//3va9KkScrMzKzXZ2sIy2YrZIeSkhKlpaXpyJEjSk1NjehYKioqtHLlSl1++eWsv4kRxDQ2EdfYRFxjDzGNTidPntSuXbuUm5ur5OTker/e4/GopKTE2ykumliWpRUrVmjs2LGRHopRWjqmtf0ZDDc3iK4/eQAAAABgGJIqAAAAAGgEGlUAAAAAzYBVNq0HlSoAAAAAaASSKgAAAEQcVR1ESlP82SOpAgAAQMRUd2IsLS2N8EjQWlX/2WtMV1DWVAEAACBi4uLilJ6erv3790s6tR+TZVlhv97j8ai8vFwnT56MupbqaJiWiqlt2yotLdX+/fuVnp6uuLi4Br8XSRUAAAAiKisrS5K8iVV92LatEydOyO121ysZQ/Rq6Zimp6d7/ww2FEkVAAAAIsqyLGVnZyszM1MVFRX1em1FRYXeeecdXXLJJWzqHCNaMqYJCQmNqlBVI6kCAABAVIiLi6v3DW5cXJwqKyuVnJxMUhUjTIwpE08BAAAAoBFIqgAAAACgEUiqAAAAAKARWFPlp3rzr5KSkgiP5NQivdLSUpWUlBgznxS1I6axibjGJuIae4hpbCKusSeaYlqdE9S1QTBJlZ+jR49KknJyciI8EgAAAADR4OjRo0pLSwt53rLrSrtaGY/Ho6+//lrt2rWL+F4HJSUlysnJ0ZdffqnU1NSIjgVNg5jGJuIam4hr7CGmsYm4xp5oiqlt2zp69Ki6dOlS60bEVKr8uFwunX766ZEehkNqamrE/0ChaRHT2ERcYxNxjT3ENDYR19gTLTGtrUJVjUYVAAAAANAIJFUAAAAA0AgkVVEsKSlJc+bMUVJSUqSHgiZCTGMTcY1NxDX2ENPYRFxjj4kxpVEFAAAAADQClSoAAAAAaASSKgAAAABoBJIqAAAAAGgEkioAAAAAaASSqij11FNP6cwzz1RycrIGDhyojRs3RnpIqMU777yjK6+8Ul26dJFlWfrTn/7kOG/btmbPnq3s7Gy53W6NHDlSn332meOagwcPavz48UpNTVV6erpuuukmHTt2rAU/BXwVFRVpwIABateunTIzMzV27Fjt2LHDcc3Jkyc1depUdezYUW3bttU111yjb775xnHNnj17dMUVVyglJUWZmZm68847VVlZ2ZIfBT4WLlyo/Px874aSgwYN0muvveY9T0zNN2/ePFmWpZ/97GfeY8TVPPfdd58sy3L89OzZ03uemJrpq6++0vXXX6+OHTvK7Xbr3HPP1Xvvvec9b/L9EklVFPrDH/6gO+64Q3PmzNH777+vvn37avTo0dq/f3+kh4YQjh8/rr59++qpp54Kev7hhx/Wr371Ky1atEgbNmxQmzZtNHr0aJ08edJ7zfjx4/XJJ5+ouLhYr7zyit555x1NmjSppT4C/KxZs0ZTp07V+vXrVVxcrIqKCo0aNUrHjx/3XjN9+nT99a9/1UsvvaQ1a9bo66+/1ve//33v+aqqKl1xxRUqLy/XP/7xDz3//PNaunSpZs+eHYmPBEmnn3665s2bp82bN+u9997T8OHD9b3vfU+ffPKJJGJquk2bNmnx4sXKz893HCeuZjrnnHO0d+9e78/atWu954ipeQ4dOqSLLrpICQkJeu2117Rt2zY9+uijat++vfcao++XbESdCy64wJ46dar3eVVVld2lSxe7qKgogqNCuCTZK1as8D73eDx2VlaW/ctf/tJ77PDhw3ZSUpL9+9//3rZt2962bZstyd60aZP3mtdee822LMv+6quvWmzsCG3//v22JHvNmjW2bZ+KYUJCgv3SSy95r9m+fbstyX733Xdt27btlStX2i6Xy963b5/3moULF9qpqal2WVlZy34AhNS+fXv7N7/5DTE13NGjR+28vDy7uLjYHjp0qD1t2jTbtvm7aqo5c+bYffv2DXqOmJrp5z//uT1kyJCQ502/X6JSFWXKy8u1efNmjRw50nvM5XJp5MiRevfddyM4MjTUrl27tG/fPkdM09LSNHDgQG9M3333XaWnp6ugoMB7zciRI+VyubRhw4YWHzMCHTlyRJLUoUMHSdLmzZtVUVHhiGvPnj11xhlnOOJ67rnnqnPnzt5rRo8erZKSEm9lBJFTVVWl5cuX6/jx4xo0aBAxNdzUqVN1xRVXOOIn8XfVZJ999pm6dOmibt26afz48dqzZ48kYmqqv/zlLyooKNC4ceOUmZmpfv366de//rX3vOn3SyRVUebbb79VVVWV4z8CktS5c2ft27cvQqNCY1THrbaY7tu3T5mZmY7z8fHx6tChA3GPAh6PRz/72c900UUXqU+fPpJOxSwxMVHp6emOa/3jGizu1ecQGVu3blXbtm2VlJSkyZMna8WKFerduzcxNdjy5cv1/vvvq6ioKOAccTXTwIEDtXTpUq1atUoLFy7Url27dPHFF+vo0aPE1FCff/65Fi5cqLy8PL3++uuaMmWKbr/9dj3//POSzL9fio/obwcAA0ydOlUff/yxYz4/zNWjRw9t2bJFR44c0csvv6wJEyZozZo1kR4WGujLL7/UtGnTVFxcrOTk5EgPB01kzJgx3sf5+fkaOHCgunbtqj/+8Y9yu90RHBkayuPxqKCgQA899JAkqV+/fvr444+1aNEiTZgwIcKjazwqVVGmU6dOiouLC+hg88033ygrKytCo0JjVMettphmZWUFNCKprKzUwYMHiXuE3XbbbXrllVf09ttv6/TTT/cez8rKUnl5uQ4fPuy43j+uweJefQ6RkZiYqO7du6t///4qKipS37599fjjjxNTQ23evFn79+/X+eefr/j4eMXHx2vNmjX61a9+pfj4eHXu3Jm4xoD09HSdffbZ2rlzJ39XDZWdna3evXs7jvXq1cs7rdP0+yWSqiiTmJio/v3768033/Qe83g8evPNNzVo0KAIjgwNlZubq6ysLEdMS0pKtGHDBm9MBw0apMOHD2vz5s3ea9566y15PB4NHDiwxceMU21db7vtNq1YsUJvvfWWcnNzHef79++vhIQER1x37NihPXv2OOK6detWx/8BFBcXKzU1NeD/WBA5Ho9HZWVlxNRQI0aM0NatW7VlyxbvT0FBgcaPH+99TFzNd+zYMf3rX/9SdnY2f1cNddFFFwVsTfLPf/5TXbt2lRQD90sRbZOBoJYvX24nJSXZS5cutbdt22ZPmjTJTk9Pd3SwQXQ5evSo/cEHH9gffPCBLclesGCB/cEHH9hffPGFbdu2PW/ePDs9Pd3+85//bH/00Uf29773PTs3N9c+ceKE9z0KCwvtfv362Rs2bLDXrl1r5+Xl2T/84Q8j9ZFavSlTpthpaWn26tWr7b1793p/SktLvddMnjzZPuOMM+y33nrLfu+99+xBgwbZgwYN8p6vrKy0+/TpY48aNcresmWLvWrVKjsjI8OeNWtWJD4SbNu+++677TVr1ti7du2yP/roI/vuu++2Lcuy33jjDdu2iWms8O3+Z9vE1UQzZsywV69ebe/atctet26dPXLkSLtTp072/v37bdsmpibauHGjHR8fb8+dO9f+7LPP7GXLltkpKSn2iy++6L3G5Pslkqoo9cQTT9hnnHGGnZiYaF9wwQX2+vXrIz0k1OLtt9+2JQX8TJgwwbbtU21C7733Xrtz5852UlKSPWLECHvHjh2O9/j3v/9t//CHP7Tbtm1rp6am2jfccIN99OjRCHwa2LYdNJ6S7CVLlnivOXHihH3rrbfa7du3t1NSUuyrr77a3rt3r+N9du/ebY8ZM8Z2u912p06d7BkzZtgVFRUt/GlQ7cYbb7S7du1qJyYm2hkZGfaIESO8CZVtE9NY4Z9UEVfz/OAHP7Czs7PtxMRE+7TTTrN/8IMf2Dt37vSeJ6Zm+utf/2r36dPHTkpKsnv27Gk/88wzjvMm3y9Ztm3bkamRAQAAAID5WFMFAAAAAI1AUgUAAAAAjUBSBQAAAACNQFIFAAAAAI1AUgUAAAAAjUBSBQAAAACNQFIFAAAAAI1AUgUAAAAAjUBSBQBoVXbv3i3LsrRly5Zm+x0TJ07U2LFjm+39AQDRhaQKAGCUiRMnyrKsgJ/CwsKwXp+Tk6O9e/eqT58+zTxSAEBrER/pAQAAUF+FhYVasmSJ41hSUlJYr42Li1NWVlZzDAsA0EpRqQIAGCcpKUlZWVmOn/bt20uSLMvSwoULNWbMGLndbnXr1k0vv/yy97X+0/8OHTqk8ePHKyMjQ263W3l5eY6EbevWrRo+fLjcbrc6duyoSZMm6dixY97zVVVVuuOOO5Senq6OHTvqrrvukm3bjvF6PB4VFRUpNzdXbrdbffv2dYwJAGA2kioAQMy59957dc011+jDDz/U+PHjdd1112n79u0hr922bZtee+01bd++XQsXLlSnTp0kScePH9fo0aPVvn17bdq0SS+99JL+9re/6bbbbvO+/tFHH9XSpUv13HPPae3atTp48KBWrFjh+B1FRUV64YUXtGjRIn3yySeaPn26rr/+eq1Zs6b5vgQAQIuxbP9/TgMAIIpNnDhRL774opKTkx3H77nnHt1zzz2yLEuTJ0/WwoULvecuvPBCnX/++Xr66ae1e/du5ebm6oMPPtB5552nq666Sp06ddJzzz0X8Lt+/etf6+c//7m+/PJLtWnTRpK0cuVKXXnllfr666/VuXNndenSRdOnT9edd94pSaqsrFRubq769++vP/3pTyorK1OHDh30t7/9TYMGDfK+980336zS0lL97ne/a46vCQDQglhTBQAwzqWXXupImiSpQ4cO3se+yUv181Dd/qZMmaJrrrlG77//vkaNGqWxY8dq8ODBkqTt27erb9++3oRKki666CJ5PB7t2LFDycnJ2rt3rwYOHOg9Hx8fr4KCAu8UwJ07d6q0tFSXXXaZ4/eWl5erX79+9f/wAICoQ1IFADBOmzZt1L179yZ5rzFjxuiLL77QypUrVVxcrBEjRmjq1Kl65JFHmuT9q9dfvfrqqzrttNMc58JtrgEAiG6sqQIAxJz169cHPO/Vq1fI6zMyMjRhwgS9+OKLeuyxx/TMM89Iknr16qUPP/xQx48f9167bt06uVwu9ejRQ2lpacrOztaGDRu85ysrK7V582bv8969eyspKUl79uxR9+7dHT85OTlN9ZEBABFEpQoAYJyysjLt27fPcSw+Pt7bYOKll15SQUGBhgwZomXLlmnjxo169tlng77X7Nmz1b9/f51zzjkqKyvTK6+84k3Axo8frzlz5mjChAm67777dODAAf30pz/Vj370I3Xu3FmSNG3aNM2bN095eXnq2bOnFixYoMOHD3vfv127dpo5c6amT58uj8ejIUOG6MiRI1q3bp1SU1M1YcKEZviGAAAtiaQKAGCcVatWKTs723GsR48e+vTTTyVJ999/v5YvX65bb71V2dnZ+v3vf6/evXsHfa/ExETNmjVLu3fvltvt1sUXX6zly5dLklJSUvT6669r2rRpGjBggFJSUnTNNddowYIF3tfPmDFDe/fu1YQJE+RyuXTjjTfq6quv1pEjR7zXPPjgg8rIyFBRUZE+//xzpaen6/zzz9c999zT1F8NACAC6P4HAIgplmVpxYoVGjt2bKSHAgBoJVhTBQAAAACNQFIFAAAAAI3AmioAQExhVjsAoKVRqQIAAACARiCpAgAAAIBGIKkCAAAAgEYgqQIAAACARiCpAgAAAIBGIKkCAAAAgEYgqQIAAACARiCpAgAAAIBG+P//ToWVYl5p1gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ This function will save, evaluate, generate a video of your agent,\n",
            "create a model card and push everything to the hub. It might take up to 1min.\n",
            "This is a work in progress: if you encounter a bug, please open an issue.\u001b[0m\n",
            "Saving video to /tmp/tmpus46mpyv/-step-0-to-step-1000.mp4\n",
            "Moviepy - Building video /tmp/tmpus46mpyv/-step-0-to-step-1000.mp4.\n",
            "Moviepy - Writing video /tmp/tmpus46mpyv/-step-0-to-step-1000.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /tmp/tmpus46mpyv/-step-0-to-step-1000.mp4\n",
            "\u001b[38;5;1m✘ 'DummyVecEnv' object has no attribute 'video_recorder'\u001b[0m\n",
            "\u001b[38;5;1m✘ We are unable to generate a replay of your agent, the package_to_hub\n",
            "process continues\u001b[0m\n",
            "\u001b[38;5;1m✘ Please open an issue at\n",
            "https://github.com/huggingface/huggingface_sb3/issues\u001b[0m\n",
            "\u001b[38;5;4mℹ Pushing repo oussamab2n/a2c-panda-reach to the Hugging Face Hub\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "policy.optimizer.pth:   0%|          | 0.00/49.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c78c5ec0063b416289dce2fe89e9b0ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adbdabe296864d4bb49cd7bf8a6eaa81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "policy.pth:   0%|          | 0.00/47.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af001b75d30f48c7a5a02293afa17ba5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "a2c-panda-reach.zip:   0%|          | 0.00/114k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc348c31afbf470a84acde08f7f4142c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Your model is pushed to the Hub. You can view your model here:\n",
            "https://huggingface.co/oussamab2n/a2c-panda-reach/tree/main/\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▃▄▄▁▄▃▄▂▂▅▁▄▃▆▃▃▆▃▆▁▆▅▂▇▇▇▇▇▁▇██▂▄█</td></tr><tr><td>mean_reward</td><td>▁</td></tr><tr><td>rollout/ep_len_mean</td><td>█▅▅▆▅▂▁▁▂▅▁▁▄▆▆▇▁▄▁▅█▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁</td></tr><tr><td>rollout/ep_rew_mean</td><td>▄▄▄▅▁▅███▆▅█████▃█████▅██▅▄█████████▄█▅█</td></tr><tr><td>rollout/success_rate</td><td>▁▁▂▅▁▃▃▄▄███▇██▄██▅█████████▂▅█▄████████</td></tr><tr><td>std_reward</td><td>▁</td></tr><tr><td>time/fps</td><td>██▆▇▃▆▃▂▂▁▂▅▅▆▄▄▄▄▄▄▄▄▅▁▂▁▄▄▄▃▄▁█▄▅▂▆▅▇▅</td></tr><tr><td>train/entropy_loss</td><td>▁▂▂▂▂▁▁▁▄▂▆▃▃▆▁▄▇▄▂▇▇█▁▁█▇██▂███▂▆▂█▆▆▅▆</td></tr><tr><td>train/explained_variance</td><td>███████████████▁█▄████████▇████▇████████</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/policy_loss</td><td>▄▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/std</td><td>███▇▇▆▆▅▇▅█▄▃▃▃▂▆▆█▂▆▅▁▁▅▁▂▄▇▂▁▃▁▁▁▁▁▁▁▁</td></tr><tr><td>train/value_loss</td><td>▁▁▃▁▁▃▁▃█▁▂▁▁▂▁▁█▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>500665</td></tr><tr><td>mean_reward</td><td>-0.4558</td></tr><tr><td>model_saved</td><td>True</td></tr><tr><td>rollout/ep_len_mean</td><td>4.75</td></tr><tr><td>rollout/ep_rew_mean</td><td>-0.38819</td></tr><tr><td>rollout/success_rate</td><td>1</td></tr><tr><td>std_reward</td><td>0.34822</td></tr><tr><td>time/fps</td><td>108</td></tr><tr><td>train/entropy_loss</td><td>-5.59675</td></tr><tr><td>train/explained_variance</td><td>0.79654</td></tr><tr><td>train/learning_rate</td><td>0.0007</td></tr><tr><td>train/policy_loss</td><td>-0.56994</td></tr><tr><td>train/std</td><td>0.58343</td></tr><tr><td>train/value_loss</td><td>0.01293</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sweet-pyramid-32</strong> at: <a href='https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym/runs/aqrdlwti' target=\"_blank\">https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym/runs/aqrdlwti</a><br> View project at: <a href='https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym' target=\"_blank\">https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 600 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250226_140257-aqrdlwti/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle entraîné sur 500 épisodes, évalué, sauvegardé et visualisé avec succès !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evalute"
      ],
      "metadata": {
        "id": "iFiJ9KWgjKFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import panda_gym\n",
        "import wandb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import A2C\n",
        "from huggingface_sb3 import load_from_hub\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "import os\n",
        "\n",
        "# Initialize Weights & Biases for evaluation\n",
        "wandb.init(project=\"panda-gym\", name=\"evaluation\", config={\"num_episodes\": 100})\n",
        "\n",
        "# Load the model from Hugging Face Hub\n",
        "repo_id = \"oussamab2n/a2c-panda-reach\"\n",
        "filename = \"a2c-panda-reach.zip\"\n",
        "model_path = load_from_hub(repo_id=repo_id, filename=filename)\n",
        "model = A2C.load(model_path)\n",
        "\n",
        "# Create video folder\n",
        "video_dir = \"videos\"\n",
        "os.makedirs(video_dir, exist_ok=True)\n",
        "\n",
        "# Create environment with video recording\n",
        "env = gym.make(\"PandaReachJointsDense-v3\", render_mode=\"rgb_array\")\n",
        "env = RecordVideo(env, video_folder=video_dir, episode_trigger=lambda e: e % 10 == 0)  # Record every 10 episodes\n",
        "\n",
        "# Run evaluation\n",
        "num_episodes = 100\n",
        "success_count = 0\n",
        "episode_rewards = []\n",
        "truncation_rewards = []  # Store reward at truncation\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    truncation_reward = None  # Initialize reward at truncation\n",
        "\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        total_reward += reward\n",
        "\n",
        "        # Check success condition\n",
        "        if \"is_success\" in info and info[\"is_success\"]:\n",
        "            success_count += 1\n",
        "\n",
        "        done = terminated or truncated\n",
        "\n",
        "    episode_rewards.append(total_reward)\n",
        "\n",
        "    # Log episode rewards\n",
        "    wandb.log({\"Episode\": episode + 1, \"Total Reward\": total_reward})\n",
        "\n",
        "    print(f\"Episode {episode+1}: Total Reward = {total_reward} is_success : {info['is_success']}\")\n",
        "\n",
        "# Log success rate\n",
        "success_rate = (success_count / num_episodes) * 100\n",
        "wandb.log({\"Success Rate\": success_rate})\n",
        "print(f\"\\nSuccess Rate: {success_rate:.2f}% ({success_count}/{num_episodes})\")\n",
        "\n",
        "# Close the environment safely\n",
        "try:\n",
        "    env.close()\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Unable to close environment properly: {e}\")\n",
        "\n",
        "# Plot Total Reward per Episode\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_episodes + 1), episode_rewards, marker=\"o\", linestyle=\"-\", label=\"Episode Reward\")\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Total Reward\")\n",
        "plt.title(\"Total Reward per Episode (Evaluation)\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Finish Weights & Biases logging\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o0EsUC_8pFK-",
        "outputId": "b45c2335-8894-4934-b36a-0bc9db13c0bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1: Total Reward = -0.4062510058283806 is_success : True\n",
            "Episode 2: Total Reward = -0.7712566517293453 is_success : True\n",
            "Episode 3: Total Reward = -0.22577803954482079 is_success : True\n",
            "Episode 4: Total Reward = -0.042276110500097275 is_success : True\n",
            "Episode 5: Total Reward = -0.618223849684 is_success : True\n",
            "Episode 6: Total Reward = -0.04875709488987923 is_success : True\n",
            "Episode 7: Total Reward = -0.5882552899420261 is_success : True\n",
            "Episode 8: Total Reward = -0.16985227167606354 is_success : True\n",
            "Episode 9: Total Reward = -0.17977378517389297 is_success : True\n",
            "Episode 10: Total Reward = -0.03690134733915329 is_success : True\n",
            "Episode 11: Total Reward = -1.8714497312903404 is_success : True\n",
            "Episode 12: Total Reward = -0.35330819338560104 is_success : True\n",
            "Episode 13: Total Reward = -0.31165493465960026 is_success : True\n",
            "Episode 14: Total Reward = -0.5640652924776077 is_success : True\n",
            "Episode 15: Total Reward = -0.33318396657705307 is_success : True\n",
            "Episode 16: Total Reward = -0.6635698936879635 is_success : True\n",
            "Episode 17: Total Reward = -0.35100577771663666 is_success : True\n",
            "Episode 18: Total Reward = -0.3555702306330204 is_success : True\n",
            "Episode 19: Total Reward = -0.14223862066864967 is_success : True\n",
            "Episode 20: Total Reward = -0.09988411515951157 is_success : True\n",
            "Episode 21: Total Reward = -0.4415702186524868 is_success : True\n",
            "Episode 22: Total Reward = -0.14504414796829224 is_success : True\n",
            "Episode 23: Total Reward = -0.48955822736024857 is_success : True\n",
            "Episode 24: Total Reward = -0.868715662509203 is_success : True\n",
            "Episode 25: Total Reward = -0.19161485880613327 is_success : True\n",
            "Episode 26: Total Reward = -0.6230216957628727 is_success : True\n",
            "Episode 27: Total Reward = -0.4985925517976284 is_success : True\n",
            "Episode 28: Total Reward = -0.293687392026186 is_success : True\n",
            "Episode 29: Total Reward = -0.14396221190690994 is_success : True\n",
            "Episode 30: Total Reward = -0.391715832054615 is_success : True\n",
            "Episode 31: Total Reward = -0.956602681428194 is_success : True\n",
            "Episode 32: Total Reward = -0.1682831607758999 is_success : True\n",
            "Episode 33: Total Reward = -0.1536100059747696 is_success : True\n",
            "Episode 34: Total Reward = -0.345889188349247 is_success : True\n",
            "Episode 35: Total Reward = -0.0851143728941679 is_success : True\n",
            "Episode 36: Total Reward = -0.21177243813872337 is_success : True\n",
            "Episode 37: Total Reward = -0.42292168363928795 is_success : True\n",
            "Episode 38: Total Reward = -0.39669718965888023 is_success : True\n",
            "Episode 39: Total Reward = -0.2870192937552929 is_success : True\n",
            "Episode 40: Total Reward = -0.1431233212351799 is_success : True\n",
            "Episode 41: Total Reward = -0.2012624740600586 is_success : True\n",
            "Episode 42: Total Reward = -0.34745531901717186 is_success : True\n",
            "Episode 43: Total Reward = -0.44094180688261986 is_success : True\n",
            "Episode 44: Total Reward = -0.35268260911107063 is_success : True\n",
            "Episode 45: Total Reward = -0.3315625675022602 is_success : True\n",
            "Episode 46: Total Reward = -0.619943555444479 is_success : True\n",
            "Episode 47: Total Reward = -1.0147716626524925 is_success : True\n",
            "Episode 48: Total Reward = -0.6043238863348961 is_success : True\n",
            "Episode 49: Total Reward = -0.35877181962132454 is_success : True\n",
            "Episode 50: Total Reward = -0.2241729274392128 is_success : True\n",
            "Episode 51: Total Reward = -0.19858066737651825 is_success : True\n",
            "Episode 52: Total Reward = -0.04564374312758446 is_success : True\n",
            "Episode 53: Total Reward = -0.22833451628684998 is_success : True\n",
            "Episode 54: Total Reward = -0.8358038850128651 is_success : True\n",
            "Episode 55: Total Reward = -0.7864313051104546 is_success : True\n",
            "Episode 56: Total Reward = -0.3810633607208729 is_success : True\n",
            "Episode 57: Total Reward = -0.11827689781785011 is_success : True\n",
            "Episode 58: Total Reward = -0.5082429815083742 is_success : True\n",
            "Episode 59: Total Reward = -0.5666449964046478 is_success : True\n",
            "Episode 60: Total Reward = -0.30292200297117233 is_success : True\n",
            "Episode 61: Total Reward = -0.6551055945456028 is_success : True\n",
            "Episode 62: Total Reward = -2.1062250286340714 is_success : True\n",
            "Episode 63: Total Reward = -0.43518895097076893 is_success : True\n",
            "Episode 64: Total Reward = -0.12211803160607815 is_success : True\n",
            "Episode 65: Total Reward = -0.5217533744871616 is_success : True\n",
            "Episode 66: Total Reward = -0.2624095845967531 is_success : True\n",
            "Episode 67: Total Reward = -0.6889664717018604 is_success : True\n",
            "Episode 68: Total Reward = -0.1458827406167984 is_success : True\n",
            "Episode 69: Total Reward = -0.6224392205476761 is_success : True\n",
            "Episode 70: Total Reward = -0.5712128654122353 is_success : True\n",
            "Episode 71: Total Reward = -0.32383403554558754 is_success : True\n",
            "Episode 72: Total Reward = -0.9531832113862038 is_success : True\n",
            "Episode 73: Total Reward = -0.3022409453988075 is_success : True\n",
            "Episode 74: Total Reward = -0.1974497027695179 is_success : True\n",
            "Episode 75: Total Reward = -0.46416498720645905 is_success : True\n",
            "Episode 76: Total Reward = -0.171061422675848 is_success : True\n",
            "Episode 77: Total Reward = -0.13197795674204826 is_success : True\n",
            "Episode 78: Total Reward = -0.40117064118385315 is_success : True\n",
            "Episode 79: Total Reward = -0.3267452251166105 is_success : True\n",
            "Episode 80: Total Reward = -0.013564204797148705 is_success : True\n",
            "Episode 81: Total Reward = -0.36473673209547997 is_success : True\n",
            "Episode 82: Total Reward = -0.20988689735531807 is_success : True\n",
            "Episode 83: Total Reward = -1.1261731199920177 is_success : True\n",
            "Episode 84: Total Reward = -0.21271120756864548 is_success : True\n",
            "Episode 85: Total Reward = -0.36954135820269585 is_success : True\n",
            "Episode 86: Total Reward = -0.1980939283967018 is_success : True\n",
            "Episode 87: Total Reward = -0.8878751918673515 is_success : True\n",
            "Episode 88: Total Reward = -0.35339905321598053 is_success : True\n",
            "Episode 89: Total Reward = -0.033909156918525696 is_success : True\n",
            "Episode 90: Total Reward = -2.02072698995471 is_success : True\n",
            "Episode 91: Total Reward = -0.5981295704841614 is_success : True\n",
            "Episode 92: Total Reward = -0.310416866093874 is_success : True\n",
            "Episode 93: Total Reward = -0.24613886699080467 is_success : True\n",
            "Episode 94: Total Reward = -0.7379350885748863 is_success : True\n",
            "Episode 95: Total Reward = -0.2529986910521984 is_success : True\n",
            "Episode 96: Total Reward = -0.7348614633083344 is_success : True\n",
            "Episode 97: Total Reward = -0.13540641963481903 is_success : True\n",
            "Episode 98: Total Reward = -0.22798261418938637 is_success : True\n",
            "Episode 99: Total Reward = -0.02772532030940056 is_success : True\n",
            "Episode 100: Total Reward = -0.37505700439214706 is_success : True\n",
            "\n",
            "Success Rate: 100.00% (100/100)\n",
            "Warning: Unable to close environment properly: 'RecordVideo' object has no attribute 'enabled'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Episode</td><td>▁▂▃▃▃▄▄▄▄▄▄▅▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>Success Rate</td><td>▁</td></tr><tr><td>Total Reward</td><td>▇▇██▁█▇▇▇███████▇▇▆██▇▇▇▆██▇▇▇██▇▇▇█▇▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Episode</td><td>100</td></tr><tr><td>Success Rate</td><td>100</td></tr><tr><td>Total Reward</td><td>-0.37506</td></tr><tr><td>is_success</td><td>True</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">evaluation</strong> at: <a href='https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym/runs/62kngzah' target=\"_blank\">https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym/runs/62kngzah</a><br> View project at: <a href='https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym' target=\"_blank\">https://wandb.ai/benyahiamohammedoussama-ecole-central-lyon/panda-gym</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250226_150848-62kngzah/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}